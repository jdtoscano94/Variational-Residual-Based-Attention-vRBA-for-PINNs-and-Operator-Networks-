## SLURM PROLOG ###############################################################
##    Job ID : 12233816
##  Job Name : vanilla
##  Nodelist : gpu2111
##      CPUs : 1
##  Mem/Node : 65536 MB
## Directory : /oscar/data/gk/jdtoscan
##   Job Started : Sat Aug  2 01:17:11 EDT 2025
###############################################################################
Sat Aug  2 01:17:11 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:25:00.0 Off |                  N/A |
| 30%   28C    P8              32W / 350W |     29MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     51757      G   /usr/libexec/Xorg                            21MiB |
+---------------------------------------------------------------------------------------+
Using device: cuda

Train Dataset
x:  (40800, 1, 64, 64)
y:  (40800, 1, 64, 64)
t:  (40800,)


Validation Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)


Test Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)

Lambda:  (40800, 1, 64, 64)
Par: 
 {'nx': 64, 'ny': 64, 'nf': 1, 'd_emb': 128, 'lb': 1, 'lf': 51, 'num_epochs': 500, 'inp_shift': np.float64(0.007669870189599345), 'inp_scale': np.float64(0.061450183570653995), 'out_shift': np.float64(-0.001635048307912137), 'out_scale': np.float64(0.03807830166415873), 't_shift': np.float64(0.0), 't_scale': np.float64(1.0), 'eta': 0.1, 'gamma': 0.99, 'do_rba': True, 'get_snr': True, 'Lambda_max': 9.999999999999991}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
Unet2D                                                  [1, 1, 64, 64]            --
├─Conv2d: 1-1                                           [1, 16, 64, 64]           2,368
├─Sequential: 1-2                                       [1, 64]                   --
│    └─SinusoidalPosEmb: 2-1                            [1, 16]                   --
│    └─Linear: 2-2                                      [1, 64]                   1,088
│    └─GELU: 2-3                                        [1, 64]                   --
│    └─Linear: 2-4                                      [1, 64]                   4,160
├─ModuleList: 1-3                                       --                        --
│    └─ModuleList: 2-5                                  --                        --
│    │    └─ResnetBlock: 3-1                            [1, 16, 64, 64]           6,784
│    │    └─ResnetBlock: 3-2                            [1, 16, 64, 64]           6,784
│    │    └─Residual: 3-3                               [1, 16, 64, 64]           8,240
│    │    └─Sequential: 3-4                             [1, 16, 32, 32]           1,040
│    └─ModuleList: 2-6                                  --                        --
│    │    └─ResnetBlock: 3-5                            [1, 16, 32, 32]           6,784
│    │    └─ResnetBlock: 3-6                            [1, 16, 32, 32]           6,784
│    │    └─Residual: 3-7                               [1, 16, 32, 32]           8,240
│    │    └─Sequential: 3-8                             [1, 32, 16, 16]           2,080
│    └─ModuleList: 2-7                                  --                        --
│    │    └─ResnetBlock: 3-9                            [1, 32, 16, 16]           22,784
│    │    └─ResnetBlock: 3-10                           [1, 32, 16, 16]           22,784
│    │    └─Residual: 3-11                              [1, 32, 16, 16]           16,480
│    │    └─Sequential: 3-12                            [1, 64, 8, 8]             8,256
│    └─ModuleList: 2-8                                  --                        --
│    │    └─ResnetBlock: 3-13                           [1, 64, 8, 8]             82,432
│    │    └─ResnetBlock: 3-14                           [1, 64, 8, 8]             82,432
│    │    └─Residual: 3-15                              [1, 64, 8, 8]             32,960
│    │    └─Conv2d: 3-16                                [1, 128, 8, 8]            73,856
├─ResnetBlock: 1-4                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-9                                  [1, 256]                  --
│    │    └─SiLU: 3-17                                  [1, 64]                   --
│    │    └─Linear: 3-18                                [1, 256]                  16,640
│    └─Block: 2-10                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-19                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-20                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-21                                  [1, 128, 8, 8]            --
│    └─Block: 2-11                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-22                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-23                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-24                                  [1, 128, 8, 8]            --
│    └─Identity: 2-12                                   [1, 128, 8, 8]            --
├─Residual: 1-5                                         [1, 128, 8, 8]            --
│    └─PreNorm: 2-13                                    [1, 128, 8, 8]            --
│    │    └─LayerNorm: 3-25                             [1, 128, 8, 8]            128
│    │    └─Attention: 3-26                             [1, 128, 8, 8]            65,664
├─ResnetBlock: 1-6                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-14                                 [1, 256]                  --
│    │    └─SiLU: 3-27                                  [1, 64]                   --
│    │    └─Linear: 3-28                                [1, 256]                  16,640
│    └─Block: 2-15                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-29                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-30                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-31                                  [1, 128, 8, 8]            --
│    └─Block: 2-16                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-32                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-33                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-34                                  [1, 128, 8, 8]            --
│    └─Identity: 2-17                                   [1, 128, 8, 8]            --
├─ModuleList: 1-7                                       --                        --
│    └─ModuleList: 2-18                                 --                        --
│    │    └─ResnetBlock: 3-35                           [1, 128, 8, 8]            410,752
│    │    └─ResnetBlock: 3-36                           [1, 128, 8, 8]            410,752
│    │    └─Residual: 3-37                              [1, 128, 8, 8]            65,920
│    │    └─Sequential: 3-38                            [1, 64, 16, 16]           73,792
│    └─ModuleList: 2-19                                 --                        --
│    │    └─ResnetBlock: 3-39                           [1, 64, 16, 16]           107,072
│    │    └─ResnetBlock: 3-40                           [1, 64, 16, 16]           107,072
│    │    └─Residual: 3-41                              [1, 64, 16, 16]           32,960
│    │    └─Sequential: 3-42                            [1, 32, 32, 32]           18,464
│    └─ModuleList: 2-20                                 --                        --
│    │    └─ResnetBlock: 3-43                           [1, 32, 32, 32]           28,960
│    │    └─ResnetBlock: 3-44                           [1, 32, 32, 32]           28,960
│    │    └─Residual: 3-45                              [1, 32, 32, 32]           16,480
│    │    └─Sequential: 3-46                            [1, 16, 64, 64]           4,624
│    └─ModuleList: 2-21                                 --                        --
│    │    └─ResnetBlock: 3-47                           [1, 16, 64, 64]           9,616
│    │    └─ResnetBlock: 3-48                           [1, 16, 64, 64]           9,616
│    │    └─Residual: 3-49                              [1, 16, 64, 64]           8,240
│    │    └─Conv2d: 3-50                                [1, 16, 64, 64]           2,320
├─ResnetBlock: 1-8                                      [1, 16, 64, 64]           --
│    └─Sequential: 2-22                                 [1, 32]                   --
│    │    └─SiLU: 3-51                                  [1, 64]                   --
│    │    └─Linear: 3-52                                [1, 32]                   2,080
│    └─Block: 2-23                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-53                                [1, 16, 64, 64]           4,624
│    │    └─GroupNorm: 3-54                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-55                                  [1, 16, 64, 64]           --
│    └─Block: 2-24                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-56                                [1, 16, 64, 64]           2,320
│    │    └─GroupNorm: 3-57                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-58                                  [1, 16, 64, 64]           --
│    └─Conv2d: 2-25                                     [1, 16, 64, 64]           528
├─Conv2d: 1-9                                           [1, 1, 64, 64]            17
=========================================================================================================
Total params: 2,432,001
Trainable params: 2,432,001
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 545.94
=========================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 60.28
Params size (MB): 9.73
Estimated Total Size (MB): 70.02
=========================================================================================================
[2025-08-02 01:18:50] - Epoch 1/500,it:408, Train Loss: 9.0179e-01, Val Loss: 9.3370e-01, best model: 1, LR: 9.9999e-04, epoch time: 88.68, snr: 4.5741e+00, var(R): 5.9177e-05, var(L*R): 5.9177e-05, WD: 0.0000e+00
[2025-08-02 01:20:19] - Epoch 2/500,it:816, Train Loss: 7.9056e-01, Val Loss: 8.7066e-01, best model: 2, LR: 9.9996e-04, epoch time: 88.57, snr: 2.0592e+01, var(R): 2.2487e-05, var(L*R): 2.2997e-05, WD: 5.2135e-08
[2025-08-02 01:21:47] - Epoch 3/500,it:1224, Train Loss: 6.9849e-01, Val Loss: 8.2177e-01, best model: 3, LR: 9.9991e-04, epoch time: 88.58, snr: 1.5612e+01, var(R): 1.1204e-05, var(L*R): 1.1553e-05, WD: 7.9606e-08
[2025-08-02 01:23:16] - Epoch 4/500,it:1632, Train Loss: 6.3977e-01, Val Loss: 6.7480e-01, best model: 4, LR: 9.9984e-04, epoch time: 88.78, snr: 1.6877e+01, var(R): 8.9090e-06, var(L*R): 9.3469e-06, WD: 1.0078e-07
[2025-08-02 01:24:45] - Epoch 5/500,it:2040, Train Loss: 5.8670e-01, Val Loss: 5.8764e-01, best model: 5, LR: 9.9975e-04, epoch time: 89.11, snr: 1.1246e+01, var(R): 3.1559e-06, var(L*R): 3.3215e-06, WD: 1.1931e-07
[2025-08-02 01:26:14] - Epoch 6/500,it:2448, Train Loss: 5.5101e-01, Val Loss: 5.1625e-01, best model: 6, LR: 9.9964e-04, epoch time: 88.95, snr: 5.0075e+00, var(R): 2.4107e-06, var(L*R): 2.5539e-06, WD: 1.3469e-07
[2025-08-02 01:27:43] - Epoch 7/500,it:2856, Train Loss: 5.3995e-01, Val Loss: 5.2534e-01, best model: 6, LR: 9.9952e-04, epoch time: 88.55, snr: 4.4999e+00, var(R): 1.8013e-06, var(L*R): 1.9477e-06, WD: 1.4961e-07
[2025-08-02 01:29:12] - Epoch 8/500,it:3264, Train Loss: 4.9669e-01, Val Loss: 4.7191e-01, best model: 8, LR: 9.9937e-04, epoch time: 89.07, snr: 6.0753e+00, var(R): 1.9027e-06, var(L*R): 2.0699e-06, WD: 1.6193e-07
[2025-08-02 01:30:41] - Epoch 9/500,it:3672, Train Loss: 4.8573e-01, Val Loss: 5.2097e-01, best model: 8, LR: 9.9920e-04, epoch time: 89.26, snr: 2.5382e+00, var(R): 1.4447e-06, var(L*R): 1.5988e-06, WD: 1.7307e-07
[2025-08-02 01:32:10] - Epoch 10/500,it:4080, Train Loss: 4.7311e-01, Val Loss: 4.9322e-01, best model: 8, LR: 9.9901e-04, epoch time: 89.01, snr: 2.0977e+00, var(R): 1.9633e-06, var(L*R): 2.1604e-06, WD: 1.8370e-07
[2025-08-02 01:33:39] - Epoch 11/500,it:4488, Train Loss: 4.5417e-01, Val Loss: 4.4061e-01, best model: 11, LR: 9.9881e-04, epoch time: 89.02, snr: 3.2027e+00, var(R): 1.7570e-06, var(L*R): 1.9434e-06, WD: 1.9472e-07
[2025-08-02 01:35:08] - Epoch 12/500,it:4896, Train Loss: 4.3993e-01, Val Loss: 4.6725e-01, best model: 11, LR: 9.9858e-04, epoch time: 89.03, snr: 6.0644e+00, var(R): 1.2530e-06, var(L*R): 1.4389e-06, WD: 2.0320e-07
[2025-08-02 01:36:37] - Epoch 13/500,it:5304, Train Loss: 4.3370e-01, Val Loss: 4.7093e-01, best model: 11, LR: 9.9833e-04, epoch time: 89.04, snr: 2.8260e+00, var(R): 1.3287e-06, var(L*R): 1.5009e-06, WD: 2.1413e-07
[2025-08-02 01:38:06] - Epoch 14/500,it:5712, Train Loss: 4.1876e-01, Val Loss: 4.5900e-01, best model: 11, LR: 9.9807e-04, epoch time: 89.24, snr: 2.5208e+00, var(R): 1.3763e-06, var(L*R): 1.5627e-06, WD: 2.2310e-07
[2025-08-02 01:39:36] - Epoch 15/500,it:6120, Train Loss: 4.1389e-01, Val Loss: 3.8861e-01, best model: 15, LR: 9.9778e-04, epoch time: 89.44, snr: 2.5516e+00, var(R): 1.2822e-06, var(L*R): 1.4655e-06, WD: 2.3139e-07
[2025-08-02 01:41:05] - Epoch 16/500,it:6528, Train Loss: 3.9258e-01, Val Loss: 4.0054e-01, best model: 15, LR: 9.9748e-04, epoch time: 89.18, snr: 7.6488e-01, var(R): 8.1630e-07, var(L*R): 9.6700e-07, WD: 2.4057e-07
[2025-08-02 01:42:35] - Epoch 17/500,it:6936, Train Loss: 3.7931e-01, Val Loss: 3.8425e-01, best model: 17, LR: 9.9715e-04, epoch time: 89.57, snr: 3.1483e+00, var(R): 7.6966e-07, var(L*R): 9.2429e-07, WD: 2.4936e-07
[2025-08-02 01:44:04] - Epoch 18/500,it:7344, Train Loss: 3.7621e-01, Val Loss: 3.7149e-01, best model: 18, LR: 9.9681e-04, epoch time: 89.38, snr: 4.8763e+00, var(R): 7.1308e-07, var(L*R): 8.4944e-07, WD: 2.5713e-07
[2025-08-02 01:45:33] - Epoch 19/500,it:7752, Train Loss: 3.6555e-01, Val Loss: 3.6898e-01, best model: 19, LR: 9.9644e-04, epoch time: 89.19, snr: 9.7838e-01, var(R): 6.1336e-07, var(L*R): 7.3594e-07, WD: 2.6501e-07
[2025-08-02 01:47:03] - Epoch 20/500,it:8160, Train Loss: 3.6372e-01, Val Loss: 3.8458e-01, best model: 19, LR: 9.9606e-04, epoch time: 89.36, snr: 2.4359e+00, var(R): 5.9789e-07, var(L*R): 6.9605e-07, WD: 2.7353e-07
[2025-08-02 01:48:32] - Epoch 21/500,it:8568, Train Loss: 3.3950e-01, Val Loss: 3.3915e-01, best model: 21, LR: 9.9565e-04, epoch time: 89.38, snr: 2.8726e+00, var(R): 6.2474e-07, var(L*R): 7.3616e-07, WD: 2.8241e-07
[2025-08-02 01:50:01] - Epoch 22/500,it:8976, Train Loss: 3.3359e-01, Val Loss: 3.8252e-01, best model: 21, LR: 9.9523e-04, epoch time: 89.23, snr: 3.2534e+00, var(R): 4.2429e-07, var(L*R): 4.8653e-07, WD: 2.8907e-07
[2025-08-02 01:51:30] - Epoch 23/500,it:9384, Train Loss: 3.2512e-01, Val Loss: 3.4568e-01, best model: 21, LR: 9.9479e-04, epoch time: 89.08, snr: 2.9237e+00, var(R): 6.1989e-07, var(L*R): 6.8866e-07, WD: 2.9730e-07
[2025-08-02 01:53:00] - Epoch 24/500,it:9792, Train Loss: 3.1598e-01, Val Loss: 3.0564e-01, best model: 24, LR: 9.9433e-04, epoch time: 89.28, snr: 4.4429e+00, var(R): 4.1141e-07, var(L*R): 4.7679e-07, WD: 3.0436e-07
[2025-08-02 01:54:29] - Epoch 25/500,it:10200, Train Loss: 3.0929e-01, Val Loss: 3.1285e-01, best model: 24, LR: 9.9384e-04, epoch time: 89.12, snr: 2.6488e+00, var(R): 3.2250e-07, var(L*R): 3.8515e-07, WD: 3.1128e-07
[2025-08-02 01:55:58] - Epoch 26/500,it:10608, Train Loss: 3.0224e-01, Val Loss: 2.7462e-01, best model: 26, LR: 9.9334e-04, epoch time: 89.33, snr: 1.5484e+00, var(R): 2.8214e-07, var(L*R): 3.3767e-07, WD: 3.1847e-07
[2025-08-02 01:57:27] - Epoch 27/500,it:11016, Train Loss: 2.9218e-01, Val Loss: 2.5634e-01, best model: 27, LR: 9.9282e-04, epoch time: 89.21, snr: 2.5970e+00, var(R): 2.5165e-07, var(L*R): 3.0012e-07, WD: 3.2652e-07
[2025-08-02 01:58:56] - Epoch 28/500,it:11424, Train Loss: 2.9052e-01, Val Loss: 2.8954e-01, best model: 27, LR: 9.9228e-04, epoch time: 88.95, snr: 2.4709e+00, var(R): 2.0021e-07, var(L*R): 2.4543e-07, WD: 3.3430e-07
[2025-08-02 02:00:25] - Epoch 29/500,it:11832, Train Loss: 2.9296e-01, Val Loss: 2.6464e-01, best model: 27, LR: 9.9172e-04, epoch time: 89.00, snr: 1.8376e+00, var(R): 2.6144e-07, var(L*R): 3.0875e-07, WD: 3.4036e-07
[2025-08-02 02:01:54] - Epoch 30/500,it:12240, Train Loss: 2.7960e-01, Val Loss: 2.5445e-01, best model: 30, LR: 9.9114e-04, epoch time: 88.85, snr: 9.4405e-01, var(R): 2.2454e-07, var(L*R): 2.7189e-07, WD: 3.4595e-07
[2025-08-02 02:03:23] - Epoch 31/500,it:12648, Train Loss: 2.7079e-01, Val Loss: 2.7119e-01, best model: 30, LR: 9.9055e-04, epoch time: 88.82, snr: 2.1357e+00, var(R): 1.9843e-07, var(L*R): 2.3892e-07, WD: 3.5392e-07
[2025-08-02 02:04:52] - Epoch 32/500,it:13056, Train Loss: 2.7468e-01, Val Loss: 3.0078e-01, best model: 30, LR: 9.8993e-04, epoch time: 88.81, snr: 1.7531e+00, var(R): 1.7440e-07, var(L*R): 1.9928e-07, WD: 3.6069e-07
[2025-08-02 02:06:21] - Epoch 33/500,it:13464, Train Loss: 2.6062e-01, Val Loss: 2.8337e-01, best model: 30, LR: 9.8929e-04, epoch time: 89.26, snr: 9.0844e-01, var(R): 2.9510e-07, var(L*R): 3.4220e-07, WD: 3.6709e-07
[2025-08-02 02:07:50] - Epoch 34/500,it:13872, Train Loss: 2.6918e-01, Val Loss: 3.3971e-01, best model: 30, LR: 9.8863e-04, epoch time: 88.84, snr: 5.4336e+00, var(R): 2.0407e-07, var(L*R): 2.3403e-07, WD: 3.7460e-07
[2025-08-02 02:09:19] - Epoch 35/500,it:14280, Train Loss: 2.6304e-01, Val Loss: 3.1543e-01, best model: 30, LR: 9.8796e-04, epoch time: 88.84, snr: 5.8694e+00, var(R): 4.3835e-07, var(L*R): 4.8290e-07, WD: 3.8062e-07
[2025-08-02 02:10:47] - Epoch 36/500,it:14688, Train Loss: 2.5623e-01, Val Loss: 2.7403e-01, best model: 30, LR: 9.8726e-04, epoch time: 88.70, snr: 1.8189e+00, var(R): 3.4899e-07, var(L*R): 4.0671e-07, WD: 3.8618e-07
[2025-08-02 02:12:16] - Epoch 37/500,it:15096, Train Loss: 2.4850e-01, Val Loss: 2.6400e-01, best model: 30, LR: 9.8655e-04, epoch time: 88.74, snr: 1.8991e+00, var(R): 2.1421e-07, var(L*R): 2.5293e-07, WD: 3.9437e-07
[2025-08-02 02:13:45] - Epoch 38/500,it:15504, Train Loss: 2.4691e-01, Val Loss: 2.3546e-01, best model: 38, LR: 9.8582e-04, epoch time: 88.67, snr: 2.2776e+00, var(R): 1.7008e-07, var(L*R): 1.9966e-07, WD: 4.0035e-07
[2025-08-02 02:15:13] - Epoch 39/500,it:15912, Train Loss: 2.9619e-01, Val Loss: 2.8237e-01, best model: 38, LR: 9.8506e-04, epoch time: 88.55, snr: 2.0071e+00, var(R): 1.5547e-07, var(L*R): 1.8378e-07, WD: 4.0600e-07
[2025-08-02 02:16:42] - Epoch 40/500,it:16320, Train Loss: 2.4791e-01, Val Loss: 2.4997e-01, best model: 38, LR: 9.8429e-04, epoch time: 88.51, snr: 5.2676e+00, var(R): 2.5869e-07, var(L*R): 3.0291e-07, WD: 4.1453e-07
[2025-08-02 02:18:11] - Epoch 41/500,it:16728, Train Loss: 2.4703e-01, Val Loss: 2.5548e-01, best model: 38, LR: 9.8350e-04, epoch time: 88.74, snr: 1.7204e+00, var(R): 1.8387e-07, var(L*R): 2.3318e-07, WD: 4.2139e-07
[2025-08-02 02:19:39] - Epoch 42/500,it:17136, Train Loss: 2.4417e-01, Val Loss: 2.2649e-01, best model: 42, LR: 9.8269e-04, epoch time: 88.65, snr: 1.0919e+00, var(R): 2.2280e-07, var(L*R): 2.5623e-07, WD: 4.2752e-07
[2025-08-02 02:21:08] - Epoch 43/500,it:17544, Train Loss: 2.4289e-01, Val Loss: 2.6471e-01, best model: 42, LR: 9.8186e-04, epoch time: 88.64, snr: 4.0900e+00, var(R): 1.1098e-07, var(L*R): 1.3197e-07, WD: 4.3180e-07
[2025-08-02 02:22:36] - Epoch 44/500,it:17952, Train Loss: 2.3804e-01, Val Loss: 2.4972e-01, best model: 42, LR: 9.8101e-04, epoch time: 88.64, snr: 6.1971e+00, var(R): 2.1774e-07, var(L*R): 2.5527e-07, WD: 4.3914e-07
[2025-08-02 02:24:05] - Epoch 45/500,it:18360, Train Loss: 2.3013e-01, Val Loss: 2.5505e-01, best model: 42, LR: 9.8015e-04, epoch time: 88.66, snr: 5.4091e+00, var(R): 1.8370e-07, var(L*R): 2.1030e-07, WD: 4.4515e-07
[2025-08-02 02:25:34] - Epoch 46/500,it:18768, Train Loss: 2.3653e-01, Val Loss: 2.4966e-01, best model: 42, LR: 9.7926e-04, epoch time: 88.48, snr: 1.4201e+00, var(R): 1.7792e-07, var(L*R): 2.0275e-07, WD: 4.5132e-07
[2025-08-02 02:27:02] - Epoch 47/500,it:19176, Train Loss: 2.2555e-01, Val Loss: 2.5570e-01, best model: 42, LR: 9.7836e-04, epoch time: 88.68, snr: 1.6122e+00, var(R): 1.6786e-07, var(L*R): 1.9745e-07, WD: 4.5805e-07
[2025-08-02 02:28:31] - Epoch 48/500,it:19584, Train Loss: 2.1407e-01, Val Loss: 1.8939e-01, best model: 48, LR: 9.7743e-04, epoch time: 88.76, snr: 6.0533e+00, var(R): 1.9718e-07, var(L*R): 2.2823e-07, WD: 4.6326e-07
[2025-08-02 02:30:00] - Epoch 49/500,it:19992, Train Loss: 2.1840e-01, Val Loss: 2.5807e-01, best model: 48, LR: 9.7649e-04, epoch time: 88.47, snr: 1.6994e+00, var(R): 5.2896e-08, var(L*R): 6.6054e-08, WD: 4.7072e-07
[2025-08-02 02:31:28] - Epoch 50/500,it:20400, Train Loss: 2.2577e-01, Val Loss: 2.4522e-01, best model: 48, LR: 9.7553e-04, epoch time: 88.52, snr: 2.5647e+00, var(R): 3.8754e-07, var(L*R): 4.7844e-07, WD: 4.7644e-07
[2025-08-02 02:32:57] - Epoch 51/500,it:20808, Train Loss: 2.2321e-01, Val Loss: 2.3355e-01, best model: 48, LR: 9.7455e-04, epoch time: 88.61, snr: 2.1531e+00, var(R): 2.7837e-07, var(L*R): 3.3775e-07, WD: 4.8317e-07
[2025-08-02 02:34:25] - Epoch 52/500,it:21216, Train Loss: 2.1373e-01, Val Loss: 2.7006e-01, best model: 48, LR: 9.7355e-04, epoch time: 88.65, snr: 1.5913e+00, var(R): 1.2989e-07, var(L*R): 1.5308e-07, WD: 4.8967e-07
[2025-08-02 02:35:54] - Epoch 53/500,it:21624, Train Loss: 2.1599e-01, Val Loss: 2.2004e-01, best model: 48, LR: 9.7253e-04, epoch time: 88.56, snr: 1.0168e+00, var(R): 3.8145e-07, var(L*R): 4.6641e-07, WD: 4.9546e-07
[2025-08-02 02:37:22] - Epoch 54/500,it:22032, Train Loss: 2.2059e-01, Val Loss: 2.2826e-01, best model: 48, LR: 9.7150e-04, epoch time: 88.54, snr: 1.7623e+00, var(R): 1.1562e-07, var(L*R): 1.4478e-07, WD: 5.0139e-07
[2025-08-02 02:38:51] - Epoch 55/500,it:22440, Train Loss: 2.1548e-01, Val Loss: 2.1795e-01, best model: 48, LR: 9.7044e-04, epoch time: 88.56, snr: 1.0963e+00, var(R): 1.3489e-07, var(L*R): 1.7051e-07, WD: 5.0686e-07
[2025-08-02 02:40:20] - Epoch 56/500,it:22848, Train Loss: 2.1202e-01, Val Loss: 2.0437e-01, best model: 48, LR: 9.6937e-04, epoch time: 88.67, snr: 4.3042e+00, var(R): 1.3650e-07, var(L*R): 1.6120e-07, WD: 5.1363e-07
[2025-08-02 02:41:48] - Epoch 57/500,it:23256, Train Loss: 2.0855e-01, Val Loss: 2.5082e-01, best model: 48, LR: 9.6827e-04, epoch time: 88.59, snr: 1.1687e+00, var(R): 1.4392e-07, var(L*R): 1.8973e-07, WD: 5.1875e-07
[2025-08-02 02:43:17] - Epoch 58/500,it:23664, Train Loss: 2.0769e-01, Val Loss: 2.1334e-01, best model: 48, LR: 9.6716e-04, epoch time: 88.70, snr: 1.2156e+00, var(R): 1.5056e-07, var(L*R): 2.3993e-07, WD: 5.2557e-07
[2025-08-02 02:44:46] - Epoch 59/500,it:24072, Train Loss: 2.3052e-01, Val Loss: 2.2329e-01, best model: 48, LR: 9.6604e-04, epoch time: 88.73, snr: 2.2184e+00, var(R): 1.1641e-07, var(L*R): 1.4220e-07, WD: 5.3039e-07
[2025-08-02 02:46:14] - Epoch 60/500,it:24480, Train Loss: 1.9982e-01, Val Loss: 2.0787e-01, best model: 48, LR: 9.6489e-04, epoch time: 88.79, snr: 1.3305e+00, var(R): 1.1423e-07, var(L*R): 1.4343e-07, WD: 5.3968e-07
[2025-08-02 02:47:43] - Epoch 61/500,it:24888, Train Loss: 2.0554e-01, Val Loss: 2.1364e-01, best model: 48, LR: 9.6372e-04, epoch time: 88.46, snr: 8.0266e-01, var(R): 8.0360e-08, var(L*R): 1.0447e-07, WD: 5.4483e-07
[2025-08-02 02:49:12] - Epoch 62/500,it:25296, Train Loss: 1.9528e-01, Val Loss: 1.9080e-01, best model: 48, LR: 9.6254e-04, epoch time: 88.63, snr: 1.9656e+00, var(R): 8.3878e-08, var(L*R): 1.0941e-07, WD: 5.4734e-07
[2025-08-02 02:50:40] - Epoch 63/500,it:25704, Train Loss: 1.9570e-01, Val Loss: 1.7943e-01, best model: 63, LR: 9.6134e-04, epoch time: 88.73, snr: 6.3712e+00, var(R): 8.5505e-08, var(L*R): 1.1673e-07, WD: 5.5307e-07
[2025-08-02 02:52:09] - Epoch 64/500,it:26112, Train Loss: 1.9319e-01, Val Loss: 2.0353e-01, best model: 63, LR: 9.6012e-04, epoch time: 88.54, snr: 5.2358e+00, var(R): 8.5736e-08, var(L*R): 1.0977e-07, WD: 5.6251e-07
[2025-08-02 02:53:37] - Epoch 65/500,it:26520, Train Loss: 1.9535e-01, Val Loss: 2.1590e-01, best model: 63, LR: 9.5888e-04, epoch time: 88.37, snr: 5.6198e+00, var(R): 6.0433e-08, var(L*R): 8.9689e-08, WD: 5.6595e-07
[2025-08-02 02:55:06] - Epoch 66/500,it:26928, Train Loss: 2.0716e-01, Val Loss: 1.9336e-01, best model: 63, LR: 9.5762e-04, epoch time: 88.58, snr: 1.9342e+00, var(R): 1.6632e-07, var(L*R): 2.2396e-07, WD: 5.7334e-07
[2025-08-02 02:56:34] - Epoch 67/500,it:27336, Train Loss: 1.9905e-01, Val Loss: 2.0151e-01, best model: 63, LR: 9.5635e-04, epoch time: 88.64, snr: 8.9084e-01, var(R): 8.5693e-08, var(L*R): 1.1493e-07, WD: 5.7877e-07
[2025-08-02 02:58:03] - Epoch 68/500,it:27744, Train Loss: 1.9334e-01, Val Loss: 2.3217e-01, best model: 63, LR: 9.5505e-04, epoch time: 88.55, snr: 1.4481e+00, var(R): 1.1545e-07, var(L*R): 1.6150e-07, WD: 5.8502e-07
[2025-08-02 02:59:31] - Epoch 69/500,it:28152, Train Loss: 1.8517e-01, Val Loss: 1.9870e-01, best model: 63, LR: 9.5374e-04, epoch time: 88.38, snr: 1.1002e+00, var(R): 1.2396e-07, var(L*R): 1.7249e-07, WD: 5.9127e-07
[2025-08-02 03:01:00] - Epoch 70/500,it:28560, Train Loss: 1.8495e-01, Val Loss: 2.1121e-01, best model: 63, LR: 9.5241e-04, epoch time: 88.62, snr: 3.6877e+00, var(R): 5.6568e-08, var(L*R): 7.5267e-08, WD: 5.9575e-07
[2025-08-02 03:02:29] - Epoch 71/500,it:28968, Train Loss: 1.8617e-01, Val Loss: 1.8827e-01, best model: 63, LR: 9.5107e-04, epoch time: 88.69, snr: 8.6227e+00, var(R): 8.1544e-08, var(L*R): 9.8007e-08, WD: 6.0003e-07
[2025-08-02 03:03:57] - Epoch 72/500,it:29376, Train Loss: 1.8101e-01, Val Loss: 2.1175e-01, best model: 63, LR: 9.4970e-04, epoch time: 88.45, snr: 1.8577e+00, var(R): 5.8506e-08, var(L*R): 7.6663e-08, WD: 6.0864e-07
[2025-08-02 03:05:26] - Epoch 73/500,it:29784, Train Loss: 1.8021e-01, Val Loss: 2.3481e-01, best model: 63, LR: 9.4832e-04, epoch time: 88.64, snr: 1.2485e+00, var(R): 9.0138e-08, var(L*R): 1.2879e-07, WD: 6.1555e-07
[2025-08-02 03:06:55] - Epoch 74/500,it:30192, Train Loss: 1.7729e-01, Val Loss: 1.8102e-01, best model: 63, LR: 9.4692e-04, epoch time: 88.69, snr: 1.9887e+00, var(R): 1.8986e-07, var(L*R): 2.4216e-07, WD: 6.1387e-07
[2025-08-02 03:08:23] - Epoch 75/500,it:30600, Train Loss: 1.8605e-01, Val Loss: 1.9837e-01, best model: 63, LR: 9.4550e-04, epoch time: 88.50, snr: 4.0458e+00, var(R): 7.9386e-08, var(L*R): 1.2017e-07, WD: 6.2308e-07
[2025-08-02 03:09:52] - Epoch 76/500,it:31008, Train Loss: 1.8384e-01, Val Loss: 1.5947e-01, best model: 76, LR: 9.4407e-04, epoch time: 88.55, snr: 3.4219e+00, var(R): 8.2119e-08, var(L*R): 1.3077e-07, WD: 6.2824e-07
[2025-08-02 03:11:20] - Epoch 77/500,it:31416, Train Loss: 1.8734e-01, Val Loss: 2.3488e-01, best model: 76, LR: 9.4262e-04, epoch time: 88.58, snr: 1.3459e+00, var(R): 3.5251e-08, var(L*R): 4.9572e-08, WD: 6.3553e-07
[2025-08-02 03:12:49] - Epoch 78/500,it:31824, Train Loss: 1.8008e-01, Val Loss: 1.7232e-01, best model: 76, LR: 9.4115e-04, epoch time: 88.65, snr: 1.5265e+00, var(R): 1.2504e-07, var(L*R): 1.9917e-07, WD: 6.4182e-07
[2025-08-02 03:14:17] - Epoch 79/500,it:32232, Train Loss: 1.7475e-01, Val Loss: 1.6747e-01, best model: 76, LR: 9.3966e-04, epoch time: 88.55, snr: 3.3484e+00, var(R): 4.1296e-08, var(L*R): 5.9008e-08, WD: 6.4778e-07
[2025-08-02 03:15:46] - Epoch 80/500,it:32640, Train Loss: 1.8238e-01, Val Loss: 1.8030e-01, best model: 76, LR: 9.3815e-04, epoch time: 88.48, snr: 2.7576e+00, var(R): 4.8355e-08, var(L*R): 7.0151e-08, WD: 6.4962e-07
[2025-08-02 03:17:14] - Epoch 81/500,it:33048, Train Loss: 1.7824e-01, Val Loss: 1.9848e-01, best model: 76, LR: 9.3663e-04, epoch time: 88.58, snr: 6.4539e+00, var(R): 7.2867e-08, var(L*R): 1.1664e-07, WD: 6.5884e-07
[2025-08-02 03:18:43] - Epoch 82/500,it:33456, Train Loss: 1.7707e-01, Val Loss: 1.7817e-01, best model: 76, LR: 9.3509e-04, epoch time: 88.72, snr: 1.8266e+00, var(R): 6.8465e-08, var(L*R): 9.1340e-08, WD: 6.6341e-07
[2025-08-02 03:20:12] - Epoch 83/500,it:33864, Train Loss: 1.7298e-01, Val Loss: 1.8312e-01, best model: 76, LR: 9.3354e-04, epoch time: 88.64, snr: 1.0632e+00, var(R): 4.7998e-08, var(L*R): 7.1201e-08, WD: 6.6931e-07
[2025-08-02 03:21:40] - Epoch 84/500,it:34272, Train Loss: 1.8354e-01, Val Loss: 2.0964e-01, best model: 76, LR: 9.3196e-04, epoch time: 88.47, snr: 9.2509e-01, var(R): 6.1081e-08, var(L*R): 8.8351e-08, WD: 6.7577e-07
[2025-08-02 03:23:09] - Epoch 85/500,it:34680, Train Loss: 1.7044e-01, Val Loss: 1.6445e-01, best model: 76, LR: 9.3037e-04, epoch time: 88.59, snr: 3.0685e+00, var(R): 1.4094e-07, var(L*R): 2.1460e-07, WD: 6.7831e-07
[2025-08-02 03:24:37] - Epoch 86/500,it:35088, Train Loss: 1.7328e-01, Val Loss: 1.8649e-01, best model: 76, LR: 9.2876e-04, epoch time: 88.60, snr: 2.6796e+00, var(R): 2.7799e-08, var(L*R): 5.5014e-08, WD: 6.8812e-07
[2025-08-02 03:26:06] - Epoch 87/500,it:35496, Train Loss: 1.7630e-01, Val Loss: 2.0197e-01, best model: 76, LR: 9.2714e-04, epoch time: 88.67, snr: 2.4228e+00, var(R): 7.7343e-08, var(L*R): 1.1549e-07, WD: 6.9447e-07
[2025-08-02 03:27:35] - Epoch 88/500,it:35904, Train Loss: 1.6286e-01, Val Loss: 1.6272e-01, best model: 76, LR: 9.2550e-04, epoch time: 88.50, snr: 1.9871e+00, var(R): 8.4155e-08, var(L*R): 1.4319e-07, WD: 6.9375e-07
[2025-08-02 03:29:03] - Epoch 89/500,it:36312, Train Loss: 1.7021e-01, Val Loss: 1.8742e-01, best model: 76, LR: 9.2384e-04, epoch time: 88.71, snr: 1.0135e+00, var(R): 4.2810e-08, var(L*R): 7.1726e-08, WD: 7.0147e-07
[2025-08-02 03:30:32] - Epoch 90/500,it:36720, Train Loss: 1.7321e-01, Val Loss: 1.8577e-01, best model: 76, LR: 9.2216e-04, epoch time: 88.64, snr: 9.6486e-01, var(R): 5.3152e-08, var(L*R): 8.8347e-08, WD: 7.0801e-07
[2025-08-02 03:32:01] - Epoch 91/500,it:37128, Train Loss: 1.6448e-01, Val Loss: 1.5620e-01, best model: 91, LR: 9.2047e-04, epoch time: 88.55, snr: 2.3748e+00, var(R): 7.3047e-08, var(L*R): 1.1480e-07, WD: 7.1748e-07
[2025-08-02 03:33:29] - Epoch 92/500,it:37536, Train Loss: 1.7136e-01, Val Loss: 1.4438e-01, best model: 92, LR: 9.1876e-04, epoch time: 88.65, snr: 7.8515e+00, var(R): 3.0895e-08, var(L*R): 5.0490e-08, WD: 7.2169e-07
[2025-08-02 03:34:58] - Epoch 93/500,it:37944, Train Loss: 1.6435e-01, Val Loss: 1.7264e-01, best model: 92, LR: 9.1704e-04, epoch time: 88.64, snr: 2.1539e+00, var(R): 3.3678e-08, var(L*R): 6.1340e-08, WD: 7.2812e-07
[2025-08-02 03:36:26] - Epoch 94/500,it:38352, Train Loss: 1.6714e-01, Val Loss: 1.7155e-01, best model: 92, LR: 9.1530e-04, epoch time: 88.63, snr: 5.9080e+00, var(R): 3.6208e-08, var(L*R): 5.8250e-08, WD: 7.3182e-07
[2025-08-02 03:37:55] - Epoch 95/500,it:38760, Train Loss: 1.5722e-01, Val Loss: 2.0722e-01, best model: 92, LR: 9.1354e-04, epoch time: 88.49, snr: 4.0495e+00, var(R): 3.6185e-08, var(L*R): 5.9105e-08, WD: 7.3564e-07
[2025-08-02 03:39:23] - Epoch 96/500,it:39168, Train Loss: 1.6720e-01, Val Loss: 2.1294e-01, best model: 92, LR: 9.1177e-04, epoch time: 88.51, snr: 1.6255e+00, var(R): 1.1190e-07, var(L*R): 1.8054e-07, WD: 7.4233e-07
[2025-08-02 03:40:52] - Epoch 97/500,it:39576, Train Loss: 1.6842e-01, Val Loss: 1.5805e-01, best model: 92, LR: 9.0998e-04, epoch time: 88.55, snr: 1.3125e+00, var(R): 1.3135e-07, var(L*R): 2.3190e-07, WD: 7.4860e-07
[2025-08-02 03:42:21] - Epoch 98/500,it:39984, Train Loss: 1.5863e-01, Val Loss: 2.0816e-01, best model: 92, LR: 9.0817e-04, epoch time: 88.67, snr: 1.6884e+00, var(R): 3.4802e-08, var(L*R): 5.8765e-08, WD: 7.5357e-07
[2025-08-02 03:43:49] - Epoch 99/500,it:40392, Train Loss: 1.6559e-01, Val Loss: 1.5449e-01, best model: 92, LR: 9.0635e-04, epoch time: 88.52, snr: 3.2567e+00, var(R): 1.6405e-07, var(L*R): 2.5098e-07, WD: 7.5818e-07
[2025-08-02 03:45:18] - Epoch 100/500,it:40800, Train Loss: 1.5861e-01, Val Loss: 1.8084e-01, best model: 92, LR: 9.0451e-04, epoch time: 88.54, snr: 6.5673e+00, var(R): 5.1579e-08, var(L*R): 9.5762e-08, WD: 7.6730e-07
[2025-08-02 03:46:46] - Epoch 101/500,it:41208, Train Loss: 1.5873e-01, Val Loss: 2.1724e-01, best model: 92, LR: 9.0265e-04, epoch time: 88.66, snr: 7.6637e-01, var(R): 8.3460e-08, var(L*R): 1.4638e-07, WD: 7.7138e-07
[2025-08-02 03:48:15] - Epoch 102/500,it:41616, Train Loss: 1.6206e-01, Val Loss: 1.4636e-01, best model: 92, LR: 9.0078e-04, epoch time: 88.67, snr: 2.0419e+00, var(R): 1.0701e-07, var(L*R): 2.1108e-07, WD: 7.7396e-07
[2025-08-02 03:49:44] - Epoch 103/500,it:42024, Train Loss: 1.5705e-01, Val Loss: 1.7918e-01, best model: 92, LR: 8.9890e-04, epoch time: 88.55, snr: 5.4278e+00, var(R): 2.8491e-08, var(L*R): 4.8556e-08, WD: 7.8244e-07
[2025-08-02 03:51:12] - Epoch 104/500,it:42432, Train Loss: 1.5897e-01, Val Loss: 1.6333e-01, best model: 92, LR: 8.9700e-04, epoch time: 88.53, snr: 4.6673e+00, var(R): 3.4070e-08, var(L*R): 5.8524e-08, WD: 7.8490e-07
[2025-08-02 03:52:41] - Epoch 105/500,it:42840, Train Loss: 1.5943e-01, Val Loss: 1.4446e-01, best model: 92, LR: 8.9508e-04, epoch time: 88.61, snr: 2.3340e+00, var(R): 4.7704e-08, var(L*R): 8.1130e-08, WD: 7.9691e-07
[2025-08-02 03:54:10] - Epoch 106/500,it:43248, Train Loss: 1.6100e-01, Val Loss: 1.5274e-01, best model: 92, LR: 8.9314e-04, epoch time: 88.71, snr: 2.8946e+00, var(R): 2.0828e-08, var(L*R): 3.3885e-08, WD: 7.9638e-07
[2025-08-02 03:55:38] - Epoch 107/500,it:43656, Train Loss: 1.6467e-01, Val Loss: 1.6592e-01, best model: 92, LR: 8.9120e-04, epoch time: 88.50, snr: 3.7644e+00, var(R): 2.2645e-08, var(L*R): 4.2123e-08, WD: 7.9940e-07
[2025-08-02 03:57:07] - Epoch 108/500,it:44064, Train Loss: 1.4842e-01, Val Loss: 1.7364e-01, best model: 92, LR: 8.8923e-04, epoch time: 88.53, snr: 1.6252e+00, var(R): 4.6919e-08, var(L*R): 7.9172e-08, WD: 8.0855e-07
[2025-08-02 03:58:35] - Epoch 109/500,it:44472, Train Loss: 1.5097e-01, Val Loss: 1.4441e-01, best model: 92, LR: 8.8725e-04, epoch time: 88.59, snr: 1.8891e+00, var(R): 3.8192e-08, var(L*R): 7.2475e-08, WD: 8.1320e-07
[2025-08-02 04:00:04] - Epoch 110/500,it:44880, Train Loss: 1.5440e-01, Val Loss: 1.8113e-01, best model: 92, LR: 8.8526e-04, epoch time: 88.70, snr: 4.9811e+00, var(R): 2.4732e-08, var(L*R): 4.6169e-08, WD: 8.1501e-07
[2025-08-02 04:01:32] - Epoch 111/500,it:45288, Train Loss: 1.5944e-01, Val Loss: 2.3034e-01, best model: 92, LR: 8.8325e-04, epoch time: 88.47, snr: 1.5706e+00, var(R): 1.2315e-07, var(L*R): 2.0748e-07, WD: 8.2453e-07
[2025-08-02 04:03:01] - Epoch 112/500,it:45696, Train Loss: 1.5779e-01, Val Loss: 1.4663e-01, best model: 92, LR: 8.8122e-04, epoch time: 88.50, snr: 2.7362e+00, var(R): 2.0332e-07, var(L*R): 3.2669e-07, WD: 8.2958e-07
[2025-08-02 04:04:30] - Epoch 113/500,it:46104, Train Loss: 1.4855e-01, Val Loss: 1.4207e-01, best model: 113, LR: 8.7918e-04, epoch time: 88.71, snr: 1.5071e+00, var(R): 2.3865e-08, var(L*R): 4.0438e-08, WD: 8.3427e-07
[2025-08-02 04:05:58] - Epoch 114/500,it:46512, Train Loss: 1.5168e-01, Val Loss: 1.5073e-01, best model: 113, LR: 8.7713e-04, epoch time: 88.54, snr: 2.2375e+00, var(R): 1.4842e-08, var(L*R): 2.6988e-08, WD: 8.3784e-07
[2025-08-02 04:07:27] - Epoch 115/500,it:46920, Train Loss: 1.4911e-01, Val Loss: 1.5671e-01, best model: 113, LR: 8.7506e-04, epoch time: 88.66, snr: 1.6212e+00, var(R): 4.4594e-08, var(L*R): 7.5191e-08, WD: 8.4419e-07
[2025-08-02 04:08:55] - Epoch 116/500,it:47328, Train Loss: 1.5400e-01, Val Loss: 1.7161e-01, best model: 113, LR: 8.7297e-04, epoch time: 88.73, snr: 3.3512e+00, var(R): 4.0283e-08, var(L*R): 6.6083e-08, WD: 8.5322e-07
[2025-08-02 04:10:24] - Epoch 117/500,it:47736, Train Loss: 1.5449e-01, Val Loss: 1.8761e-01, best model: 113, LR: 8.7087e-04, epoch time: 88.92, snr: 1.6706e+00, var(R): 5.3757e-08, var(L*R): 8.7653e-08, WD: 8.5529e-07
[2025-08-02 04:11:53] - Epoch 118/500,it:48144, Train Loss: 1.5084e-01, Val Loss: 2.1223e-01, best model: 113, LR: 8.6876e-04, epoch time: 88.93, snr: 1.4396e+00, var(R): 9.6925e-08, var(L*R): 1.7855e-07, WD: 8.5945e-07
[2025-08-02 04:13:22] - Epoch 119/500,it:48552, Train Loss: 1.5458e-01, Val Loss: 1.7423e-01, best model: 113, LR: 8.6663e-04, epoch time: 88.84, snr: 2.4839e+00, var(R): 1.4215e-07, var(L*R): 2.2485e-07, WD: 8.6581e-07
[2025-08-02 04:14:51] - Epoch 120/500,it:48960, Train Loss: 1.4299e-01, Val Loss: 1.5349e-01, best model: 113, LR: 8.6448e-04, epoch time: 88.81, snr: 2.3086e+00, var(R): 3.3405e-08, var(L*R): 7.3830e-08, WD: 8.6838e-07
[2025-08-02 04:16:20] - Epoch 121/500,it:49368, Train Loss: 1.5083e-01, Val Loss: 1.5435e-01, best model: 113, LR: 8.6233e-04, epoch time: 88.88, snr: 3.8064e+00, var(R): 1.7149e-08, var(L*R): 3.9679e-08, WD: 8.7739e-07
[2025-08-02 04:17:49] - Epoch 122/500,it:49776, Train Loss: 1.4775e-01, Val Loss: 1.7674e-01, best model: 113, LR: 8.6015e-04, epoch time: 88.80, snr: 1.6004e+00, var(R): 2.7688e-08, var(L*R): 5.1865e-08, WD: 8.8490e-07
[2025-08-02 04:19:18] - Epoch 123/500,it:50184, Train Loss: 1.4815e-01, Val Loss: 1.8193e-01, best model: 113, LR: 8.5797e-04, epoch time: 88.86, snr: 3.8789e+00, var(R): 5.9666e-08, var(L*R): 9.5233e-08, WD: 8.8881e-07
[2025-08-02 04:20:46] - Epoch 124/500,it:50592, Train Loss: 1.4869e-01, Val Loss: 1.6601e-01, best model: 113, LR: 8.5577e-04, epoch time: 88.94, snr: 1.2952e+00, var(R): 7.7047e-08, var(L*R): 2.1326e-07, WD: 8.9054e-07
[2025-08-02 04:22:15] - Epoch 125/500,it:51000, Train Loss: 1.3963e-01, Val Loss: 1.7157e-01, best model: 113, LR: 8.5355e-04, epoch time: 88.94, snr: 4.1900e+00, var(R): 4.7312e-08, var(L*R): 8.4001e-08, WD: 8.9618e-07
[2025-08-02 04:23:44] - Epoch 126/500,it:51408, Train Loss: 1.4404e-01, Val Loss: 1.4523e-01, best model: 113, LR: 8.5132e-04, epoch time: 88.73, snr: 4.4370e+00, var(R): 6.5930e-08, var(L*R): 1.0509e-07, WD: 9.0437e-07
[2025-08-02 04:25:13] - Epoch 127/500,it:51816, Train Loss: 1.4077e-01, Val Loss: 1.4643e-01, best model: 113, LR: 8.4908e-04, epoch time: 88.80, snr: 1.6442e+00, var(R): 1.9963e-08, var(L*R): 3.7325e-08, WD: 9.1173e-07
[2025-08-02 04:26:42] - Epoch 128/500,it:52224, Train Loss: 1.4158e-01, Val Loss: 1.7055e-01, best model: 113, LR: 8.4683e-04, epoch time: 88.85, snr: 1.6107e+00, var(R): 2.4592e-08, var(L*R): 3.8537e-08, WD: 9.1671e-07
[2025-08-02 04:28:11] - Epoch 129/500,it:52632, Train Loss: 1.4286e-01, Val Loss: 2.0917e-01, best model: 113, LR: 8.4456e-04, epoch time: 88.89, snr: 2.5239e+00, var(R): 4.4696e-08, var(L*R): 6.7822e-08, WD: 9.1696e-07
[2025-08-02 04:29:39] - Epoch 130/500,it:53040, Train Loss: 1.4749e-01, Val Loss: 1.9220e-01, best model: 113, LR: 8.4227e-04, epoch time: 88.72, snr: 2.6666e+00, var(R): 1.6525e-07, var(L*R): 3.2312e-07, WD: 9.2498e-07
[2025-08-02 04:31:08] - Epoch 131/500,it:53448, Train Loss: 1.4890e-01, Val Loss: 1.5171e-01, best model: 113, LR: 8.3998e-04, epoch time: 88.86, snr: 4.1349e+00, var(R): 5.4108e-08, var(L*R): 8.4547e-08, WD: 9.3244e-07
[2025-08-02 04:32:37] - Epoch 132/500,it:53856, Train Loss: 1.3694e-01, Val Loss: 1.4675e-01, best model: 113, LR: 8.3767e-04, epoch time: 88.91, snr: 1.2803e+00, var(R): 2.4690e-08, var(L*R): 4.2409e-08, WD: 9.3686e-07
[2025-08-02 04:34:06] - Epoch 133/500,it:54264, Train Loss: 1.3690e-01, Val Loss: 1.5258e-01, best model: 113, LR: 8.3534e-04, epoch time: 88.99, snr: 4.8568e+00, var(R): 3.2917e-08, var(L*R): 7.5660e-08, WD: 9.3858e-07
[2025-08-02 04:35:35] - Epoch 134/500,it:54672, Train Loss: 1.3354e-01, Val Loss: 1.2390e-01, best model: 134, LR: 8.3301e-04, epoch time: 88.83, snr: 9.3997e-01, var(R): 1.8096e-08, var(L*R): 3.2355e-08, WD: 9.4457e-07
[2025-08-02 04:37:04] - Epoch 135/500,it:55080, Train Loss: 1.3870e-01, Val Loss: 1.2495e-01, best model: 134, LR: 8.3066e-04, epoch time: 88.79, snr: 2.2023e+00, var(R): 1.6567e-08, var(L*R): 3.0062e-08, WD: 9.4621e-07
[2025-08-02 04:38:33] - Epoch 136/500,it:55488, Train Loss: 1.3994e-01, Val Loss: 1.6940e-01, best model: 134, LR: 8.2829e-04, epoch time: 88.80, snr: 5.2037e+00, var(R): 1.7169e-08, var(L*R): 4.9847e-08, WD: 9.5114e-07
[2025-08-02 04:40:01] - Epoch 137/500,it:55896, Train Loss: 1.4052e-01, Val Loss: 1.4662e-01, best model: 134, LR: 8.2592e-04, epoch time: 88.77, snr: 2.3243e+00, var(R): 7.1354e-08, var(L*R): 1.2459e-07, WD: 9.5984e-07
[2025-08-02 04:41:30] - Epoch 138/500,it:56304, Train Loss: 1.2834e-01, Val Loss: 1.4038e-01, best model: 134, LR: 8.2353e-04, epoch time: 88.88, snr: 3.3085e+00, var(R): 1.7846e-08, var(L*R): 3.2080e-08, WD: 9.6139e-07
[2025-08-02 04:42:59] - Epoch 139/500,it:56712, Train Loss: 1.3208e-01, Val Loss: 1.2774e-01, best model: 134, LR: 8.2113e-04, epoch time: 88.78, snr: 3.4306e+00, var(R): 1.6710e-08, var(L*R): 4.4074e-08, WD: 9.6883e-07
[2025-08-02 04:44:28] - Epoch 140/500,it:57120, Train Loss: 1.3956e-01, Val Loss: 1.6489e-01, best model: 134, LR: 8.1871e-04, epoch time: 88.86, snr: 1.5207e+00, var(R): 2.3965e-08, var(L*R): 4.7767e-08, WD: 9.7295e-07
[2025-08-02 04:45:57] - Epoch 141/500,it:57528, Train Loss: 1.3746e-01, Val Loss: 1.4254e-01, best model: 134, LR: 8.1629e-04, epoch time: 88.78, snr: 1.7865e+00, var(R): 4.3743e-08, var(L*R): 9.3642e-08, WD: 9.7885e-07
[2025-08-02 04:47:26] - Epoch 142/500,it:57936, Train Loss: 1.4143e-01, Val Loss: 1.7768e-01, best model: 134, LR: 8.1385e-04, epoch time: 88.95, snr: 3.8533e+00, var(R): 2.8443e-08, var(L*R): 7.4179e-08, WD: 9.8610e-07
[2025-08-02 04:48:55] - Epoch 143/500,it:58344, Train Loss: 1.4353e-01, Val Loss: 1.6816e-01, best model: 134, LR: 8.1139e-04, epoch time: 88.96, snr: 2.1886e+00, var(R): 9.9868e-08, var(L*R): 1.8090e-07, WD: 9.8551e-07
[2025-08-02 04:50:24] - Epoch 144/500,it:58752, Train Loss: 1.4038e-01, Val Loss: 1.5016e-01, best model: 134, LR: 8.0893e-04, epoch time: 88.92, snr: 5.3483e+00, var(R): 4.0538e-08, var(L*R): 6.4644e-08, WD: 9.9082e-07
[2025-08-02 04:51:53] - Epoch 145/500,it:59160, Train Loss: 1.2746e-01, Val Loss: 1.1555e-01, best model: 145, LR: 8.0645e-04, epoch time: 89.03, snr: 1.5201e+00, var(R): 5.2917e-08, var(L*R): 1.0286e-07, WD: 1.0014e-06
[2025-08-02 04:53:22] - Epoch 146/500,it:59568, Train Loss: 1.3462e-01, Val Loss: 1.5934e-01, best model: 145, LR: 8.0397e-04, epoch time: 88.98, snr: 4.6544e+00, var(R): 1.1926e-08, var(L*R): 2.7256e-08, WD: 1.0035e-06
[2025-08-02 04:54:51] - Epoch 147/500,it:59976, Train Loss: 1.2860e-01, Val Loss: 1.5895e-01, best model: 145, LR: 8.0146e-04, epoch time: 88.97, snr: 1.1116e+00, var(R): 6.1213e-08, var(L*R): 1.1852e-07, WD: 1.0129e-06
[2025-08-02 04:56:20] - Epoch 148/500,it:60384, Train Loss: 1.2822e-01, Val Loss: 1.4966e-01, best model: 145, LR: 7.9895e-04, epoch time: 89.04, snr: 2.7173e+00, var(R): 3.5296e-08, var(L*R): 6.4199e-08, WD: 1.0156e-06
[2025-08-02 04:57:49] - Epoch 149/500,it:60792, Train Loss: 1.3052e-01, Val Loss: 1.3642e-01, best model: 145, LR: 7.9643e-04, epoch time: 88.94, snr: 9.8298e+00, var(R): 3.0987e-08, var(L*R): 6.3251e-08, WD: 1.0099e-06
[2025-08-02 04:59:18] - Epoch 150/500,it:61200, Train Loss: 1.3880e-01, Val Loss: 1.8544e-01, best model: 145, LR: 7.9389e-04, epoch time: 89.05, snr: 1.8424e+00, var(R): 1.8932e-08, var(L*R): 3.3066e-08, WD: 1.0211e-06
[2025-08-02 05:00:47] - Epoch 151/500,it:61608, Train Loss: 1.3668e-01, Val Loss: 1.3301e-01, best model: 145, LR: 7.9135e-04, epoch time: 89.18, snr: 2.0431e+00, var(R): 9.4115e-08, var(L*R): 1.8531e-07, WD: 1.0303e-06
[2025-08-02 05:02:16] - Epoch 152/500,it:62016, Train Loss: 1.2926e-01, Val Loss: 1.6413e-01, best model: 145, LR: 7.8879e-04, epoch time: 89.48, snr: 2.4095e+00, var(R): 1.7241e-08, var(L*R): 4.3212e-08, WD: 1.0343e-06
[2025-08-02 05:03:46] - Epoch 153/500,it:62424, Train Loss: 1.2209e-01, Val Loss: 1.5879e-01, best model: 145, LR: 7.8622e-04, epoch time: 89.41, snr: 3.4901e+00, var(R): 5.6127e-08, var(L*R): 1.0099e-07, WD: 1.0392e-06
[2025-08-02 05:05:15] - Epoch 154/500,it:62832, Train Loss: 1.2694e-01, Val Loss: 1.3434e-01, best model: 145, LR: 7.8363e-04, epoch time: 89.33, snr: 6.1662e+00, var(R): 3.1518e-08, var(L*R): 4.6409e-08, WD: 1.0409e-06
[2025-08-02 05:06:44] - Epoch 155/500,it:63240, Train Loss: 1.2381e-01, Val Loss: 1.8982e-01, best model: 145, LR: 7.8104e-04, epoch time: 89.18, snr: 9.0102e-01, var(R): 3.0359e-08, var(L*R): 6.6106e-08, WD: 1.0452e-06
[2025-08-02 05:08:13] - Epoch 156/500,it:63648, Train Loss: 1.2622e-01, Val Loss: 1.2819e-01, best model: 145, LR: 7.7844e-04, epoch time: 88.89, snr: 3.3183e+00, var(R): 1.0913e-07, var(L*R): 1.9160e-07, WD: 1.0508e-06
[2025-08-02 05:09:42] - Epoch 157/500,it:64056, Train Loss: 1.2842e-01, Val Loss: 1.6551e-01, best model: 145, LR: 7.7582e-04, epoch time: 88.74, snr: 3.5042e+00, var(R): 1.8182e-08, var(L*R): 3.0155e-08, WD: 1.0481e-06
[2025-08-02 05:11:11] - Epoch 158/500,it:64464, Train Loss: 1.2758e-01, Val Loss: 1.4575e-01, best model: 145, LR: 7.7320e-04, epoch time: 88.72, snr: 2.7290e+00, var(R): 7.4837e-08, var(L*R): 1.6583e-07, WD: 1.0638e-06
[2025-08-02 05:12:39] - Epoch 159/500,it:64872, Train Loss: 1.2975e-01, Val Loss: 1.4821e-01, best model: 145, LR: 7.7056e-04, epoch time: 88.79, snr: 4.8317e+00, var(R): 1.4119e-08, var(L*R): 6.8476e-08, WD: 1.0647e-06
[2025-08-02 05:14:08] - Epoch 160/500,it:65280, Train Loss: 1.2928e-01, Val Loss: 1.3385e-01, best model: 145, LR: 7.6791e-04, epoch time: 88.66, snr: 1.5050e+00, var(R): 4.7079e-08, var(L*R): 9.8339e-08, WD: 1.0744e-06
[2025-08-02 05:15:37] - Epoch 161/500,it:65688, Train Loss: 1.2280e-01, Val Loss: 1.3857e-01, best model: 145, LR: 7.6526e-04, epoch time: 88.61, snr: 9.8259e-01, var(R): 1.9189e-08, var(L*R): 5.2845e-08, WD: 1.0788e-06
[2025-08-02 05:17:05] - Epoch 162/500,it:66096, Train Loss: 1.2850e-01, Val Loss: 1.5860e-01, best model: 145, LR: 7.6259e-04, epoch time: 88.71, snr: 2.6303e+00, var(R): 2.6086e-08, var(L*R): 5.8092e-08, WD: 1.0796e-06
[2025-08-02 05:18:34] - Epoch 163/500,it:66504, Train Loss: 1.2647e-01, Val Loss: 1.3395e-01, best model: 145, LR: 7.5991e-04, epoch time: 88.73, snr: 1.4964e+00, var(R): 6.6376e-08, var(L*R): 1.3646e-07, WD: 1.0833e-06
[2025-08-02 05:20:03] - Epoch 164/500,it:66912, Train Loss: 1.2059e-01, Val Loss: 1.4266e-01, best model: 145, LR: 7.5722e-04, epoch time: 88.73, snr: 2.0327e+00, var(R): 1.6812e-08, var(L*R): 5.6880e-08, WD: 1.0887e-06
[2025-08-02 05:21:32] - Epoch 165/500,it:67320, Train Loss: 1.4616e-01, Val Loss: 1.6034e-01, best model: 145, LR: 7.5452e-04, epoch time: 88.74, snr: 3.9685e+00, var(R): 3.3426e-08, var(L*R): 5.7604e-08, WD: 1.0937e-06
[2025-08-02 05:23:00] - Epoch 166/500,it:67728, Train Loss: 1.2160e-01, Val Loss: 1.4408e-01, best model: 145, LR: 7.5181e-04, epoch time: 88.71, snr: 1.8220e+00, var(R): 5.5140e-08, var(L*R): 1.2682e-07, WD: 1.0967e-06
[2025-08-02 05:24:29] - Epoch 167/500,it:68136, Train Loss: 1.2728e-01, Val Loss: 1.0573e-01, best model: 167, LR: 7.4909e-04, epoch time: 88.77, snr: 1.4490e+00, var(R): 3.5890e-08, var(L*R): 8.8661e-08, WD: 1.1069e-06
[2025-08-02 05:25:58] - Epoch 168/500,it:68544, Train Loss: 1.1908e-01, Val Loss: 1.3411e-01, best model: 167, LR: 7.4636e-04, epoch time: 88.77, snr: 4.2502e+00, var(R): 9.4858e-09, var(L*R): 2.1304e-08, WD: 1.1073e-06
[2025-08-02 05:27:27] - Epoch 169/500,it:68952, Train Loss: 1.2491e-01, Val Loss: 1.3925e-01, best model: 167, LR: 7.4363e-04, epoch time: 88.75, snr: 1.0781e+00, var(R): 1.8632e-08, var(L*R): 4.2963e-08, WD: 1.1104e-06
[2025-08-02 05:28:55] - Epoch 170/500,it:69360, Train Loss: 1.1867e-01, Val Loss: 1.7250e-01, best model: 167, LR: 7.4088e-04, epoch time: 88.64, snr: 1.2429e+00, var(R): 4.4176e-08, var(L*R): 9.8319e-08, WD: 1.1157e-06
[2025-08-02 05:30:24] - Epoch 171/500,it:69768, Train Loss: 1.2042e-01, Val Loss: 1.4697e-01, best model: 167, LR: 7.3812e-04, epoch time: 88.67, snr: 1.6245e+00, var(R): 1.1967e-07, var(L*R): 2.6917e-07, WD: 1.1213e-06
[2025-08-02 05:31:53] - Epoch 172/500,it:70176, Train Loss: 1.2622e-01, Val Loss: 1.2295e-01, best model: 167, LR: 7.3535e-04, epoch time: 88.61, snr: 1.4133e+00, var(R): 3.0102e-08, var(L*R): 5.4298e-08, WD: 1.1223e-06
[2025-08-02 05:33:21] - Epoch 173/500,it:70584, Train Loss: 1.2485e-01, Val Loss: 1.7401e-01, best model: 167, LR: 7.3258e-04, epoch time: 88.71, snr: 1.6928e+00, var(R): 1.8563e-08, var(L*R): 4.2146e-08, WD: 1.1272e-06
[2025-08-02 05:34:50] - Epoch 174/500,it:70992, Train Loss: 1.2357e-01, Val Loss: 1.4466e-01, best model: 167, LR: 7.2979e-04, epoch time: 88.72, snr: 1.4594e+00, var(R): 6.1325e-08, var(L*R): 1.7319e-07, WD: 1.1310e-06
[2025-08-02 05:36:19] - Epoch 175/500,it:71400, Train Loss: 1.1843e-01, Val Loss: 1.2975e-01, best model: 167, LR: 7.2700e-04, epoch time: 88.71, snr: 1.0244e+00, var(R): 4.3826e-08, var(L*R): 8.4681e-08, WD: 1.1348e-06
[2025-08-02 05:37:47] - Epoch 176/500,it:71808, Train Loss: 1.2134e-01, Val Loss: 1.6466e-01, best model: 167, LR: 7.2419e-04, epoch time: 88.62, snr: 3.6780e+00, var(R): 2.2795e-08, var(L*R): 4.9021e-08, WD: 1.1426e-06
[2025-08-02 05:39:16] - Epoch 177/500,it:72216, Train Loss: 1.1320e-01, Val Loss: 1.2244e-01, best model: 167, LR: 7.2138e-04, epoch time: 88.74, snr: 1.3769e+00, var(R): 8.2903e-08, var(L*R): 2.2305e-07, WD: 1.1492e-06
[2025-08-02 05:40:45] - Epoch 178/500,it:72624, Train Loss: 1.1702e-01, Val Loss: 1.2532e-01, best model: 167, LR: 7.1856e-04, epoch time: 88.73, snr: 2.6463e+00, var(R): 1.3212e-08, var(L*R): 2.8514e-08, WD: 1.1488e-06
[2025-08-02 05:42:13] - Epoch 179/500,it:73032, Train Loss: 1.1896e-01, Val Loss: 1.9184e-01, best model: 167, LR: 7.1573e-04, epoch time: 88.56, snr: 1.8409e+00, var(R): 2.9912e-08, var(L*R): 7.9429e-08, WD: 1.1598e-06
[2025-08-02 05:43:42] - Epoch 180/500,it:73440, Train Loss: 1.2561e-01, Val Loss: 1.2666e-01, best model: 167, LR: 7.1289e-04, epoch time: 88.81, snr: 3.3894e+00, var(R): 1.3238e-07, var(L*R): 3.0873e-07, WD: 1.1582e-06
[2025-08-02 05:45:11] - Epoch 181/500,it:73848, Train Loss: 1.1328e-01, Val Loss: 1.1923e-01, best model: 167, LR: 7.1004e-04, epoch time: 88.73, snr: 2.5851e+00, var(R): 3.0349e-08, var(L*R): 6.6557e-08, WD: 1.1670e-06
[2025-08-02 05:46:40] - Epoch 182/500,it:74256, Train Loss: 1.1826e-01, Val Loss: 1.3848e-01, best model: 167, LR: 7.0719e-04, epoch time: 88.63, snr: 1.4732e+00, var(R): 2.0574e-08, var(L*R): 8.2212e-08, WD: 1.1668e-06
[2025-08-02 05:48:08] - Epoch 183/500,it:74664, Train Loss: 1.1812e-01, Val Loss: 1.2645e-01, best model: 167, LR: 7.0432e-04, epoch time: 88.53, snr: 2.6594e+00, var(R): 2.6504e-08, var(L*R): 6.2982e-08, WD: 1.1759e-06
[2025-08-02 05:49:37] - Epoch 184/500,it:75072, Train Loss: 1.1562e-01, Val Loss: 1.4613e-01, best model: 167, LR: 7.0145e-04, epoch time: 88.70, snr: 1.9341e+00, var(R): 1.7983e-08, var(L*R): 5.1226e-08, WD: 1.1773e-06
[2025-08-02 05:51:06] - Epoch 185/500,it:75480, Train Loss: 1.2468e-01, Val Loss: 1.4559e-01, best model: 167, LR: 6.9857e-04, epoch time: 88.71, snr: 1.0405e+00, var(R): 5.1225e-08, var(L*R): 1.3248e-07, WD: 1.1744e-06
[2025-08-02 05:52:34] - Epoch 186/500,it:75888, Train Loss: 1.1101e-01, Val Loss: 1.0535e-01, best model: 186, LR: 6.9569e-04, epoch time: 88.72, snr: 1.2972e+00, var(R): 5.9937e-08, var(L*R): 1.6704e-07, WD: 1.1909e-06
[2025-08-02 05:54:03] - Epoch 187/500,it:76296, Train Loss: 1.1394e-01, Val Loss: 1.1460e-01, best model: 186, LR: 6.9279e-04, epoch time: 88.59, snr: 2.2071e+00, var(R): 1.4496e-08, var(L*R): 3.4116e-08, WD: 1.1913e-06
[2025-08-02 05:55:32] - Epoch 188/500,it:76704, Train Loss: 1.1103e-01, Val Loss: 1.1437e-01, best model: 186, LR: 6.8989e-04, epoch time: 88.76, snr: 1.5636e+00, var(R): 1.1574e-08, var(L*R): 2.5839e-08, WD: 1.1885e-06
[2025-08-02 05:57:00] - Epoch 189/500,it:77112, Train Loss: 1.1880e-01, Val Loss: 1.2231e-01, best model: 186, LR: 6.8698e-04, epoch time: 88.67, snr: 2.7716e+00, var(R): 1.4895e-08, var(L*R): 2.8719e-08, WD: 1.2017e-06
[2025-08-02 05:58:29] - Epoch 190/500,it:77520, Train Loss: 1.0949e-01, Val Loss: 1.3704e-01, best model: 186, LR: 6.8406e-04, epoch time: 88.66, snr: 1.4151e+00, var(R): 1.5959e-08, var(L*R): 3.6196e-08, WD: 1.1988e-06
[2025-08-02 05:59:58] - Epoch 191/500,it:77928, Train Loss: 1.1437e-01, Val Loss: 1.2700e-01, best model: 186, LR: 6.8114e-04, epoch time: 88.53, snr: 2.1881e+00, var(R): 3.5544e-08, var(L*R): 9.9040e-08, WD: 1.2087e-06
[2025-08-02 06:01:26] - Epoch 192/500,it:78336, Train Loss: 1.0900e-01, Val Loss: 1.3668e-01, best model: 186, LR: 6.7821e-04, epoch time: 88.81, snr: 1.6676e+00, var(R): 1.6438e-08, var(L*R): 4.7824e-08, WD: 1.2148e-06
[2025-08-02 06:02:55] - Epoch 193/500,it:78744, Train Loss: 1.1167e-01, Val Loss: 1.1439e-01, best model: 186, LR: 6.7527e-04, epoch time: 88.67, snr: 1.9901e+00, var(R): 4.1335e-08, var(L*R): 9.6180e-08, WD: 1.2089e-06
[2025-08-02 06:04:24] - Epoch 194/500,it:79152, Train Loss: 1.1276e-01, Val Loss: 1.2800e-01, best model: 186, LR: 6.7232e-04, epoch time: 88.57, snr: 1.5356e+00, var(R): 9.5580e-09, var(L*R): 2.3440e-08, WD: 1.2174e-06
[2025-08-02 06:05:52] - Epoch 195/500,it:79560, Train Loss: 1.1778e-01, Val Loss: 1.2821e-01, best model: 186, LR: 6.6937e-04, epoch time: 88.56, snr: 2.9719e+00, var(R): 1.9949e-08, var(L*R): 4.4589e-08, WD: 1.2201e-06
[2025-08-02 06:07:21] - Epoch 196/500,it:79968, Train Loss: 1.1013e-01, Val Loss: 1.2189e-01, best model: 186, LR: 6.6641e-04, epoch time: 88.76, snr: 1.4105e+00, var(R): 2.7010e-08, var(L*R): 7.1980e-08, WD: 1.2284e-06
[2025-08-02 06:08:50] - Epoch 197/500,it:80376, Train Loss: 1.0869e-01, Val Loss: 1.6072e-01, best model: 186, LR: 6.6344e-04, epoch time: 88.68, snr: 2.2641e+00, var(R): 1.9639e-08, var(L*R): 3.5629e-08, WD: 1.2331e-06
[2025-08-02 06:10:18] - Epoch 198/500,it:80784, Train Loss: 1.1341e-01, Val Loss: 1.1494e-01, best model: 186, LR: 6.6047e-04, epoch time: 88.63, snr: 1.2702e+00, var(R): 6.2092e-08, var(L*R): 1.5823e-07, WD: 1.2385e-06
[2025-08-02 06:11:47] - Epoch 199/500,it:81192, Train Loss: 1.0956e-01, Val Loss: 1.0847e-01, best model: 186, LR: 6.5749e-04, epoch time: 88.46, snr: 2.2221e+00, var(R): 1.3256e-08, var(L*R): 3.2099e-08, WD: 1.2317e-06
[2025-08-02 06:13:15] - Epoch 200/500,it:81600, Train Loss: 1.1130e-01, Val Loss: 1.2344e-01, best model: 186, LR: 6.5451e-04, epoch time: 88.66, snr: 6.2401e+00, var(R): 1.0553e-08, var(L*R): 3.2660e-08, WD: 1.2334e-06
[2025-08-02 06:14:44] - Epoch 201/500,it:82008, Train Loss: 1.0229e-01, Val Loss: 1.0814e-01, best model: 186, LR: 6.5152e-04, epoch time: 88.61, snr: 2.0887e+00, var(R): 2.0223e-08, var(L*R): 5.9947e-08, WD: 1.2414e-06
[2025-08-02 06:16:13] - Epoch 202/500,it:82416, Train Loss: 1.0783e-01, Val Loss: 1.1190e-01, best model: 186, LR: 6.4852e-04, epoch time: 88.56, snr: 2.4769e+00, var(R): 1.4765e-08, var(L*R): 4.3170e-08, WD: 1.2468e-06
[2025-08-02 06:17:41] - Epoch 203/500,it:82824, Train Loss: 1.0519e-01, Val Loss: 1.5284e-01, best model: 186, LR: 6.4552e-04, epoch time: 88.64, snr: 5.2493e+00, var(R): 1.3288e-08, var(L*R): 3.2155e-08, WD: 1.2505e-06
[2025-08-02 06:19:10] - Epoch 204/500,it:83232, Train Loss: 1.0787e-01, Val Loss: 1.3379e-01, best model: 186, LR: 6.4251e-04, epoch time: 88.64, snr: 1.5871e+00, var(R): 5.4234e-08, var(L*R): 1.6682e-07, WD: 1.2577e-06
[2025-08-02 06:20:38] - Epoch 205/500,it:83640, Train Loss: 1.0944e-01, Val Loss: 1.2008e-01, best model: 186, LR: 6.3950e-04, epoch time: 88.49, snr: 2.6379e+00, var(R): 2.5755e-08, var(L*R): 7.7034e-08, WD: 1.2601e-06
[2025-08-02 06:22:07] - Epoch 206/500,it:84048, Train Loss: 1.0896e-01, Val Loss: 1.1391e-01, best model: 186, LR: 6.3648e-04, epoch time: 88.29, snr: 1.3100e+00, var(R): 2.7400e-08, var(L*R): 1.0004e-07, WD: 1.2622e-06
[2025-08-02 06:23:35] - Epoch 207/500,it:84456, Train Loss: 1.0988e-01, Val Loss: 1.0158e-01, best model: 207, LR: 6.3345e-04, epoch time: 88.56, snr: 1.8850e+00, var(R): 1.8450e-08, var(L*R): 5.1415e-08, WD: 1.2736e-06
[2025-08-02 06:25:04] - Epoch 208/500,it:84864, Train Loss: 1.0292e-01, Val Loss: 1.2857e-01, best model: 207, LR: 6.3042e-04, epoch time: 88.50, snr: 2.9030e+00, var(R): 8.6919e-09, var(L*R): 2.6443e-08, WD: 1.2695e-06
[2025-08-02 06:26:32] - Epoch 209/500,it:85272, Train Loss: 1.0522e-01, Val Loss: 1.3272e-01, best model: 207, LR: 6.2739e-04, epoch time: 88.43, snr: 1.6571e+00, var(R): 2.8433e-08, var(L*R): 6.3917e-08, WD: 1.2730e-06
[2025-08-02 06:28:00] - Epoch 210/500,it:85680, Train Loss: 1.0380e-01, Val Loss: 1.1763e-01, best model: 207, LR: 6.2434e-04, epoch time: 88.21, snr: 1.2263e+00, var(R): 2.8705e-08, var(L*R): 1.0196e-07, WD: 1.2782e-06
[2025-08-02 06:29:29] - Epoch 211/500,it:86088, Train Loss: 1.0650e-01, Val Loss: 1.3189e-01, best model: 207, LR: 6.2130e-04, epoch time: 88.37, snr: 3.7523e+00, var(R): 1.3371e-08, var(L*R): 3.6940e-08, WD: 1.2795e-06
[2025-08-02 06:30:57] - Epoch 212/500,it:86496, Train Loss: 1.0863e-01, Val Loss: 1.1792e-01, best model: 207, LR: 6.1825e-04, epoch time: 88.48, snr: 1.4399e+00, var(R): 3.3259e-08, var(L*R): 1.3980e-07, WD: 1.2828e-06
[2025-08-02 06:32:26] - Epoch 213/500,it:86904, Train Loss: 1.0036e-01, Val Loss: 9.9125e-02, best model: 213, LR: 6.1519e-04, epoch time: 88.50, snr: 4.0445e+00, var(R): 1.1947e-08, var(L*R): 2.8694e-08, WD: 1.2838e-06
[2025-08-02 06:33:54] - Epoch 214/500,it:87312, Train Loss: 1.0153e-01, Val Loss: 1.3911e-01, best model: 213, LR: 6.1214e-04, epoch time: 88.14, snr: 3.3980e+00, var(R): 9.5284e-09, var(L*R): 2.6661e-08, WD: 1.2910e-06
[2025-08-02 06:35:22] - Epoch 215/500,it:87720, Train Loss: 1.0225e-01, Val Loss: 1.2677e-01, best model: 213, LR: 6.0907e-04, epoch time: 88.24, snr: 1.4384e+00, var(R): 2.8993e-08, var(L*R): 1.4116e-07, WD: 1.2948e-06
[2025-08-02 06:36:50] - Epoch 216/500,it:88128, Train Loss: 1.1098e-01, Val Loss: 1.1857e-01, best model: 213, LR: 6.0600e-04, epoch time: 88.29, snr: 3.2822e+00, var(R): 2.8308e-08, var(L*R): 5.3561e-08, WD: 1.2994e-06
[2025-08-02 06:38:19] - Epoch 217/500,it:88536, Train Loss: 9.9720e-02, Val Loss: 1.0565e-01, best model: 213, LR: 6.0293e-04, epoch time: 88.28, snr: 3.3543e+00, var(R): 3.2075e-08, var(L*R): 1.4722e-07, WD: 1.3028e-06
[2025-08-02 06:39:47] - Epoch 218/500,it:88944, Train Loss: 9.7408e-02, Val Loss: 9.1561e-02, best model: 218, LR: 5.9985e-04, epoch time: 88.20, snr: 1.5321e+00, var(R): 1.2687e-08, var(L*R): 4.2366e-08, WD: 1.3083e-06
[2025-08-02 06:41:15] - Epoch 219/500,it:89352, Train Loss: 1.0433e-01, Val Loss: 9.6245e-02, best model: 218, LR: 5.9677e-04, epoch time: 88.17, snr: 1.9735e+00, var(R): 8.3247e-09, var(L*R): 2.1927e-08, WD: 1.3142e-06
[2025-08-02 06:42:43] - Epoch 220/500,it:89760, Train Loss: 1.0488e-01, Val Loss: 1.0422e-01, best model: 218, LR: 5.9369e-04, epoch time: 88.28, snr: 4.2632e+00, var(R): 8.4568e-09, var(L*R): 2.3889e-08, WD: 1.3106e-06
[2025-08-02 06:44:11] - Epoch 221/500,it:90168, Train Loss: 9.9927e-02, Val Loss: 1.3577e-01, best model: 218, LR: 5.9060e-04, epoch time: 88.05, snr: 2.9715e+00, var(R): 1.1510e-08, var(L*R): 4.0599e-08, WD: 1.3233e-06
[2025-08-02 06:45:40] - Epoch 222/500,it:90576, Train Loss: 9.8989e-02, Val Loss: 1.1137e-01, best model: 218, LR: 5.8751e-04, epoch time: 88.07, snr: 1.6789e+00, var(R): 3.4227e-08, var(L*R): 2.0974e-07, WD: 1.3136e-06
[2025-08-02 06:47:08] - Epoch 223/500,it:90984, Train Loss: 1.0480e-01, Val Loss: 1.0504e-01, best model: 218, LR: 5.8442e-04, epoch time: 88.13, snr: 2.7554e+00, var(R): 1.4700e-08, var(L*R): 3.7555e-08, WD: 1.3233e-06
[2025-08-02 06:48:36] - Epoch 224/500,it:91392, Train Loss: 1.0155e-01, Val Loss: 9.7781e-02, best model: 218, LR: 5.8132e-04, epoch time: 88.04, snr: 2.4415e+00, var(R): 1.4572e-08, var(L*R): 4.7465e-08, WD: 1.3320e-06
[2025-08-02 06:50:04] - Epoch 225/500,it:91800, Train Loss: 9.9912e-02, Val Loss: 1.1103e-01, best model: 218, LR: 5.7822e-04, epoch time: 87.96, snr: 3.8611e+00, var(R): 9.6545e-09, var(L*R): 3.3822e-08, WD: 1.3309e-06
[2025-08-02 06:51:32] - Epoch 226/500,it:92208, Train Loss: 9.6212e-02, Val Loss: 1.0589e-01, best model: 218, LR: 5.7511e-04, epoch time: 88.02, snr: 4.6755e+00, var(R): 1.0766e-08, var(L*R): 3.2013e-08, WD: 1.3386e-06
[2025-08-02 06:53:00] - Epoch 227/500,it:92616, Train Loss: 9.5178e-02, Val Loss: 1.0482e-01, best model: 218, LR: 5.7201e-04, epoch time: 88.09, snr: 1.2956e+00, var(R): 1.6178e-08, var(L*R): 3.6464e-08, WD: 1.3378e-06
[2025-08-02 06:54:28] - Epoch 228/500,it:93024, Train Loss: 9.8895e-02, Val Loss: 1.0471e-01, best model: 218, LR: 5.6890e-04, epoch time: 87.96, snr: 1.5619e+00, var(R): 1.5944e-08, var(L*R): 5.8941e-08, WD: 1.3408e-06
[2025-08-02 06:55:55] - Epoch 229/500,it:93432, Train Loss: 1.0249e-01, Val Loss: 1.0152e-01, best model: 218, LR: 5.6578e-04, epoch time: 87.77, snr: 5.8754e+00, var(R): 8.9598e-09, var(L*R): 3.0966e-08, WD: 1.3441e-06
[2025-08-02 06:57:23] - Epoch 230/500,it:93840, Train Loss: 9.3360e-02, Val Loss: 1.1262e-01, best model: 218, LR: 5.6267e-04, epoch time: 87.95, snr: 3.3783e+00, var(R): 1.6177e-08, var(L*R): 5.1088e-08, WD: 1.3525e-06
[2025-08-02 06:58:51] - Epoch 231/500,it:94248, Train Loss: 9.6603e-02, Val Loss: 1.2658e-01, best model: 218, LR: 5.5955e-04, epoch time: 87.78, snr: 1.3716e+00, var(R): 1.8265e-08, var(L*R): 7.1898e-08, WD: 1.3527e-06
[2025-08-02 07:00:19] - Epoch 232/500,it:94656, Train Loss: 9.5143e-02, Val Loss: 1.1117e-01, best model: 218, LR: 5.5643e-04, epoch time: 87.92, snr: 3.6305e+00, var(R): 2.6518e-08, var(L*R): 6.1945e-08, WD: 1.3497e-06
[2025-08-02 07:01:47] - Epoch 233/500,it:95064, Train Loss: 9.4256e-02, Val Loss: 1.4242e-01, best model: 218, LR: 5.5331e-04, epoch time: 87.78, snr: 1.2908e+00, var(R): 1.7089e-08, var(L*R): 4.7550e-08, WD: 1.3540e-06
[2025-08-02 07:03:15] - Epoch 234/500,it:95472, Train Loss: 9.9287e-02, Val Loss: 1.1392e-01, best model: 218, LR: 5.5018e-04, epoch time: 87.79, snr: 1.3170e+00, var(R): 4.6481e-08, var(L*R): 1.7451e-07, WD: 1.3645e-06
[2025-08-02 07:04:43] - Epoch 235/500,it:95880, Train Loss: 9.6351e-02, Val Loss: 1.1056e-01, best model: 218, LR: 5.4705e-04, epoch time: 87.78, snr: 2.7504e+00, var(R): 1.8425e-08, var(L*R): 6.8365e-08, WD: 1.3641e-06
[2025-08-02 07:06:10] - Epoch 236/500,it:96288, Train Loss: 9.3840e-02, Val Loss: 9.1792e-02, best model: 218, LR: 5.4393e-04, epoch time: 87.70, snr: 5.2228e+00, var(R): 1.2597e-08, var(L*R): 3.9341e-08, WD: 1.3708e-06
[2025-08-02 07:07:38] - Epoch 237/500,it:96696, Train Loss: 9.4487e-02, Val Loss: 9.6113e-02, best model: 218, LR: 5.4080e-04, epoch time: 87.64, snr: 4.9608e+00, var(R): 1.1735e-08, var(L*R): 2.8149e-08, WD: 1.3687e-06
[2025-08-02 07:09:06] - Epoch 238/500,it:97104, Train Loss: 9.0495e-02, Val Loss: 1.0162e-01, best model: 218, LR: 5.3766e-04, epoch time: 87.71, snr: 2.8385e+00, var(R): 9.4756e-09, var(L*R): 3.5022e-08, WD: 1.3656e-06
[2025-08-02 07:10:33] - Epoch 239/500,it:97512, Train Loss: 9.3801e-02, Val Loss: 1.0544e-01, best model: 218, LR: 5.3453e-04, epoch time: 87.70, snr: 7.1909e+00, var(R): 1.1329e-08, var(L*R): 3.7310e-08, WD: 1.3762e-06
[2025-08-02 07:12:01] - Epoch 240/500,it:97920, Train Loss: 9.3201e-02, Val Loss: 1.3721e-01, best model: 218, LR: 5.3140e-04, epoch time: 87.55, snr: 2.3574e+00, var(R): 1.8104e-08, var(L*R): 6.3958e-08, WD: 1.3820e-06
[2025-08-02 07:13:28] - Epoch 241/500,it:98328, Train Loss: 9.5094e-02, Val Loss: 1.0418e-01, best model: 218, LR: 5.2826e-04, epoch time: 87.47, snr: 2.0275e+00, var(R): 4.2307e-08, var(L*R): 1.4222e-07, WD: 1.3813e-06
[2025-08-02 07:14:56] - Epoch 242/500,it:98736, Train Loss: 9.1931e-02, Val Loss: 9.8369e-02, best model: 218, LR: 5.2512e-04, epoch time: 87.56, snr: 2.7910e+00, var(R): 1.5235e-08, var(L*R): 3.6363e-08, WD: 1.3814e-06
[2025-08-02 07:16:23] - Epoch 243/500,it:99144, Train Loss: 9.2306e-02, Val Loss: 9.8175e-02, best model: 218, LR: 5.2198e-04, epoch time: 87.51, snr: 1.8476e+00, var(R): 1.2096e-08, var(L*R): 5.1252e-08, WD: 1.3894e-06
[2025-08-02 07:17:51] - Epoch 244/500,it:99552, Train Loss: 9.1753e-02, Val Loss: 1.0470e-01, best model: 218, LR: 5.1885e-04, epoch time: 87.34, snr: 7.0358e+00, var(R): 9.7711e-09, var(L*R): 3.1582e-08, WD: 1.3923e-06
[2025-08-02 07:19:18] - Epoch 245/500,it:99960, Train Loss: 9.2665e-02, Val Loss: 1.1369e-01, best model: 218, LR: 5.1571e-04, epoch time: 87.51, snr: 2.5939e+00, var(R): 1.5688e-08, var(L*R): 4.8386e-08, WD: 1.3985e-06
[2025-08-02 07:20:46] - Epoch 246/500,it:100368, Train Loss: 9.2724e-02, Val Loss: 8.7664e-02, best model: 246, LR: 5.1257e-04, epoch time: 87.63, snr: 1.9035e+00, var(R): 2.7335e-08, var(L*R): 1.0484e-07, WD: 1.3906e-06
[2025-08-02 07:22:13] - Epoch 247/500,it:100776, Train Loss: 8.6444e-02, Val Loss: 1.0893e-01, best model: 246, LR: 5.0942e-04, epoch time: 87.55, snr: 4.1302e+00, var(R): 6.2322e-09, var(L*R): 2.7282e-08, WD: 1.3966e-06
[2025-08-02 07:23:41] - Epoch 248/500,it:101184, Train Loss: 9.4345e-02, Val Loss: 1.0785e-01, best model: 246, LR: 5.0628e-04, epoch time: 87.40, snr: 2.1911e+00, var(R): 1.4587e-08, var(L*R): 5.0667e-08, WD: 1.4018e-06
[2025-08-02 07:25:08] - Epoch 249/500,it:101592, Train Loss: 9.0349e-02, Val Loss: 9.8799e-02, best model: 246, LR: 5.0314e-04, epoch time: 87.49, snr: 3.2014e+00, var(R): 1.5296e-08, var(L*R): 5.0880e-08, WD: 1.4020e-06
[2025-08-02 07:26:36] - Epoch 250/500,it:102000, Train Loss: 8.9532e-02, Val Loss: 8.5584e-02, best model: 250, LR: 5.0000e-04, epoch time: 87.60, snr: 2.8929e+00, var(R): 1.2074e-08, var(L*R): 3.5744e-08, WD: 1.4033e-06
[2025-08-02 07:28:03] - Epoch 251/500,it:102408, Train Loss: 9.3483e-02, Val Loss: 1.0652e-01, best model: 250, LR: 4.9686e-04, epoch time: 87.56, snr: 1.8483e+00, var(R): 7.9613e-09, var(L*R): 3.5095e-08, WD: 1.4030e-06
[2025-08-02 07:29:31] - Epoch 252/500,it:102816, Train Loss: 9.0416e-02, Val Loss: 1.3938e-01, best model: 250, LR: 4.9372e-04, epoch time: 87.39, snr: 3.6923e+00, var(R): 1.9317e-08, var(L*R): 7.4772e-08, WD: 1.4223e-06
[2025-08-02 07:30:58] - Epoch 253/500,it:103224, Train Loss: 8.9387e-02, Val Loss: 1.0902e-01, best model: 250, LR: 4.9058e-04, epoch time: 87.50, snr: 2.6645e+00, var(R): 4.5038e-08, var(L*R): 1.5656e-07, WD: 1.4251e-06
[2025-08-02 07:32:26] - Epoch 254/500,it:103632, Train Loss: 8.6231e-02, Val Loss: 8.9954e-02, best model: 250, LR: 4.8743e-04, epoch time: 87.65, snr: 1.9657e+00, var(R): 2.1648e-08, var(L*R): 8.1403e-08, WD: 1.4288e-06
[2025-08-02 07:33:54] - Epoch 255/500,it:104040, Train Loss: 9.1860e-02, Val Loss: 9.2495e-02, best model: 250, LR: 4.8429e-04, epoch time: 87.50, snr: 3.9830e+00, var(R): 1.3303e-08, var(L*R): 3.4132e-08, WD: 1.4216e-06
[2025-08-02 07:35:21] - Epoch 256/500,it:104448, Train Loss: 8.7773e-02, Val Loss: 1.0167e-01, best model: 250, LR: 4.8115e-04, epoch time: 87.40, snr: 2.3446e+00, var(R): 8.2339e-09, var(L*R): 2.9984e-08, WD: 1.4303e-06
[2025-08-02 07:36:48] - Epoch 257/500,it:104856, Train Loss: 8.7844e-02, Val Loss: 1.6226e-01, best model: 250, LR: 4.7802e-04, epoch time: 87.52, snr: 3.1644e+00, var(R): 1.5667e-08, var(L*R): 5.6315e-08, WD: 1.4200e-06
[2025-08-02 07:38:16] - Epoch 258/500,it:105264, Train Loss: 8.7937e-02, Val Loss: 8.0894e-02, best model: 258, LR: 4.7488e-04, epoch time: 87.73, snr: 2.9188e+00, var(R): 7.2162e-08, var(L*R): 2.5744e-07, WD: 1.4287e-06
[2025-08-02 07:39:44] - Epoch 259/500,it:105672, Train Loss: 8.6224e-02, Val Loss: 1.2532e-01, best model: 258, LR: 4.7174e-04, epoch time: 87.47, snr: 3.9971e+00, var(R): 7.3539e-09, var(L*R): 2.9003e-08, WD: 1.4274e-06
[2025-08-02 07:41:11] - Epoch 260/500,it:106080, Train Loss: 8.8337e-02, Val Loss: 1.1923e-01, best model: 258, LR: 4.6860e-04, epoch time: 87.39, snr: 2.4982e+00, var(R): 3.2471e-08, var(L*R): 1.4062e-07, WD: 1.4309e-06
[2025-08-02 07:42:39] - Epoch 261/500,it:106488, Train Loss: 8.9222e-02, Val Loss: 9.4329e-02, best model: 258, LR: 4.6547e-04, epoch time: 87.55, snr: 2.3653e+00, var(R): 3.2079e-08, var(L*R): 1.0182e-07, WD: 1.4473e-06
[2025-08-02 07:44:06] - Epoch 262/500,it:106896, Train Loss: 8.4353e-02, Val Loss: 8.8777e-02, best model: 258, LR: 4.6234e-04, epoch time: 87.54, snr: 2.5840e+00, var(R): 1.3705e-08, var(L*R): 4.7903e-08, WD: 1.4431e-06
[2025-08-02 07:45:34] - Epoch 263/500,it:107304, Train Loss: 8.1296e-02, Val Loss: 7.7464e-02, best model: 263, LR: 4.5920e-04, epoch time: 87.63, snr: 4.2095e+00, var(R): 1.1514e-08, var(L*R): 3.2737e-08, WD: 1.4459e-06
[2025-08-02 07:47:01] - Epoch 264/500,it:107712, Train Loss: 9.1028e-02, Val Loss: 1.3192e-01, best model: 263, LR: 4.5607e-04, epoch time: 87.41, snr: 6.9364e+00, var(R): 8.5386e-09, var(L*R): 3.0300e-08, WD: 1.4429e-06
[2025-08-02 07:48:29] - Epoch 265/500,it:108120, Train Loss: 8.7235e-02, Val Loss: 9.4482e-02, best model: 263, LR: 4.5295e-04, epoch time: 87.61, snr: 2.5272e+00, var(R): 3.8451e-08, var(L*R): 1.5445e-07, WD: 1.4469e-06
[2025-08-02 07:49:56] - Epoch 266/500,it:108528, Train Loss: 8.2022e-02, Val Loss: 8.6242e-02, best model: 263, LR: 4.4982e-04, epoch time: 87.60, snr: 3.0552e+00, var(R): 1.4088e-08, var(L*R): 4.8599e-08, WD: 1.4545e-06
[2025-08-02 07:51:24] - Epoch 267/500,it:108936, Train Loss: 7.9324e-02, Val Loss: 9.6930e-02, best model: 263, LR: 4.4669e-04, epoch time: 87.39, snr: 4.2392e+00, var(R): 1.2198e-08, var(L*R): 4.3374e-08, WD: 1.4451e-06
[2025-08-02 07:52:51] - Epoch 268/500,it:109344, Train Loss: 8.1208e-02, Val Loss: 8.3017e-02, best model: 263, LR: 4.4357e-04, epoch time: 87.45, snr: 1.8193e+00, var(R): 1.3562e-08, var(L*R): 7.1133e-08, WD: 1.4520e-06
[2025-08-02 07:54:19] - Epoch 269/500,it:109752, Train Loss: 8.4693e-02, Val Loss: 8.4858e-02, best model: 263, LR: 4.4045e-04, epoch time: 87.49, snr: 3.8603e+00, var(R): 1.1555e-08, var(L*R): 3.8225e-08, WD: 1.4560e-06
[2025-08-02 07:55:46] - Epoch 270/500,it:110160, Train Loss: 8.2947e-02, Val Loss: 1.2098e-01, best model: 263, LR: 4.3733e-04, epoch time: 87.46, snr: 4.6191e+00, var(R): 1.1102e-08, var(L*R): 4.0591e-08, WD: 1.4564e-06
[2025-08-02 07:57:14] - Epoch 271/500,it:110568, Train Loss: 8.4431e-02, Val Loss: 1.0326e-01, best model: 263, LR: 4.3422e-04, epoch time: 87.46, snr: 2.1502e+00, var(R): 3.5358e-08, var(L*R): 1.3355e-07, WD: 1.4621e-06
[2025-08-02 07:58:41] - Epoch 272/500,it:110976, Train Loss: 7.9098e-02, Val Loss: 9.9284e-02, best model: 263, LR: 4.3110e-04, epoch time: 87.56, snr: 2.8800e+00, var(R): 1.5054e-08, var(L*R): 4.6997e-08, WD: 1.4696e-06
[2025-08-02 08:00:09] - Epoch 273/500,it:111384, Train Loss: 8.1127e-02, Val Loss: 8.0467e-02, best model: 263, LR: 4.2799e-04, epoch time: 87.48, snr: 4.1156e+00, var(R): 1.5180e-08, var(L*R): 4.6430e-08, WD: 1.4605e-06
[2025-08-02 08:01:36] - Epoch 274/500,it:111792, Train Loss: 7.8352e-02, Val Loss: 9.2830e-02, best model: 263, LR: 4.2489e-04, epoch time: 87.71, snr: 4.8839e+00, var(R): 1.0458e-08, var(L*R): 3.1743e-08, WD: 1.4718e-06
[2025-08-02 08:03:04] - Epoch 275/500,it:112200, Train Loss: 8.3120e-02, Val Loss: 1.0258e-01, best model: 263, LR: 4.2178e-04, epoch time: 87.36, snr: 3.8625e+00, var(R): 1.5944e-08, var(L*R): 4.3707e-08, WD: 1.4670e-06
[2025-08-02 08:04:31] - Epoch 276/500,it:112608, Train Loss: 7.8696e-02, Val Loss: 8.3939e-02, best model: 263, LR: 4.1868e-04, epoch time: 87.56, snr: 2.5276e+00, var(R): 2.0546e-08, var(L*R): 7.6035e-08, WD: 1.4784e-06
[2025-08-02 08:05:59] - Epoch 277/500,it:113016, Train Loss: 8.0631e-02, Val Loss: 1.2284e-01, best model: 263, LR: 4.1558e-04, epoch time: 87.48, snr: 3.8020e+00, var(R): 1.2808e-08, var(L*R): 3.6138e-08, WD: 1.4900e-06
[2025-08-02 08:07:27] - Epoch 278/500,it:113424, Train Loss: 7.6541e-02, Val Loss: 7.7455e-02, best model: 278, LR: 4.1249e-04, epoch time: 87.60, snr: 3.6067e+00, var(R): 2.8573e-08, var(L*R): 1.0360e-07, WD: 1.4799e-06
[2025-08-02 08:08:54] - Epoch 279/500,it:113832, Train Loss: 8.2558e-02, Val Loss: 1.1608e-01, best model: 278, LR: 4.0940e-04, epoch time: 87.47, snr: 2.8518e+00, var(R): 1.0123e-08, var(L*R): 3.2479e-08, WD: 1.4860e-06
[2025-08-02 08:10:22] - Epoch 280/500,it:114240, Train Loss: 7.6832e-02, Val Loss: 8.0165e-02, best model: 278, LR: 4.0631e-04, epoch time: 87.55, snr: 2.5225e+00, var(R): 2.9707e-08, var(L*R): 9.9852e-08, WD: 1.4898e-06
[2025-08-02 08:11:49] - Epoch 281/500,it:114648, Train Loss: 7.9820e-02, Val Loss: 8.3753e-02, best model: 278, LR: 4.0323e-04, epoch time: 87.51, snr: 2.5192e+00, var(R): 8.9135e-09, var(L*R): 3.3166e-08, WD: 1.4893e-06
[2025-08-02 08:13:17] - Epoch 282/500,it:115056, Train Loss: 7.4621e-02, Val Loss: 7.5609e-02, best model: 282, LR: 4.0015e-04, epoch time: 87.69, snr: 5.5209e+00, var(R): 1.0349e-08, var(L*R): 3.8311e-08, WD: 1.4945e-06
[2025-08-02 08:14:44] - Epoch 283/500,it:115464, Train Loss: 7.9622e-02, Val Loss: 8.9487e-02, best model: 282, LR: 3.9707e-04, epoch time: 87.46, snr: 4.2112e+00, var(R): 9.4247e-09, var(L*R): 3.1683e-08, WD: 1.4866e-06
[2025-08-02 08:16:12] - Epoch 284/500,it:115872, Train Loss: 7.5358e-02, Val Loss: 8.0425e-02, best model: 282, LR: 3.9400e-04, epoch time: 87.70, snr: 2.3562e+00, var(R): 1.2427e-08, var(L*R): 4.4714e-08, WD: 1.4947e-06
[2025-08-02 08:17:40] - Epoch 285/500,it:116280, Train Loss: 8.0253e-02, Val Loss: 7.4387e-02, best model: 285, LR: 3.9093e-04, epoch time: 87.56, snr: 5.6217e+00, var(R): 9.8887e-09, var(L*R): 3.9497e-08, WD: 1.4982e-06
[2025-08-02 08:19:07] - Epoch 286/500,it:116688, Train Loss: 7.4122e-02, Val Loss: 1.2414e-01, best model: 285, LR: 3.8786e-04, epoch time: 87.51, snr: 5.0293e+00, var(R): 9.3013e-09, var(L*R): 3.4253e-08, WD: 1.4893e-06
[2025-08-02 08:20:35] - Epoch 287/500,it:117096, Train Loss: 7.6849e-02, Val Loss: 7.9765e-02, best model: 285, LR: 3.8481e-04, epoch time: 87.57, snr: 2.0045e+00, var(R): 3.4962e-08, var(L*R): 1.5197e-07, WD: 1.5078e-06
[2025-08-02 08:22:02] - Epoch 288/500,it:117504, Train Loss: 7.8812e-02, Val Loss: 6.9306e-02, best model: 288, LR: 3.8175e-04, epoch time: 87.59, snr: 2.3287e+00, var(R): 9.1528e-09, var(L*R): 4.3699e-08, WD: 1.5028e-06
[2025-08-02 08:23:30] - Epoch 289/500,it:117912, Train Loss: 7.4949e-02, Val Loss: 8.6621e-02, best model: 288, LR: 3.7870e-04, epoch time: 87.47, snr: 5.6127e+00, var(R): 9.0571e-09, var(L*R): 3.6134e-08, WD: 1.5112e-06
[2025-08-02 08:24:57] - Epoch 290/500,it:118320, Train Loss: 7.2695e-02, Val Loss: 7.4857e-02, best model: 288, LR: 3.7566e-04, epoch time: 87.48, snr: 4.5870e+00, var(R): 1.4175e-08, var(L*R): 5.0753e-08, WD: 1.4975e-06
[2025-08-02 08:26:25] - Epoch 291/500,it:118728, Train Loss: 7.5575e-02, Val Loss: 9.0527e-02, best model: 288, LR: 3.7261e-04, epoch time: 87.72, snr: 3.4418e+00, var(R): 8.9561e-09, var(L*R): 2.9071e-08, WD: 1.5159e-06
[2025-08-02 08:27:52] - Epoch 292/500,it:119136, Train Loss: 7.4146e-02, Val Loss: 8.3783e-02, best model: 288, LR: 3.6958e-04, epoch time: 87.59, snr: 2.7421e+00, var(R): 1.4375e-08, var(L*R): 6.0524e-08, WD: 1.5214e-06
[2025-08-02 08:29:20] - Epoch 293/500,it:119544, Train Loss: 7.2244e-02, Val Loss: 7.1627e-02, best model: 288, LR: 3.6655e-04, epoch time: 87.59, snr: 4.9895e+00, var(R): 1.3622e-08, var(L*R): 4.7823e-08, WD: 1.5120e-06
[2025-08-02 08:30:47] - Epoch 294/500,it:119952, Train Loss: 7.0640e-02, Val Loss: 7.3134e-02, best model: 288, LR: 3.6352e-04, epoch time: 87.35, snr: 3.6873e+00, var(R): 1.0883e-08, var(L*R): 4.1890e-08, WD: 1.5094e-06
[2025-08-02 08:32:15] - Epoch 295/500,it:120360, Train Loss: 7.6719e-02, Val Loss: 8.9271e-02, best model: 288, LR: 3.6050e-04, epoch time: 87.61, snr: 4.9796e+00, var(R): 8.7930e-09, var(L*R): 3.1475e-08, WD: 1.5218e-06
[2025-08-02 08:33:43] - Epoch 296/500,it:120768, Train Loss: 7.0089e-02, Val Loss: 7.9653e-02, best model: 288, LR: 3.5749e-04, epoch time: 87.56, snr: 2.7595e+00, var(R): 1.5822e-08, var(L*R): 6.7975e-08, WD: 1.5238e-06
[2025-08-02 08:35:11] - Epoch 297/500,it:121176, Train Loss: 7.4920e-02, Val Loss: 1.0856e-01, best model: 288, LR: 3.5448e-04, epoch time: 87.94, snr: 2.2326e+00, var(R): 1.2291e-08, var(L*R): 3.8037e-08, WD: 1.5106e-06
[2025-08-02 08:36:38] - Epoch 298/500,it:121584, Train Loss: 7.2777e-02, Val Loss: 7.1305e-02, best model: 288, LR: 3.5148e-04, epoch time: 87.45, snr: 1.9978e+00, var(R): 2.8496e-08, var(L*R): 1.1659e-07, WD: 1.5106e-06
[2025-08-02 08:38:06] - Epoch 299/500,it:121992, Train Loss: 7.0808e-02, Val Loss: 9.4882e-02, best model: 288, LR: 3.4848e-04, epoch time: 87.57, snr: 4.8942e+00, var(R): 9.5889e-09, var(L*R): 3.6707e-08, WD: 1.5225e-06
[2025-08-02 08:39:33] - Epoch 300/500,it:122400, Train Loss: 7.0027e-02, Val Loss: 8.9675e-02, best model: 288, LR: 3.4549e-04, epoch time: 87.58, snr: 3.6893e+00, var(R): 1.8345e-08, var(L*R): 6.2050e-08, WD: 1.5188e-06
[2025-08-02 08:41:01] - Epoch 301/500,it:122808, Train Loss: 7.2182e-02, Val Loss: 9.3332e-02, best model: 288, LR: 3.4251e-04, epoch time: 87.56, snr: 3.5909e+00, var(R): 1.8279e-08, var(L*R): 5.4119e-08, WD: 1.5128e-06
[2025-08-02 08:42:28] - Epoch 302/500,it:123216, Train Loss: 7.0053e-02, Val Loss: 7.4625e-02, best model: 288, LR: 3.3953e-04, epoch time: 87.39, snr: 3.1286e+00, var(R): 1.6761e-08, var(L*R): 6.7942e-08, WD: 1.5199e-06
[2025-08-02 08:43:56] - Epoch 303/500,it:123624, Train Loss: 7.0391e-02, Val Loss: 8.4185e-02, best model: 288, LR: 3.3656e-04, epoch time: 87.52, snr: 4.3393e+00, var(R): 1.0203e-08, var(L*R): 4.4383e-08, WD: 1.5232e-06
[2025-08-02 08:45:23] - Epoch 304/500,it:124032, Train Loss: 7.4267e-02, Val Loss: 6.9084e-02, best model: 304, LR: 3.3359e-04, epoch time: 87.71, snr: 2.9433e+00, var(R): 1.2770e-08, var(L*R): 5.8297e-08, WD: 1.5286e-06
[2025-08-02 08:46:51] - Epoch 305/500,it:124440, Train Loss: 6.6476e-02, Val Loss: 8.4471e-02, best model: 304, LR: 3.3063e-04, epoch time: 87.82, snr: 5.7210e+00, var(R): 1.0150e-08, var(L*R): 3.7616e-08, WD: 1.5260e-06
[2025-08-02 08:48:19] - Epoch 306/500,it:124848, Train Loss: 6.9463e-02, Val Loss: 8.3505e-02, best model: 304, LR: 3.2768e-04, epoch time: 87.47, snr: 3.4464e+00, var(R): 1.5763e-08, var(L*R): 8.1314e-08, WD: 1.5324e-06
[2025-08-02 08:49:46] - Epoch 307/500,it:125256, Train Loss: 6.6207e-02, Val Loss: 7.2882e-02, best model: 304, LR: 3.2473e-04, epoch time: 87.71, snr: 2.2651e+00, var(R): 1.5964e-08, var(L*R): 6.6848e-08, WD: 1.5241e-06
[2025-08-02 08:51:14] - Epoch 308/500,it:125664, Train Loss: 6.8119e-02, Val Loss: 7.8439e-02, best model: 304, LR: 3.2179e-04, epoch time: 87.54, snr: 6.3515e+00, var(R): 1.0445e-08, var(L*R): 3.2252e-08, WD: 1.5341e-06
[2025-08-02 08:52:41] - Epoch 309/500,it:126072, Train Loss: 6.6960e-02, Val Loss: 7.7890e-02, best model: 304, LR: 3.1886e-04, epoch time: 87.42, snr: 2.7569e+00, var(R): 1.2116e-08, var(L*R): 5.1676e-08, WD: 1.5397e-06
[2025-08-02 08:54:09] - Epoch 310/500,it:126480, Train Loss: 6.8519e-02, Val Loss: 8.3126e-02, best model: 304, LR: 3.1594e-04, epoch time: 87.60, snr: 6.2228e+00, var(R): 1.1415e-08, var(L*R): 3.3734e-08, WD: 1.5297e-06
[2025-08-02 08:55:37] - Epoch 311/500,it:126888, Train Loss: 6.6761e-02, Val Loss: 1.0236e-01, best model: 304, LR: 3.1302e-04, epoch time: 87.65, snr: 5.0549e+00, var(R): 1.4622e-08, var(L*R): 5.4635e-08, WD: 1.5305e-06
[2025-08-02 08:57:04] - Epoch 312/500,it:127296, Train Loss: 7.4683e-02, Val Loss: 7.2286e-02, best model: 304, LR: 3.1011e-04, epoch time: 87.55, snr: 3.4605e+00, var(R): 2.3297e-08, var(L*R): 8.5192e-08, WD: 1.5436e-06
[2025-08-02 08:58:32] - Epoch 313/500,it:127704, Train Loss: 6.6747e-02, Val Loss: 7.1237e-02, best model: 304, LR: 3.0721e-04, epoch time: 87.60, snr: 4.1754e+00, var(R): 1.2237e-08, var(L*R): 4.3168e-08, WD: 1.5325e-06
[2025-08-02 08:59:59] - Epoch 314/500,it:128112, Train Loss: 6.4004e-02, Val Loss: 7.6300e-02, best model: 304, LR: 3.0431e-04, epoch time: 87.61, snr: 4.8696e+00, var(R): 1.3193e-08, var(L*R): 4.3075e-08, WD: 1.5465e-06
[2025-08-02 09:01:27] - Epoch 315/500,it:128520, Train Loss: 6.3953e-02, Val Loss: 6.7473e-02, best model: 315, LR: 3.0143e-04, epoch time: 87.81, snr: 3.9668e+00, var(R): 1.1525e-08, var(L*R): 3.9808e-08, WD: 1.5477e-06
[2025-08-02 09:02:55] - Epoch 316/500,it:128928, Train Loss: 6.2514e-02, Val Loss: 7.1148e-02, best model: 315, LR: 2.9855e-04, epoch time: 87.59, snr: 4.2294e+00, var(R): 1.1896e-08, var(L*R): 3.8996e-08, WD: 1.5496e-06
[2025-08-02 09:04:22] - Epoch 317/500,it:129336, Train Loss: 6.5661e-02, Val Loss: 7.6781e-02, best model: 315, LR: 2.9568e-04, epoch time: 87.44, snr: 1.8073e+00, var(R): 1.1463e-08, var(L*R): 5.7694e-08, WD: 1.5492e-06
[2025-08-02 09:05:50] - Epoch 318/500,it:129744, Train Loss: 6.5575e-02, Val Loss: 1.2001e-01, best model: 315, LR: 2.9281e-04, epoch time: 87.88, snr: 4.1119e+00, var(R): 1.4855e-08, var(L*R): 4.5108e-08, WD: 1.5541e-06
[2025-08-02 09:07:18] - Epoch 319/500,it:130152, Train Loss: 6.7528e-02, Val Loss: 6.6788e-02, best model: 319, LR: 2.8996e-04, epoch time: 87.78, snr: 2.2804e+00, var(R): 3.6663e-08, var(L*R): 1.3786e-07, WD: 1.5410e-06
[2025-08-02 09:08:46] - Epoch 320/500,it:130560, Train Loss: 6.6468e-02, Val Loss: 7.3971e-02, best model: 319, LR: 2.8711e-04, epoch time: 87.70, snr: 4.8493e+00, var(R): 8.4805e-09, var(L*R): 3.5041e-08, WD: 1.5522e-06
[2025-08-02 09:10:13] - Epoch 321/500,it:130968, Train Loss: 6.2492e-02, Val Loss: 6.8748e-02, best model: 319, LR: 2.8427e-04, epoch time: 87.53, snr: 5.0641e+00, var(R): 1.4850e-08, var(L*R): 5.3144e-08, WD: 1.5511e-06
[2025-08-02 09:11:41] - Epoch 322/500,it:131376, Train Loss: 6.2643e-02, Val Loss: 6.7073e-02, best model: 319, LR: 2.8144e-04, epoch time: 87.61, snr: 2.8217e+00, var(R): 1.0477e-08, var(L*R): 4.3568e-08, WD: 1.5571e-06
[2025-08-02 09:13:08] - Epoch 323/500,it:131784, Train Loss: 6.2216e-02, Val Loss: 6.9955e-02, best model: 319, LR: 2.7862e-04, epoch time: 87.57, snr: 5.4804e+00, var(R): 1.0192e-08, var(L*R): 3.9097e-08, WD: 1.5523e-06
[2025-08-02 09:14:36] - Epoch 324/500,it:132192, Train Loss: 6.4966e-02, Val Loss: 8.2739e-02, best model: 319, LR: 2.7581e-04, epoch time: 87.64, snr: 5.3757e+00, var(R): 1.4123e-08, var(L*R): 4.6117e-08, WD: 1.5482e-06
[2025-08-02 09:16:04] - Epoch 325/500,it:132600, Train Loss: 6.4012e-02, Val Loss: 8.2474e-02, best model: 319, LR: 2.7300e-04, epoch time: 87.64, snr: 2.9606e+00, var(R): 1.6737e-08, var(L*R): 8.6659e-08, WD: 1.5510e-06
[2025-08-02 09:17:31] - Epoch 326/500,it:133008, Train Loss: 6.1868e-02, Val Loss: 6.6724e-02, best model: 326, LR: 2.7021e-04, epoch time: 87.76, snr: 5.2403e+00, var(R): 1.2615e-08, var(L*R): 5.1147e-08, WD: 1.5680e-06
[2025-08-02 09:18:59] - Epoch 327/500,it:133416, Train Loss: 6.5363e-02, Val Loss: 7.3464e-02, best model: 326, LR: 2.6742e-04, epoch time: 87.70, snr: 5.0904e+00, var(R): 1.1393e-08, var(L*R): 4.1850e-08, WD: 1.5578e-06
[2025-08-02 09:20:27] - Epoch 328/500,it:133824, Train Loss: 6.0037e-02, Val Loss: 5.9199e-02, best model: 328, LR: 2.6465e-04, epoch time: 87.79, snr: 3.4209e+00, var(R): 1.5562e-08, var(L*R): 5.8343e-08, WD: 1.5511e-06
[2025-08-02 09:21:54] - Epoch 329/500,it:134232, Train Loss: 6.0111e-02, Val Loss: 6.9025e-02, best model: 328, LR: 2.6188e-04, epoch time: 87.43, snr: 6.2077e+00, var(R): 9.0515e-09, var(L*R): 3.3317e-08, WD: 1.5677e-06
[2025-08-02 09:23:22] - Epoch 330/500,it:134640, Train Loss: 6.0846e-02, Val Loss: 7.0439e-02, best model: 328, LR: 2.5912e-04, epoch time: 87.60, snr: 3.9222e+00, var(R): 1.2504e-08, var(L*R): 5.2030e-08, WD: 1.5695e-06
[2025-08-02 09:24:50] - Epoch 331/500,it:135048, Train Loss: 5.8579e-02, Val Loss: 6.7821e-02, best model: 328, LR: 2.5637e-04, epoch time: 87.58, snr: 5.9621e+00, var(R): 1.2380e-08, var(L*R): 4.1020e-08, WD: 1.5522e-06
[2025-08-02 09:26:17] - Epoch 332/500,it:135456, Train Loss: 6.3174e-02, Val Loss: 8.7953e-02, best model: 328, LR: 2.5364e-04, epoch time: 87.45, snr: 2.3485e+00, var(R): 1.0581e-08, var(L*R): 5.0456e-08, WD: 1.5693e-06
[2025-08-02 09:27:45] - Epoch 333/500,it:135864, Train Loss: 5.9859e-02, Val Loss: 5.8679e-02, best model: 333, LR: 2.5091e-04, epoch time: 87.81, snr: 2.6991e+00, var(R): 2.3364e-08, var(L*R): 9.3867e-08, WD: 1.5571e-06
[2025-08-02 09:29:13] - Epoch 334/500,it:136272, Train Loss: 5.8225e-02, Val Loss: 7.3843e-02, best model: 333, LR: 2.4819e-04, epoch time: 87.79, snr: 6.2830e+00, var(R): 9.2978e-09, var(L*R): 3.8838e-08, WD: 1.5715e-06
[2025-08-02 09:30:40] - Epoch 335/500,it:136680, Train Loss: 6.1909e-02, Val Loss: 7.8995e-02, best model: 333, LR: 2.4548e-04, epoch time: 87.59, snr: 4.0703e+00, var(R): 1.6617e-08, var(L*R): 5.5645e-08, WD: 1.5490e-06
[2025-08-02 09:32:08] - Epoch 336/500,it:137088, Train Loss: 5.9760e-02, Val Loss: 6.5918e-02, best model: 333, LR: 2.4278e-04, epoch time: 87.63, snr: 4.2824e+00, var(R): 1.6337e-08, var(L*R): 5.9159e-08, WD: 1.5653e-06
[2025-08-02 09:33:35] - Epoch 337/500,it:137496, Train Loss: 5.9155e-02, Val Loss: 6.3926e-02, best model: 333, LR: 2.4009e-04, epoch time: 87.61, snr: 5.6500e+00, var(R): 1.1612e-08, var(L*R): 4.5715e-08, WD: 1.5602e-06
[2025-08-02 09:35:03] - Epoch 338/500,it:137904, Train Loss: 5.7506e-02, Val Loss: 6.3315e-02, best model: 333, LR: 2.3741e-04, epoch time: 87.96, snr: 4.8382e+00, var(R): 1.5273e-08, var(L*R): 5.4727e-08, WD: 1.5609e-06
[2025-08-02 09:36:31] - Epoch 339/500,it:138312, Train Loss: 6.0232e-02, Val Loss: 7.4151e-02, best model: 333, LR: 2.3474e-04, epoch time: 87.68, snr: 3.1743e+00, var(R): 1.2288e-08, var(L*R): 5.8979e-08, WD: 1.5607e-06
[2025-08-02 09:37:59] - Epoch 340/500,it:138720, Train Loss: 5.7948e-02, Val Loss: 5.9733e-02, best model: 333, LR: 2.3209e-04, epoch time: 87.68, snr: 2.9392e+00, var(R): 1.7572e-08, var(L*R): 7.6713e-08, WD: 1.5700e-06
[2025-08-02 09:39:27] - Epoch 341/500,it:139128, Train Loss: 5.8408e-02, Val Loss: 6.4988e-02, best model: 333, LR: 2.2944e-04, epoch time: 87.80, snr: 3.3165e+00, var(R): 1.1046e-08, var(L*R): 5.8948e-08, WD: 1.5638e-06
[2025-08-02 09:40:55] - Epoch 342/500,it:139536, Train Loss: 5.8282e-02, Val Loss: 5.4964e-02, best model: 342, LR: 2.2680e-04, epoch time: 87.97, snr: 5.9237e+00, var(R): 1.1477e-08, var(L*R): 4.6563e-08, WD: 1.5756e-06
[2025-08-02 09:42:23] - Epoch 343/500,it:139944, Train Loss: 5.7185e-02, Val Loss: 6.8092e-02, best model: 342, LR: 2.2418e-04, epoch time: 88.42, snr: 6.4231e+00, var(R): 9.8174e-09, var(L*R): 3.7147e-08, WD: 1.5722e-06
[2025-08-02 09:43:51] - Epoch 344/500,it:140352, Train Loss: 5.5605e-02, Val Loss: 6.3201e-02, best model: 342, LR: 2.2156e-04, epoch time: 88.03, snr: 3.5793e+00, var(R): 1.3844e-08, var(L*R): 5.8467e-08, WD: 1.5708e-06
[2025-08-02 09:45:19] - Epoch 345/500,it:140760, Train Loss: 5.7238e-02, Val Loss: 6.4802e-02, best model: 342, LR: 2.1896e-04, epoch time: 88.00, snr: 5.0267e+00, var(R): 1.3725e-08, var(L*R): 4.8232e-08, WD: 1.5677e-06
[2025-08-02 09:46:48] - Epoch 346/500,it:141168, Train Loss: 5.5570e-02, Val Loss: 6.2059e-02, best model: 342, LR: 2.1637e-04, epoch time: 89.00, snr: 6.0675e+00, var(R): 1.1308e-08, var(L*R): 4.6992e-08, WD: 1.5673e-06
[2025-08-02 09:48:17] - Epoch 347/500,it:141576, Train Loss: 5.6491e-02, Val Loss: 5.8074e-02, best model: 342, LR: 2.1378e-04, epoch time: 88.90, snr: 3.2846e+00, var(R): 1.2728e-08, var(L*R): 5.7379e-08, WD: 1.5749e-06
[2025-08-02 09:49:46] - Epoch 348/500,it:141984, Train Loss: 5.6178e-02, Val Loss: 5.8205e-02, best model: 342, LR: 2.1121e-04, epoch time: 89.24, snr: 5.4786e+00, var(R): 1.0198e-08, var(L*R): 4.0792e-08, WD: 1.5596e-06
[2025-08-02 09:51:15] - Epoch 349/500,it:142392, Train Loss: 5.6329e-02, Val Loss: 6.7298e-02, best model: 342, LR: 2.0865e-04, epoch time: 88.39, snr: 4.6677e+00, var(R): 1.2155e-08, var(L*R): 4.3897e-08, WD: 1.5760e-06
[2025-08-02 09:52:43] - Epoch 350/500,it:142800, Train Loss: 5.3475e-02, Val Loss: 6.2685e-02, best model: 342, LR: 2.0611e-04, epoch time: 88.65, snr: 4.8938e+00, var(R): 1.3481e-08, var(L*R): 5.1602e-08, WD: 1.5710e-06
[2025-08-02 09:54:12] - Epoch 351/500,it:143208, Train Loss: 5.4185e-02, Val Loss: 6.2997e-02, best model: 342, LR: 2.0357e-04, epoch time: 88.33, snr: 4.7143e+00, var(R): 1.3135e-08, var(L*R): 5.4731e-08, WD: 1.5671e-06
[2025-08-02 09:55:40] - Epoch 352/500,it:143616, Train Loss: 5.5199e-02, Val Loss: 6.0081e-02, best model: 342, LR: 2.0105e-04, epoch time: 88.27, snr: 5.2566e+00, var(R): 1.3054e-08, var(L*R): 5.2170e-08, WD: 1.5687e-06
[2025-08-02 09:57:08] - Epoch 353/500,it:144024, Train Loss: 5.3804e-02, Val Loss: 6.2778e-02, best model: 342, LR: 1.9854e-04, epoch time: 88.46, snr: 4.3098e+00, var(R): 1.1620e-08, var(L*R): 5.0635e-08, WD: 1.5824e-06
[2025-08-02 09:58:36] - Epoch 354/500,it:144432, Train Loss: 5.4639e-02, Val Loss: 6.5455e-02, best model: 342, LR: 1.9603e-04, epoch time: 88.16, snr: 5.2255e+00, var(R): 1.3844e-08, var(L*R): 5.2018e-08, WD: 1.5624e-06
[2025-08-02 10:00:05] - Epoch 355/500,it:144840, Train Loss: 5.3007e-02, Val Loss: 6.0110e-02, best model: 342, LR: 1.9355e-04, epoch time: 88.37, snr: 4.3002e+00, var(R): 1.5867e-08, var(L*R): 6.0941e-08, WD: 1.5742e-06
[2025-08-02 10:01:33] - Epoch 356/500,it:145248, Train Loss: 5.4920e-02, Val Loss: 6.3442e-02, best model: 342, LR: 1.9107e-04, epoch time: 88.45, snr: 5.1984e+00, var(R): 1.2163e-08, var(L*R): 4.7764e-08, WD: 1.5772e-06
[2025-08-02 10:03:01] - Epoch 357/500,it:145656, Train Loss: 5.3249e-02, Val Loss: 5.5739e-02, best model: 342, LR: 1.8861e-04, epoch time: 88.14, snr: 3.8625e+00, var(R): 1.6040e-08, var(L*R): 6.5750e-08, WD: 1.5710e-06
[2025-08-02 10:04:30] - Epoch 358/500,it:146064, Train Loss: 5.2584e-02, Val Loss: 6.4788e-02, best model: 342, LR: 1.8615e-04, epoch time: 88.32, snr: 5.4986e+00, var(R): 1.1973e-08, var(L*R): 4.9379e-08, WD: 1.5766e-06
[2025-08-02 10:05:58] - Epoch 359/500,it:146472, Train Loss: 5.2785e-02, Val Loss: 5.7697e-02, best model: 342, LR: 1.8371e-04, epoch time: 88.12, snr: 4.5409e+00, var(R): 1.5366e-08, var(L*R): 6.2404e-08, WD: 1.5897e-06
[2025-08-02 10:07:26] - Epoch 360/500,it:146880, Train Loss: 5.2784e-02, Val Loss: 6.1041e-02, best model: 342, LR: 1.8129e-04, epoch time: 88.49, snr: 4.9756e+00, var(R): 1.3574e-08, var(L*R): 5.3684e-08, WD: 1.5782e-06
[2025-08-02 10:08:55] - Epoch 361/500,it:147288, Train Loss: 5.0828e-02, Val Loss: 5.2636e-02, best model: 361, LR: 1.7887e-04, epoch time: 88.49, snr: 4.9418e+00, var(R): 1.2332e-08, var(L*R): 5.0331e-08, WD: 1.5736e-06
[2025-08-02 10:10:24] - Epoch 362/500,it:147696, Train Loss: 5.0367e-02, Val Loss: 5.2485e-02, best model: 362, LR: 1.7647e-04, epoch time: 88.91, snr: 5.3398e+00, var(R): 1.2576e-08, var(L*R): 5.1892e-08, WD: 1.5712e-06
[2025-08-02 10:11:52] - Epoch 363/500,it:148104, Train Loss: 5.3760e-02, Val Loss: 6.3982e-02, best model: 362, LR: 1.7408e-04, epoch time: 88.34, snr: 4.5919e+00, var(R): 1.2476e-08, var(L*R): 5.1879e-08, WD: 1.5650e-06
[2025-08-02 10:13:20] - Epoch 364/500,it:148512, Train Loss: 5.3445e-02, Val Loss: 5.2191e-02, best model: 364, LR: 1.7171e-04, epoch time: 88.28, snr: 4.1546e+00, var(R): 1.4802e-08, var(L*R): 6.2067e-08, WD: 1.5745e-06
[2025-08-02 10:14:49] - Epoch 365/500,it:148920, Train Loss: 5.0849e-02, Val Loss: 5.3298e-02, best model: 364, LR: 1.6934e-04, epoch time: 88.75, snr: 5.5409e+00, var(R): 1.2436e-08, var(L*R): 5.1824e-08, WD: 1.5765e-06
[2025-08-02 10:16:18] - Epoch 366/500,it:149328, Train Loss: 4.9716e-02, Val Loss: 5.5274e-02, best model: 364, LR: 1.6699e-04, epoch time: 88.84, snr: 5.6081e+00, var(R): 1.2212e-08, var(L*R): 5.0323e-08, WD: 1.5740e-06
[2025-08-02 10:17:47] - Epoch 367/500,it:149736, Train Loss: 4.9514e-02, Val Loss: 5.3488e-02, best model: 364, LR: 1.6466e-04, epoch time: 88.52, snr: 5.3772e+00, var(R): 1.2673e-08, var(L*R): 5.2962e-08, WD: 1.5730e-06
[2025-08-02 10:19:15] - Epoch 368/500,it:150144, Train Loss: 5.2178e-02, Val Loss: 6.2920e-02, best model: 364, LR: 1.6233e-04, epoch time: 88.66, snr: 4.8230e+00, var(R): 1.2956e-08, var(L*R): 5.1829e-08, WD: 1.5643e-06
[2025-08-02 10:20:44] - Epoch 369/500,it:150552, Train Loss: 5.1106e-02, Val Loss: 5.8601e-02, best model: 364, LR: 1.6002e-04, epoch time: 89.22, snr: 4.2561e+00, var(R): 1.8081e-08, var(L*R): 7.1327e-08, WD: 1.5840e-06
[2025-08-02 10:22:14] - Epoch 370/500,it:150960, Train Loss: 4.9698e-02, Val Loss: 5.1411e-02, best model: 370, LR: 1.5773e-04, epoch time: 89.28, snr: 4.3396e+00, var(R): 1.4529e-08, var(L*R): 6.3388e-08, WD: 1.5635e-06
[2025-08-02 10:23:43] - Epoch 371/500,it:151368, Train Loss: 4.8374e-02, Val Loss: 4.9892e-02, best model: 371, LR: 1.5544e-04, epoch time: 89.25, snr: 5.6634e+00, var(R): 1.1617e-08, var(L*R): 5.2202e-08, WD: 1.5783e-06
[2025-08-02 10:25:12] - Epoch 372/500,it:151776, Train Loss: 4.8770e-02, Val Loss: 5.9023e-02, best model: 371, LR: 1.5317e-04, epoch time: 88.56, snr: 5.5298e+00, var(R): 1.3045e-08, var(L*R): 5.8359e-08, WD: 1.5736e-06
[2025-08-02 10:26:41] - Epoch 373/500,it:152184, Train Loss: 4.9442e-02, Val Loss: 5.7180e-02, best model: 371, LR: 1.5092e-04, epoch time: 89.26, snr: 4.5393e+00, var(R): 1.3376e-08, var(L*R): 5.6579e-08, WD: 1.5810e-06
[2025-08-02 10:28:09] - Epoch 374/500,it:152592, Train Loss: 4.9410e-02, Val Loss: 5.0551e-02, best model: 371, LR: 1.4868e-04, epoch time: 88.62, snr: 4.5243e+00, var(R): 1.3619e-08, var(L*R): 6.1516e-08, WD: 1.5649e-06
[2025-08-02 10:29:39] - Epoch 375/500,it:153000, Train Loss: 4.8912e-02, Val Loss: 5.3540e-02, best model: 371, LR: 1.4645e-04, epoch time: 89.19, snr: 5.7896e+00, var(R): 1.2938e-08, var(L*R): 5.7213e-08, WD: 1.5851e-06
[2025-08-02 10:31:07] - Epoch 376/500,it:153408, Train Loss: 4.8578e-02, Val Loss: 5.2914e-02, best model: 371, LR: 1.4423e-04, epoch time: 88.80, snr: 4.7406e+00, var(R): 1.2452e-08, var(L*R): 5.7866e-08, WD: 1.5752e-06
[2025-08-02 10:32:36] - Epoch 377/500,it:153816, Train Loss: 4.8834e-02, Val Loss: 5.7223e-02, best model: 371, LR: 1.4203e-04, epoch time: 88.71, snr: 4.4316e+00, var(R): 1.4626e-08, var(L*R): 6.8931e-08, WD: 1.5921e-06
[2025-08-02 10:34:05] - Epoch 378/500,it:154224, Train Loss: 4.9405e-02, Val Loss: 5.5969e-02, best model: 371, LR: 1.3985e-04, epoch time: 88.47, snr: 3.9658e+00, var(R): 1.5189e-08, var(L*R): 6.8502e-08, WD: 1.5712e-06
[2025-08-02 10:35:33] - Epoch 379/500,it:154632, Train Loss: 4.8762e-02, Val Loss: 5.4668e-02, best model: 371, LR: 1.3767e-04, epoch time: 88.71, snr: 4.6817e+00, var(R): 1.4984e-08, var(L*R): 6.9367e-08, WD: 1.5956e-06
[2025-08-02 10:37:02] - Epoch 380/500,it:155040, Train Loss: 4.8118e-02, Val Loss: 4.7521e-02, best model: 380, LR: 1.3552e-04, epoch time: 88.86, snr: 4.4583e+00, var(R): 1.5216e-08, var(L*R): 7.1421e-08, WD: 1.5723e-06
[2025-08-02 10:38:32] - Epoch 381/500,it:155448, Train Loss: 4.6409e-02, Val Loss: 4.6688e-02, best model: 381, LR: 1.3337e-04, epoch time: 89.33, snr: 5.9135e+00, var(R): 1.2945e-08, var(L*R): 6.0581e-08, WD: 1.5696e-06
[2025-08-02 10:40:00] - Epoch 382/500,it:155856, Train Loss: 4.6051e-02, Val Loss: 5.5783e-02, best model: 381, LR: 1.3124e-04, epoch time: 88.51, snr: 5.7492e+00, var(R): 1.2829e-08, var(L*R): 6.0851e-08, WD: 1.5627e-06
[2025-08-02 10:41:29] - Epoch 383/500,it:156264, Train Loss: 4.7997e-02, Val Loss: 5.7564e-02, best model: 381, LR: 1.2913e-04, epoch time: 88.76, snr: 4.6892e+00, var(R): 1.4636e-08, var(L*R): 6.7287e-08, WD: 1.5715e-06
[2025-08-02 10:42:57] - Epoch 384/500,it:156672, Train Loss: 4.7231e-02, Val Loss: 4.7729e-02, best model: 381, LR: 1.2703e-04, epoch time: 88.56, snr: 4.0529e+00, var(R): 1.6882e-08, var(L*R): 7.7901e-08, WD: 1.5687e-06
[2025-08-02 10:44:26] - Epoch 385/500,it:157080, Train Loss: 4.6078e-02, Val Loss: 5.2889e-02, best model: 381, LR: 1.2494e-04, epoch time: 88.79, snr: 5.6803e+00, var(R): 1.3606e-08, var(L*R): 6.4931e-08, WD: 1.5656e-06
[2025-08-02 10:45:55] - Epoch 386/500,it:157488, Train Loss: 4.7249e-02, Val Loss: 5.3116e-02, best model: 381, LR: 1.2287e-04, epoch time: 88.47, snr: 4.7817e+00, var(R): 1.4318e-08, var(L*R): 7.0134e-08, WD: 1.5712e-06
[2025-08-02 10:47:24] - Epoch 387/500,it:157896, Train Loss: 4.5956e-02, Val Loss: 5.1397e-02, best model: 381, LR: 1.2082e-04, epoch time: 89.07, snr: 4.9204e+00, var(R): 1.5496e-08, var(L*R): 7.5128e-08, WD: 1.5677e-06
[2025-08-02 10:48:52] - Epoch 388/500,it:158304, Train Loss: 4.6268e-02, Val Loss: 5.1659e-02, best model: 381, LR: 1.1878e-04, epoch time: 88.47, snr: 4.7801e+00, var(R): 1.4609e-08, var(L*R): 7.2852e-08, WD: 1.5716e-06
[2025-08-02 10:50:21] - Epoch 389/500,it:158712, Train Loss: 4.6202e-02, Val Loss: 4.6758e-02, best model: 381, LR: 1.1675e-04, epoch time: 88.57, snr: 4.9083e+00, var(R): 1.4603e-08, var(L*R): 7.3843e-08, WD: 1.5833e-06
[2025-08-02 10:51:49] - Epoch 390/500,it:159120, Train Loss: 4.6038e-02, Val Loss: 5.0593e-02, best model: 381, LR: 1.1474e-04, epoch time: 88.63, snr: 5.4538e+00, var(R): 1.3651e-08, var(L*R): 6.9914e-08, WD: 1.5773e-06
[2025-08-02 10:53:18] - Epoch 391/500,it:159528, Train Loss: 4.5957e-02, Val Loss: 4.5447e-02, best model: 391, LR: 1.1275e-04, epoch time: 88.87, snr: 4.7332e+00, var(R): 1.4753e-08, var(L*R): 7.6594e-08, WD: 1.5603e-06
[2025-08-02 10:54:47] - Epoch 392/500,it:159936, Train Loss: 4.4905e-02, Val Loss: 4.5637e-02, best model: 391, LR: 1.1077e-04, epoch time: 89.06, snr: 5.7165e+00, var(R): 1.3492e-08, var(L*R): 7.1389e-08, WD: 1.5610e-06
[2025-08-02 10:56:16] - Epoch 393/500,it:160344, Train Loss: 4.4671e-02, Val Loss: 5.1697e-02, best model: 391, LR: 1.0880e-04, epoch time: 89.08, snr: 5.7603e+00, var(R): 1.4156e-08, var(L*R): 7.3854e-08, WD: 1.5725e-06
[2025-08-02 10:57:45] - Epoch 394/500,it:160752, Train Loss: 4.7587e-02, Val Loss: 4.5809e-02, best model: 391, LR: 1.0686e-04, epoch time: 88.41, snr: 4.7576e+00, var(R): 1.4990e-08, var(L*R): 7.7731e-08, WD: 1.5727e-06
[2025-08-02 10:59:14] - Epoch 395/500,it:161160, Train Loss: 4.6416e-02, Val Loss: 4.4262e-02, best model: 395, LR: 1.0492e-04, epoch time: 88.80, snr: 5.6101e+00, var(R): 1.4419e-08, var(L*R): 7.9029e-08, WD: 1.5670e-06
[2025-08-02 11:00:42] - Epoch 396/500,it:161568, Train Loss: 4.5208e-02, Val Loss: 4.4366e-02, best model: 395, LR: 1.0300e-04, epoch time: 88.66, snr: 5.6551e+00, var(R): 1.4191e-08, var(L*R): 7.6376e-08, WD: 1.5795e-06
[2025-08-02 11:02:11] - Epoch 397/500,it:161976, Train Loss: 4.5121e-02, Val Loss: 4.4481e-02, best model: 395, LR: 1.0110e-04, epoch time: 88.64, snr: 5.7320e+00, var(R): 1.4455e-08, var(L*R): 7.7891e-08, WD: 1.5662e-06
[2025-08-02 11:03:40] - Epoch 398/500,it:162384, Train Loss: 4.5087e-02, Val Loss: 4.3915e-02, best model: 398, LR: 9.9217e-05, epoch time: 88.68, snr: 5.9416e+00, var(R): 1.4520e-08, var(L*R): 7.9681e-08, WD: 1.5663e-06
[2025-08-02 11:05:08] - Epoch 399/500,it:162792, Train Loss: 4.4971e-02, Val Loss: 4.3930e-02, best model: 398, LR: 9.7346e-05, epoch time: 88.62, snr: 5.9433e+00, var(R): 1.4264e-08, var(L*R): 7.9326e-08, WD: 1.5687e-06
[2025-08-02 11:06:37] - Epoch 400/500,it:163200, Train Loss: 4.4374e-02, Val Loss: 4.3402e-02, best model: 400, LR: 9.5492e-05, epoch time: 88.72, snr: 6.0617e+00, var(R): 1.4157e-08, var(L*R): 8.2800e-08, WD: 1.5567e-06
[2025-08-02 11:08:05] - Epoch 401/500,it:163608, Train Loss: 4.3959e-02, Val Loss: 4.3241e-02, best model: 401, LR: 9.3653e-05, epoch time: 88.53, snr: 5.8389e+00, var(R): 1.4159e-08, var(L*R): 7.9966e-08, WD: 1.5564e-06
[2025-08-02 11:09:34] - Epoch 402/500,it:164016, Train Loss: 4.4365e-02, Val Loss: 4.3582e-02, best model: 401, LR: 9.1830e-05, epoch time: 88.81, snr: 5.8407e+00, var(R): 1.4307e-08, var(L*R): 8.1710e-08, WD: 1.5617e-06
[2025-08-02 11:11:04] - Epoch 403/500,it:164424, Train Loss: 4.3755e-02, Val Loss: 4.3042e-02, best model: 403, LR: 9.0024e-05, epoch time: 89.52, snr: 5.9470e+00, var(R): 1.4353e-08, var(L*R): 8.2277e-08, WD: 1.5635e-06
[2025-08-02 11:12:34] - Epoch 404/500,it:164832, Train Loss: 4.4173e-02, Val Loss: 4.3430e-02, best model: 403, LR: 8.8234e-05, epoch time: 89.95, snr: 6.0455e+00, var(R): 1.4127e-08, var(L*R): 8.2390e-08, WD: 1.5714e-06
[2025-08-02 11:14:04] - Epoch 405/500,it:165240, Train Loss: 4.3476e-02, Val Loss: 4.2651e-02, best model: 405, LR: 8.6460e-05, epoch time: 90.35, snr: 5.8214e+00, var(R): 1.4170e-08, var(L*R): 8.4968e-08, WD: 1.5671e-06
[2025-08-02 11:15:34] - Epoch 406/500,it:165648, Train Loss: 4.3501e-02, Val Loss: 4.2731e-02, best model: 405, LR: 8.4702e-05, epoch time: 89.84, snr: 5.9784e+00, var(R): 1.4161e-08, var(L*R): 8.4134e-08, WD: 1.5555e-06
[2025-08-02 11:17:03] - Epoch 407/500,it:166056, Train Loss: 4.3236e-02, Val Loss: 4.2074e-02, best model: 407, LR: 8.2961e-05, epoch time: 89.34, snr: 5.9366e+00, var(R): 1.3995e-08, var(L*R): 8.5077e-08, WD: 1.5593e-06
[2025-08-02 11:18:32] - Epoch 408/500,it:166464, Train Loss: 4.2811e-02, Val Loss: 4.2084e-02, best model: 407, LR: 8.1236e-05, epoch time: 88.51, snr: 5.9940e+00, var(R): 1.4071e-08, var(L*R): 8.5593e-08, WD: 1.5754e-06
[2025-08-02 11:20:00] - Epoch 409/500,it:166872, Train Loss: 4.2744e-02, Val Loss: 4.2205e-02, best model: 407, LR: 7.9528e-05, epoch time: 88.40, snr: 5.8585e+00, var(R): 1.4117e-08, var(L*R): 8.5655e-08, WD: 1.5613e-06
[2025-08-02 11:21:29] - Epoch 410/500,it:167280, Train Loss: 4.2646e-02, Val Loss: 4.2103e-02, best model: 407, LR: 7.7836e-05, epoch time: 88.77, snr: 5.9651e+00, var(R): 1.4373e-08, var(L*R): 8.8479e-08, WD: 1.5603e-06
[2025-08-02 11:22:57] - Epoch 411/500,it:167688, Train Loss: 4.2651e-02, Val Loss: 4.2202e-02, best model: 407, LR: 7.6161e-05, epoch time: 88.45, snr: 5.9788e+00, var(R): 1.4353e-08, var(L*R): 8.8541e-08, WD: 1.5544e-06
[2025-08-02 11:24:26] - Epoch 412/500,it:168096, Train Loss: 4.2238e-02, Val Loss: 4.2125e-02, best model: 407, LR: 7.4503e-05, epoch time: 88.49, snr: 5.9267e+00, var(R): 1.4439e-08, var(L*R): 9.0499e-08, WD: 1.5472e-06
[2025-08-02 11:25:54] - Epoch 413/500,it:168504, Train Loss: 4.2459e-02, Val Loss: 4.2179e-02, best model: 407, LR: 7.2861e-05, epoch time: 88.26, snr: 5.9891e+00, var(R): 1.4357e-08, var(L*R): 9.2069e-08, WD: 1.5645e-06
[2025-08-02 11:27:23] - Epoch 414/500,it:168912, Train Loss: 4.2266e-02, Val Loss: 4.1569e-02, best model: 414, LR: 7.1237e-05, epoch time: 88.49, snr: 6.0081e+00, var(R): 1.4411e-08, var(L*R): 9.4725e-08, WD: 1.5600e-06
[2025-08-02 11:28:51] - Epoch 415/500,it:169320, Train Loss: 4.1933e-02, Val Loss: 4.1687e-02, best model: 414, LR: 6.9629e-05, epoch time: 88.44, snr: 5.6875e+00, var(R): 1.4158e-08, var(L*R): 9.2430e-08, WD: 1.5485e-06
[2025-08-02 11:30:20] - Epoch 416/500,it:169728, Train Loss: 4.1746e-02, Val Loss: 4.1792e-02, best model: 414, LR: 6.8038e-05, epoch time: 88.51, snr: 5.7790e+00, var(R): 1.4467e-08, var(L*R): 9.4867e-08, WD: 1.5488e-06
[2025-08-02 11:31:48] - Epoch 417/500,it:170136, Train Loss: 4.1628e-02, Val Loss: 4.1807e-02, best model: 414, LR: 6.6465e-05, epoch time: 88.36, snr: 6.0098e+00, var(R): 1.4529e-08, var(L*R): 9.6473e-08, WD: 1.5443e-06
[2025-08-02 11:33:17] - Epoch 418/500,it:170544, Train Loss: 4.1568e-02, Val Loss: 4.1724e-02, best model: 414, LR: 6.4908e-05, epoch time: 88.72, snr: 5.6691e+00, var(R): 1.4522e-08, var(L*R): 9.8081e-08, WD: 1.5479e-06
[2025-08-02 11:34:45] - Epoch 419/500,it:170952, Train Loss: 4.1378e-02, Val Loss: 4.2149e-02, best model: 414, LR: 6.3369e-05, epoch time: 88.20, snr: 5.8563e+00, var(R): 1.4367e-08, var(L*R): 9.9392e-08, WD: 1.5667e-06
[2025-08-02 11:36:14] - Epoch 420/500,it:171360, Train Loss: 4.1157e-02, Val Loss: 4.1640e-02, best model: 414, LR: 6.1847e-05, epoch time: 88.88, snr: 5.6336e+00, var(R): 1.4916e-08, var(L*R): 9.8808e-08, WD: 1.5503e-06
[2025-08-02 11:37:42] - Epoch 421/500,it:171768, Train Loss: 4.1159e-02, Val Loss: 4.1877e-02, best model: 414, LR: 6.0342e-05, epoch time: 88.24, snr: 5.5785e+00, var(R): 1.4895e-08, var(L*R): 1.0006e-07, WD: 1.5443e-06
[2025-08-02 11:39:11] - Epoch 422/500,it:172176, Train Loss: 4.0943e-02, Val Loss: 4.1857e-02, best model: 414, LR: 5.8854e-05, epoch time: 89.16, snr: 5.7099e+00, var(R): 1.5004e-08, var(L*R): 1.0420e-07, WD: 1.5495e-06
[2025-08-02 11:40:40] - Epoch 423/500,it:172584, Train Loss: 4.0819e-02, Val Loss: 4.1763e-02, best model: 414, LR: 5.7384e-05, epoch time: 88.31, snr: 5.3172e+00, var(R): 1.4910e-08, var(L*R): 1.0111e-07, WD: 1.5477e-06
[2025-08-02 11:42:08] - Epoch 424/500,it:172992, Train Loss: 4.0657e-02, Val Loss: 4.1744e-02, best model: 414, LR: 5.5932e-05, epoch time: 88.46, snr: 5.4846e+00, var(R): 1.5146e-08, var(L*R): 1.0537e-07, WD: 1.5453e-06
[2025-08-02 11:43:36] - Epoch 425/500,it:173400, Train Loss: 4.0483e-02, Val Loss: 4.1388e-02, best model: 425, LR: 5.4497e-05, epoch time: 88.33, snr: 5.3912e+00, var(R): 1.5232e-08, var(L*R): 1.0452e-07, WD: 1.5559e-06
[2025-08-02 11:45:05] - Epoch 426/500,it:173808, Train Loss: 4.0506e-02, Val Loss: 4.1720e-02, best model: 425, LR: 5.3079e-05, epoch time: 88.35, snr: 5.5618e+00, var(R): 1.5301e-08, var(L*R): 1.0595e-07, WD: 1.5548e-06
[2025-08-02 11:46:33] - Epoch 427/500,it:174216, Train Loss: 4.0307e-02, Val Loss: 4.1405e-02, best model: 425, LR: 5.1679e-05, epoch time: 88.27, snr: 5.3606e+00, var(R): 1.5281e-08, var(L*R): 1.0854e-07, WD: 1.5444e-06
[2025-08-02 11:48:01] - Epoch 428/500,it:174624, Train Loss: 4.0213e-02, Val Loss: 4.1346e-02, best model: 428, LR: 5.0297e-05, epoch time: 88.32, snr: 5.3700e+00, var(R): 1.5248e-08, var(L*R): 1.0859e-07, WD: 1.5445e-06
[2025-08-02 11:49:30] - Epoch 429/500,it:175032, Train Loss: 4.0042e-02, Val Loss: 4.0854e-02, best model: 429, LR: 4.8933e-05, epoch time: 88.22, snr: 5.4146e+00, var(R): 1.5457e-08, var(L*R): 1.1057e-07, WD: 1.5476e-06
[2025-08-02 11:50:58] - Epoch 430/500,it:175440, Train Loss: 3.9941e-02, Val Loss: 4.0822e-02, best model: 430, LR: 4.7586e-05, epoch time: 88.34, snr: 5.5582e+00, var(R): 1.5363e-08, var(L*R): 1.1049e-07, WD: 1.5362e-06
[2025-08-02 11:52:26] - Epoch 431/500,it:175848, Train Loss: 3.9982e-02, Val Loss: 4.1569e-02, best model: 430, LR: 4.6258e-05, epoch time: 88.05, snr: 5.7164e+00, var(R): 1.5471e-08, var(L*R): 1.1218e-07, WD: 1.5527e-06
[2025-08-02 11:53:54] - Epoch 432/500,it:176256, Train Loss: 3.9780e-02, Val Loss: 4.1364e-02, best model: 430, LR: 4.4947e-05, epoch time: 88.03, snr: 5.5023e+00, var(R): 1.5934e-08, var(L*R): 1.1451e-07, WD: 1.5492e-06
[2025-08-02 11:55:22] - Epoch 433/500,it:176664, Train Loss: 3.9655e-02, Val Loss: 4.1184e-02, best model: 430, LR: 4.3654e-05, epoch time: 88.06, snr: 5.4570e+00, var(R): 1.5879e-08, var(L*R): 1.1405e-07, WD: 1.5468e-06
[2025-08-02 11:56:50] - Epoch 434/500,it:177072, Train Loss: 3.9444e-02, Val Loss: 4.1248e-02, best model: 430, LR: 4.2379e-05, epoch time: 88.15, snr: 5.5402e+00, var(R): 1.5841e-08, var(L*R): 1.1497e-07, WD: 1.5354e-06
[2025-08-02 11:58:18] - Epoch 435/500,it:177480, Train Loss: 3.9401e-02, Val Loss: 4.0880e-02, best model: 430, LR: 4.1123e-05, epoch time: 88.06, snr: 5.2515e+00, var(R): 1.5567e-08, var(L*R): 1.1127e-07, WD: 1.5388e-06
[2025-08-02 11:59:47] - Epoch 436/500,it:177888, Train Loss: 3.9328e-02, Val Loss: 4.0475e-02, best model: 436, LR: 3.9884e-05, epoch time: 88.65, snr: 5.4616e+00, var(R): 1.5692e-08, var(L*R): 1.1396e-07, WD: 1.5344e-06
[2025-08-02 12:01:15] - Epoch 437/500,it:178296, Train Loss: 3.9168e-02, Val Loss: 4.0046e-02, best model: 437, LR: 3.8664e-05, epoch time: 88.20, snr: 5.5216e+00, var(R): 1.5500e-08, var(L*R): 1.1286e-07, WD: 1.5314e-06
[2025-08-02 12:02:43] - Epoch 438/500,it:178704, Train Loss: 3.9093e-02, Val Loss: 4.0379e-02, best model: 437, LR: 3.7461e-05, epoch time: 88.13, snr: 5.4726e+00, var(R): 1.5528e-08, var(L*R): 1.1609e-07, WD: 1.5406e-06
[2025-08-02 12:04:11] - Epoch 439/500,it:179112, Train Loss: 3.9061e-02, Val Loss: 4.0203e-02, best model: 437, LR: 3.6277e-05, epoch time: 88.23, snr: 5.6125e+00, var(R): 1.5769e-08, var(L*R): 1.1688e-07, WD: 1.5375e-06
[2025-08-02 12:05:40] - Epoch 440/500,it:179520, Train Loss: 3.8932e-02, Val Loss: 4.0376e-02, best model: 437, LR: 3.5112e-05, epoch time: 88.05, snr: 5.6745e+00, var(R): 1.5790e-08, var(L*R): 1.1873e-07, WD: 1.5194e-06
[2025-08-02 12:07:08] - Epoch 441/500,it:179928, Train Loss: 3.8819e-02, Val Loss: 3.9883e-02, best model: 441, LR: 3.3964e-05, epoch time: 88.37, snr: 5.4360e+00, var(R): 1.5580e-08, var(L*R): 1.1694e-07, WD: 1.5349e-06
[2025-08-02 12:08:36] - Epoch 442/500,it:180336, Train Loss: 3.8760e-02, Val Loss: 3.9847e-02, best model: 442, LR: 3.2836e-05, epoch time: 88.40, snr: 5.4521e+00, var(R): 1.5653e-08, var(L*R): 1.1858e-07, WD: 1.5355e-06
[2025-08-02 12:10:05] - Epoch 443/500,it:180744, Train Loss: 3.8647e-02, Val Loss: 3.9644e-02, best model: 443, LR: 3.1725e-05, epoch time: 89.05, snr: 5.3957e+00, var(R): 1.5429e-08, var(L*R): 1.1675e-07, WD: 1.5260e-06
[2025-08-02 12:11:34] - Epoch 444/500,it:181152, Train Loss: 3.8566e-02, Val Loss: 3.9430e-02, best model: 444, LR: 3.0633e-05, epoch time: 88.20, snr: 5.3806e+00, var(R): 1.5519e-08, var(L*R): 1.1740e-07, WD: 1.5241e-06
[2025-08-02 12:13:03] - Epoch 445/500,it:181560, Train Loss: 3.8485e-02, Val Loss: 3.9168e-02, best model: 445, LR: 2.9560e-05, epoch time: 89.19, snr: 5.4876e+00, var(R): 1.5405e-08, var(L*R): 1.1891e-07, WD: 1.5372e-06
[2025-08-02 12:14:31] - Epoch 446/500,it:181968, Train Loss: 3.8416e-02, Val Loss: 3.9095e-02, best model: 446, LR: 2.8505e-05, epoch time: 88.38, snr: 5.4795e+00, var(R): 1.5395e-08, var(L*R): 1.2041e-07, WD: 1.5292e-06
[2025-08-02 12:16:00] - Epoch 447/500,it:182376, Train Loss: 3.8342e-02, Val Loss: 3.9072e-02, best model: 447, LR: 2.7468e-05, epoch time: 88.74, snr: 5.5953e+00, var(R): 1.5612e-08, var(L*R): 1.2365e-07, WD: 1.5292e-06
[2025-08-02 12:17:28] - Epoch 448/500,it:182784, Train Loss: 3.8308e-02, Val Loss: 3.8937e-02, best model: 448, LR: 2.6451e-05, epoch time: 88.19, snr: 5.5115e+00, var(R): 1.5696e-08, var(L*R): 1.2279e-07, WD: 1.5290e-06
[2025-08-02 12:18:57] - Epoch 449/500,it:183192, Train Loss: 3.8213e-02, Val Loss: 3.8690e-02, best model: 449, LR: 2.5452e-05, epoch time: 88.53, snr: 5.6164e+00, var(R): 1.5581e-08, var(L*R): 1.2314e-07, WD: 1.5262e-06
[2025-08-02 12:20:25] - Epoch 450/500,it:183600, Train Loss: 3.8143e-02, Val Loss: 3.8644e-02, best model: 450, LR: 2.4472e-05, epoch time: 88.08, snr: 5.5525e+00, var(R): 1.5572e-08, var(L*R): 1.2478e-07, WD: 1.5251e-06
[2025-08-02 12:21:53] - Epoch 451/500,it:184008, Train Loss: 3.8075e-02, Val Loss: 3.8616e-02, best model: 451, LR: 2.3510e-05, epoch time: 88.16, snr: 5.5584e+00, var(R): 1.5610e-08, var(L*R): 1.2545e-07, WD: 1.5064e-06
[2025-08-02 12:23:21] - Epoch 452/500,it:184416, Train Loss: 3.7996e-02, Val Loss: 3.8412e-02, best model: 452, LR: 2.2568e-05, epoch time: 88.28, snr: 5.5743e+00, var(R): 1.5708e-08, var(L*R): 1.2744e-07, WD: 1.5183e-06
[2025-08-02 12:24:49] - Epoch 453/500,it:184824, Train Loss: 3.7918e-02, Val Loss: 3.8449e-02, best model: 452, LR: 2.1644e-05, epoch time: 88.14, snr: 5.6415e+00, var(R): 1.5690e-08, var(L*R): 1.2931e-07, WD: 1.5190e-06
[2025-08-02 12:26:17] - Epoch 454/500,it:185232, Train Loss: 3.7869e-02, Val Loss: 3.8004e-02, best model: 454, LR: 2.0739e-05, epoch time: 88.19, snr: 5.5499e+00, var(R): 1.5752e-08, var(L*R): 1.2845e-07, WD: 1.5270e-06
[2025-08-02 12:27:46] - Epoch 455/500,it:185640, Train Loss: 3.7808e-02, Val Loss: 3.8217e-02, best model: 454, LR: 1.9853e-05, epoch time: 88.50, snr: 5.7490e+00, var(R): 1.6150e-08, var(L*R): 1.3193e-07, WD: 1.5096e-06
[2025-08-02 12:29:14] - Epoch 456/500,it:186048, Train Loss: 3.7756e-02, Val Loss: 3.7983e-02, best model: 456, LR: 1.8986e-05, epoch time: 88.17, snr: 5.5441e+00, var(R): 1.5925e-08, var(L*R): 1.3189e-07, WD: 1.5187e-06
[2025-08-02 12:30:43] - Epoch 457/500,it:186456, Train Loss: 3.7701e-02, Val Loss: 3.7844e-02, best model: 457, LR: 1.8138e-05, epoch time: 88.63, snr: 5.6690e+00, var(R): 1.5997e-08, var(L*R): 1.3291e-07, WD: 1.5211e-06
[2025-08-02 12:32:11] - Epoch 458/500,it:186864, Train Loss: 3.7680e-02, Val Loss: 3.7885e-02, best model: 457, LR: 1.7309e-05, epoch time: 88.22, snr: 5.7649e+00, var(R): 1.6101e-08, var(L*R): 1.3407e-07, WD: 1.5079e-06
[2025-08-02 12:33:39] - Epoch 459/500,it:187272, Train Loss: 3.7612e-02, Val Loss: 3.7706e-02, best model: 459, LR: 1.6499e-05, epoch time: 88.35, snr: 5.6131e+00, var(R): 1.6173e-08, var(L*R): 1.3428e-07, WD: 1.5040e-06
[2025-08-02 12:35:08] - Epoch 460/500,it:187680, Train Loss: 3.7547e-02, Val Loss: 3.7748e-02, best model: 459, LR: 1.5708e-05, epoch time: 88.23, snr: 5.7157e+00, var(R): 1.6205e-08, var(L*R): 1.3511e-07, WD: 1.5126e-06
[2025-08-02 12:36:36] - Epoch 461/500,it:188088, Train Loss: 3.7516e-02, Val Loss: 3.7625e-02, best model: 461, LR: 1.4937e-05, epoch time: 88.33, snr: 5.6008e+00, var(R): 1.6139e-08, var(L*R): 1.3577e-07, WD: 1.5229e-06
[2025-08-02 12:38:04] - Epoch 462/500,it:188496, Train Loss: 3.7464e-02, Val Loss: 3.7578e-02, best model: 462, LR: 1.4184e-05, epoch time: 88.40, snr: 5.6266e+00, var(R): 1.6301e-08, var(L*R): 1.3621e-07, WD: 1.4970e-06
[2025-08-02 12:39:33] - Epoch 463/500,it:188904, Train Loss: 3.7395e-02, Val Loss: 3.7568e-02, best model: 463, LR: 1.3451e-05, epoch time: 88.57, snr: 5.7220e+00, var(R): 1.6468e-08, var(L*R): 1.3757e-07, WD: 1.5081e-06
[2025-08-02 12:41:01] - Epoch 464/500,it:189312, Train Loss: 3.7375e-02, Val Loss: 3.7505e-02, best model: 464, LR: 1.2737e-05, epoch time: 88.49, snr: 5.6466e+00, var(R): 1.6486e-08, var(L*R): 1.3845e-07, WD: 1.5058e-06
[2025-08-02 12:42:30] - Epoch 465/500,it:189720, Train Loss: 3.7309e-02, Val Loss: 3.7545e-02, best model: 464, LR: 1.2042e-05, epoch time: 88.42, snr: 5.6025e+00, var(R): 1.6421e-08, var(L*R): 1.3937e-07, WD: 1.5123e-06
[2025-08-02 12:43:58] - Epoch 466/500,it:190128, Train Loss: 3.7261e-02, Val Loss: 3.7477e-02, best model: 466, LR: 1.1366e-05, epoch time: 88.18, snr: 5.5756e+00, var(R): 1.6546e-08, var(L*R): 1.3969e-07, WD: 1.5020e-06
[2025-08-02 12:45:26] - Epoch 467/500,it:190536, Train Loss: 3.7204e-02, Val Loss: 3.7404e-02, best model: 467, LR: 1.0710e-05, epoch time: 87.99, snr: 5.5887e+00, var(R): 1.6606e-08, var(L*R): 1.4074e-07, WD: 1.5000e-06
[2025-08-02 12:46:54] - Epoch 468/500,it:190944, Train Loss: 3.7166e-02, Val Loss: 3.7406e-02, best model: 467, LR: 1.0072e-05, epoch time: 88.42, snr: 5.5946e+00, var(R): 1.6690e-08, var(L*R): 1.4127e-07, WD: 1.4947e-06
[2025-08-02 12:48:23] - Epoch 469/500,it:191352, Train Loss: 3.7123e-02, Val Loss: 3.7377e-02, best model: 469, LR: 9.4547e-06, epoch time: 88.18, snr: 5.5812e+00, var(R): 1.6672e-08, var(L*R): 1.4114e-07, WD: 1.5003e-06
[2025-08-02 12:49:52] - Epoch 470/500,it:191760, Train Loss: 3.7094e-02, Val Loss: 3.7362e-02, best model: 470, LR: 8.8564e-06, epoch time: 89.16, snr: 5.6336e+00, var(R): 1.6801e-08, var(L*R): 1.4191e-07, WD: 1.5019e-06
[2025-08-02 12:51:20] - Epoch 471/500,it:192168, Train Loss: 3.7050e-02, Val Loss: 3.7282e-02, best model: 471, LR: 8.2774e-06, epoch time: 88.46, snr: 5.5238e+00, var(R): 1.6837e-08, var(L*R): 1.4284e-07, WD: 1.5062e-06
[2025-08-02 12:52:49] - Epoch 472/500,it:192576, Train Loss: 3.7017e-02, Val Loss: 3.7232e-02, best model: 472, LR: 7.7178e-06, epoch time: 89.04, snr: 5.4873e+00, var(R): 1.6915e-08, var(L*R): 1.4356e-07, WD: 1.5145e-06
[2025-08-02 12:54:18] - Epoch 473/500,it:192984, Train Loss: 3.6988e-02, Val Loss: 3.7200e-02, best model: 473, LR: 7.1777e-06, epoch time: 88.61, snr: 5.5407e+00, var(R): 1.6981e-08, var(L*R): 1.4419e-07, WD: 1.4972e-06
[2025-08-02 12:55:47] - Epoch 474/500,it:193392, Train Loss: 3.6963e-02, Val Loss: 3.7164e-02, best model: 474, LR: 6.6570e-06, epoch time: 88.97, snr: 5.5544e+00, var(R): 1.7057e-08, var(L*R): 1.4585e-07, WD: 1.4923e-06
[2025-08-02 12:57:15] - Epoch 475/500,it:193800, Train Loss: 3.6944e-02, Val Loss: 3.7124e-02, best model: 475, LR: 6.1558e-06, epoch time: 88.50, snr: 5.5524e+00, var(R): 1.7149e-08, var(L*R): 1.4722e-07, WD: 1.4942e-06
[2025-08-02 12:58:44] - Epoch 476/500,it:194208, Train Loss: 3.6918e-02, Val Loss: 3.7092e-02, best model: 476, LR: 5.6741e-06, epoch time: 88.49, snr: 5.4716e+00, var(R): 1.7115e-08, var(L*R): 1.4781e-07, WD: 1.5047e-06
[2025-08-02 13:00:12] - Epoch 477/500,it:194616, Train Loss: 3.6882e-02, Val Loss: 3.7048e-02, best model: 477, LR: 5.2119e-06, epoch time: 88.48, snr: 5.5350e+00, var(R): 1.7137e-08, var(L*R): 1.4933e-07, WD: 1.4893e-06
[2025-08-02 13:01:41] - Epoch 478/500,it:195024, Train Loss: 3.6855e-02, Val Loss: 3.6999e-02, best model: 478, LR: 4.7693e-06, epoch time: 88.18, snr: 5.4623e+00, var(R): 1.7112e-08, var(L*R): 1.4982e-07, WD: 1.4920e-06
[2025-08-02 13:03:09] - Epoch 479/500,it:195432, Train Loss: 3.6839e-02, Val Loss: 3.6957e-02, best model: 479, LR: 4.3462e-06, epoch time: 88.18, snr: 5.5217e+00, var(R): 1.7037e-08, var(L*R): 1.5045e-07, WD: 1.5061e-06
[2025-08-02 13:04:37] - Epoch 480/500,it:195840, Train Loss: 3.6815e-02, Val Loss: 3.6932e-02, best model: 480, LR: 3.9426e-06, epoch time: 88.21, snr: 5.5791e+00, var(R): 1.7070e-08, var(L*R): 1.5179e-07, WD: 1.4948e-06
[2025-08-02 13:06:05] - Epoch 481/500,it:196248, Train Loss: 3.6791e-02, Val Loss: 3.6921e-02, best model: 481, LR: 3.5587e-06, epoch time: 88.30, snr: 5.6075e+00, var(R): 1.7078e-08, var(L*R): 1.5282e-07, WD: 1.4994e-06
[2025-08-02 13:07:34] - Epoch 482/500,it:196656, Train Loss: 3.6770e-02, Val Loss: 3.6907e-02, best model: 482, LR: 3.1943e-06, epoch time: 88.43, snr: 5.6291e+00, var(R): 1.7050e-08, var(L*R): 1.5386e-07, WD: 1.5073e-06
[2025-08-02 13:09:02] - Epoch 483/500,it:197064, Train Loss: 3.6751e-02, Val Loss: 3.6895e-02, best model: 483, LR: 2.8496e-06, epoch time: 88.25, snr: 5.6369e+00, var(R): 1.7007e-08, var(L*R): 1.5461e-07, WD: 1.4978e-06
[2025-08-02 13:10:30] - Epoch 484/500,it:197472, Train Loss: 3.6738e-02, Val Loss: 3.6893e-02, best model: 484, LR: 2.5245e-06, epoch time: 88.57, snr: 5.5964e+00, var(R): 1.6980e-08, var(L*R): 1.5499e-07, WD: 1.4838e-06
[2025-08-02 13:11:59] - Epoch 485/500,it:197880, Train Loss: 3.6720e-02, Val Loss: 3.6883e-02, best model: 485, LR: 2.2190e-06, epoch time: 88.21, snr: 5.6019e+00, var(R): 1.7034e-08, var(L*R): 1.5644e-07, WD: 1.4861e-06
[2025-08-02 13:13:27] - Epoch 486/500,it:198288, Train Loss: 3.6703e-02, Val Loss: 3.6853e-02, best model: 486, LR: 1.9332e-06, epoch time: 88.06, snr: 5.5466e+00, var(R): 1.7014e-08, var(L*R): 1.5690e-07, WD: 1.4811e-06
[2025-08-02 13:14:55] - Epoch 487/500,it:198696, Train Loss: 3.6687e-02, Val Loss: 3.6857e-02, best model: 486, LR: 1.6670e-06, epoch time: 88.15, snr: 5.5505e+00, var(R): 1.7044e-08, var(L*R): 1.5768e-07, WD: 1.4922e-06
[2025-08-02 13:16:23] - Epoch 488/500,it:199104, Train Loss: 3.6669e-02, Val Loss: 3.6860e-02, best model: 486, LR: 1.4205e-06, epoch time: 88.39, snr: 5.5304e+00, var(R): 1.7047e-08, var(L*R): 1.5840e-07, WD: 1.4940e-06
[2025-08-02 13:17:51] - Epoch 489/500,it:199512, Train Loss: 3.6652e-02, Val Loss: 3.6859e-02, best model: 486, LR: 1.1937e-06, epoch time: 87.99, snr: 5.4648e+00, var(R): 1.7026e-08, var(L*R): 1.5931e-07, WD: 1.4853e-06
[2025-08-02 13:19:19] - Epoch 490/500,it:199920, Train Loss: 3.6638e-02, Val Loss: 3.6823e-02, best model: 490, LR: 9.8664e-07, epoch time: 87.91, snr: 5.4316e+00, var(R): 1.6985e-08, var(L*R): 1.5937e-07, WD: 1.4599e-06
[2025-08-02 13:20:47] - Epoch 491/500,it:200328, Train Loss: 3.6625e-02, Val Loss: 3.6811e-02, best model: 491, LR: 7.9922e-07, epoch time: 88.10, snr: 5.4530e+00, var(R): 1.6969e-08, var(L*R): 1.5995e-07, WD: 1.4727e-06
[2025-08-02 13:22:16] - Epoch 492/500,it:200736, Train Loss: 3.6615e-02, Val Loss: 3.6804e-02, best model: 492, LR: 6.3152e-07, epoch time: 88.37, snr: 5.4637e+00, var(R): 1.6962e-08, var(L*R): 1.6064e-07, WD: 1.4777e-06
[2025-08-02 13:23:44] - Epoch 493/500,it:201144, Train Loss: 3.6607e-02, Val Loss: 3.6794e-02, best model: 493, LR: 4.8353e-07, epoch time: 88.62, snr: 5.4751e+00, var(R): 1.6929e-08, var(L*R): 1.6153e-07, WD: 1.4774e-06
[2025-08-02 13:25:12] - Epoch 494/500,it:201552, Train Loss: 3.6598e-02, Val Loss: 3.6788e-02, best model: 494, LR: 3.5526e-07, epoch time: 88.16, snr: 5.4677e+00, var(R): 1.6877e-08, var(L*R): 1.6218e-07, WD: 1.4755e-06
[2025-08-02 13:26:41] - Epoch 495/500,it:201960, Train Loss: 3.6592e-02, Val Loss: 3.6783e-02, best model: 495, LR: 2.4672e-07, epoch time: 88.84, snr: 5.4753e+00, var(R): 1.6870e-08, var(L*R): 1.6302e-07, WD: 1.4811e-06
[2025-08-02 13:28:10] - Epoch 496/500,it:202368, Train Loss: 3.6586e-02, Val Loss: 3.6779e-02, best model: 496, LR: 1.5791e-07, epoch time: 88.23, snr: 5.4908e+00, var(R): 1.6867e-08, var(L*R): 1.6396e-07, WD: 1.4759e-06
[2025-08-02 13:29:38] - Epoch 497/500,it:202776, Train Loss: 3.6582e-02, Val Loss: 3.6778e-02, best model: 497, LR: 8.8824e-08, epoch time: 88.36, snr: 5.5016e+00, var(R): 1.6843e-08, var(L*R): 1.6453e-07, WD: 1.4733e-06
[2025-08-02 13:31:06] - Epoch 498/500,it:203184, Train Loss: 3.6577e-02, Val Loss: 3.6776e-02, best model: 498, LR: 3.9478e-08, epoch time: 88.24, snr: 5.4959e+00, var(R): 1.6817e-08, var(L*R): 1.6510e-07, WD: 1.4722e-06
[2025-08-02 13:32:34] - Epoch 499/500,it:203592, Train Loss: 3.6574e-02, Val Loss: 3.6775e-02, best model: 499, LR: 9.8696e-09, epoch time: 88.19, snr: 5.4828e+00, var(R): 1.6794e-08, var(L*R): 1.6554e-07, WD: 1.4702e-06
[2025-08-02 13:34:01] - Epoch 500/500,it:204000, Train Loss: 3.6571e-02, Val Loss: 3.6775e-02, best model: 499, LR: 0.0000e+00, epoch time: 86.74, snr: 5.4834e+00, var(R): 1.6785e-08, var(L*R): 1.6627e-07, WD: 1.4702e-06
Training finished.
Test Loss: 3.6936e-02
