## SLURM PROLOG ###############################################################
##    Job ID : 12241757
##  Job Name : rba_sample
##  Nodelist : gpu2107
##      CPUs : 1
##  Mem/Node : 65536 MB
## Directory : /oscar/data/gk/jdtoscan
##   Job Started : Sun Aug  3 00:51:57 EDT 2025
###############################################################################
Sun Aug  3 00:51:57 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:41:00.0 Off |                  N/A |
| 34%   34C    P8              22W / 350W |     25MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     51662      G   /usr/libexec/Xorg                            17MiB |
+---------------------------------------------------------------------------------------+
Using device: cuda

Train Dataset
x:  (40800, 1, 64, 64)
y:  (40800, 1, 64, 64)
t:  (40800,)


Validation Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)


Test Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)

Lambda:  (40800, 1, 64, 64)
Par: 
 {'nx': 64, 'ny': 64, 'nf': 1, 'd_emb': 128, 'lb': 1, 'lf': 51, 'num_epochs': 500, 'inp_shift': np.float64(0.007669870189599345), 'inp_scale': np.float64(0.061450183570653995), 'out_shift': np.float64(-0.001635048307912137), 'out_scale': np.float64(0.03807830166415873), 't_shift': np.float64(0.0), 't_scale': np.float64(1.0), 'eta': 0.1, 'gamma': 0.99, 'do_rba': True, 'get_snr': True, 'Lambda_max': 9.999999999999991}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
Unet2D                                                  [1, 1, 64, 64]            --
├─Conv2d: 1-1                                           [1, 16, 64, 64]           2,368
├─Sequential: 1-2                                       [1, 64]                   --
│    └─SinusoidalPosEmb: 2-1                            [1, 16]                   --
│    └─Linear: 2-2                                      [1, 64]                   1,088
│    └─GELU: 2-3                                        [1, 64]                   --
│    └─Linear: 2-4                                      [1, 64]                   4,160
├─ModuleList: 1-3                                       --                        --
│    └─ModuleList: 2-5                                  --                        --
│    │    └─ResnetBlock: 3-1                            [1, 16, 64, 64]           6,784
│    │    └─ResnetBlock: 3-2                            [1, 16, 64, 64]           6,784
│    │    └─Residual: 3-3                               [1, 16, 64, 64]           8,240
│    │    └─Sequential: 3-4                             [1, 16, 32, 32]           1,040
│    └─ModuleList: 2-6                                  --                        --
│    │    └─ResnetBlock: 3-5                            [1, 16, 32, 32]           6,784
│    │    └─ResnetBlock: 3-6                            [1, 16, 32, 32]           6,784
│    │    └─Residual: 3-7                               [1, 16, 32, 32]           8,240
│    │    └─Sequential: 3-8                             [1, 32, 16, 16]           2,080
│    └─ModuleList: 2-7                                  --                        --
│    │    └─ResnetBlock: 3-9                            [1, 32, 16, 16]           22,784
│    │    └─ResnetBlock: 3-10                           [1, 32, 16, 16]           22,784
│    │    └─Residual: 3-11                              [1, 32, 16, 16]           16,480
│    │    └─Sequential: 3-12                            [1, 64, 8, 8]             8,256
│    └─ModuleList: 2-8                                  --                        --
│    │    └─ResnetBlock: 3-13                           [1, 64, 8, 8]             82,432
│    │    └─ResnetBlock: 3-14                           [1, 64, 8, 8]             82,432
│    │    └─Residual: 3-15                              [1, 64, 8, 8]             32,960
│    │    └─Conv2d: 3-16                                [1, 128, 8, 8]            73,856
├─ResnetBlock: 1-4                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-9                                  [1, 256]                  --
│    │    └─SiLU: 3-17                                  [1, 64]                   --
│    │    └─Linear: 3-18                                [1, 256]                  16,640
│    └─Block: 2-10                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-19                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-20                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-21                                  [1, 128, 8, 8]            --
│    └─Block: 2-11                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-22                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-23                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-24                                  [1, 128, 8, 8]            --
│    └─Identity: 2-12                                   [1, 128, 8, 8]            --
├─Residual: 1-5                                         [1, 128, 8, 8]            --
│    └─PreNorm: 2-13                                    [1, 128, 8, 8]            --
│    │    └─LayerNorm: 3-25                             [1, 128, 8, 8]            128
│    │    └─Attention: 3-26                             [1, 128, 8, 8]            65,664
├─ResnetBlock: 1-6                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-14                                 [1, 256]                  --
│    │    └─SiLU: 3-27                                  [1, 64]                   --
│    │    └─Linear: 3-28                                [1, 256]                  16,640
│    └─Block: 2-15                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-29                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-30                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-31                                  [1, 128, 8, 8]            --
│    └─Block: 2-16                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-32                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-33                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-34                                  [1, 128, 8, 8]            --
│    └─Identity: 2-17                                   [1, 128, 8, 8]            --
├─ModuleList: 1-7                                       --                        --
│    └─ModuleList: 2-18                                 --                        --
│    │    └─ResnetBlock: 3-35                           [1, 128, 8, 8]            410,752
│    │    └─ResnetBlock: 3-36                           [1, 128, 8, 8]            410,752
│    │    └─Residual: 3-37                              [1, 128, 8, 8]            65,920
│    │    └─Sequential: 3-38                            [1, 64, 16, 16]           73,792
│    └─ModuleList: 2-19                                 --                        --
│    │    └─ResnetBlock: 3-39                           [1, 64, 16, 16]           107,072
│    │    └─ResnetBlock: 3-40                           [1, 64, 16, 16]           107,072
│    │    └─Residual: 3-41                              [1, 64, 16, 16]           32,960
│    │    └─Sequential: 3-42                            [1, 32, 32, 32]           18,464
│    └─ModuleList: 2-20                                 --                        --
│    │    └─ResnetBlock: 3-43                           [1, 32, 32, 32]           28,960
│    │    └─ResnetBlock: 3-44                           [1, 32, 32, 32]           28,960
│    │    └─Residual: 3-45                              [1, 32, 32, 32]           16,480
│    │    └─Sequential: 3-46                            [1, 16, 64, 64]           4,624
│    └─ModuleList: 2-21                                 --                        --
│    │    └─ResnetBlock: 3-47                           [1, 16, 64, 64]           9,616
│    │    └─ResnetBlock: 3-48                           [1, 16, 64, 64]           9,616
│    │    └─Residual: 3-49                              [1, 16, 64, 64]           8,240
│    │    └─Conv2d: 3-50                                [1, 16, 64, 64]           2,320
├─ResnetBlock: 1-8                                      [1, 16, 64, 64]           --
│    └─Sequential: 2-22                                 [1, 32]                   --
│    │    └─SiLU: 3-51                                  [1, 64]                   --
│    │    └─Linear: 3-52                                [1, 32]                   2,080
│    └─Block: 2-23                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-53                                [1, 16, 64, 64]           4,624
│    │    └─GroupNorm: 3-54                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-55                                  [1, 16, 64, 64]           --
│    └─Block: 2-24                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-56                                [1, 16, 64, 64]           2,320
│    │    └─GroupNorm: 3-57                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-58                                  [1, 16, 64, 64]           --
│    └─Conv2d: 2-25                                     [1, 16, 64, 64]           528
├─Conv2d: 1-9                                           [1, 1, 64, 64]            17
=========================================================================================================
Total params: 2,432,001
Trainable params: 2,432,001
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 545.94
=========================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 60.28
Params size (MB): 9.73
Estimated Total Size (MB): 70.02
=========================================================================================================
[2025-08-03 00:53:36] - Epoch 1/500,it:408, Train Loss: 4.5141e+00, Val Loss: 7.5392e-01, best model: 1, LR: 9.9999e-04, epoch time: 87.98, snr: 4.5227e+00, var(R): 5.9177e-05, var(L*R): 5.9177e-05, WD: 0.0000e+00
[2025-08-03 00:55:03] - Epoch 2/500,it:816, Train Loss: 2.9029e+00, Val Loss: 4.7710e-01, best model: 2, LR: 9.9996e-04, epoch time: 87.78, snr: 9.6031e+00, var(R): 4.3526e-06, var(L*R): 4.5318e-06, WD: 4.8339e-07
[2025-08-03 00:56:31] - Epoch 3/500,it:1224, Train Loss: 1.5624e+00, Val Loss: 2.3553e-01, best model: 3, LR: 9.9991e-04, epoch time: 87.66, snr: 9.6448e+00, var(R): 1.0766e-06, var(L*R): 1.1393e-06, WD: 7.3074e-07
[2025-08-03 00:57:59] - Epoch 4/500,it:1632, Train Loss: 9.8668e-01, Val Loss: 1.9369e-01, best model: 4, LR: 9.9984e-04, epoch time: 87.63, snr: 1.0027e+01, var(R): 7.3392e-08, var(L*R): 7.8466e-08, WD: 9.0920e-07
[2025-08-03 00:59:26] - Epoch 5/500,it:2040, Train Loss: 9.1848e-01, Val Loss: 1.4709e-01, best model: 5, LR: 9.9975e-04, epoch time: 87.60, snr: 9.8608e+00, var(R): 3.0226e-08, var(L*R): 3.2512e-08, WD: 1.0778e-06
[2025-08-03 01:00:54] - Epoch 6/500,it:2448, Train Loss: 8.4385e-01, Val Loss: 1.2937e-01, best model: 6, LR: 9.9964e-04, epoch time: 87.65, snr: 6.6390e+00, var(R): 1.1361e-08, var(L*R): 1.2841e-08, WD: 1.2421e-06
[2025-08-03 01:02:21] - Epoch 7/500,it:2856, Train Loss: 8.1489e-01, Val Loss: 2.1367e-01, best model: 6, LR: 9.9952e-04, epoch time: 87.55, snr: 2.1258e+00, var(R): 7.8666e-09, var(L*R): 9.0497e-09, WD: 1.4006e-06
[2025-08-03 01:03:49] - Epoch 8/500,it:3264, Train Loss: 7.3281e-01, Val Loss: 1.0954e-01, best model: 8, LR: 9.9937e-04, epoch time: 87.71, snr: 1.5428e+01, var(R): 1.1475e-07, var(L*R): 1.5251e-07, WD: 1.5543e-06
[2025-08-03 01:05:17] - Epoch 9/500,it:3672, Train Loss: 6.4169e-01, Val Loss: 1.2179e-01, best model: 8, LR: 9.9920e-04, epoch time: 87.57, snr: 2.6790e+00, var(R): 3.6279e-09, var(L*R): 4.4346e-09, WD: 1.7095e-06
[2025-08-03 01:06:44] - Epoch 10/500,it:4080, Train Loss: 7.0359e-01, Val Loss: 1.3387e-01, best model: 8, LR: 9.9901e-04, epoch time: 87.70, snr: 4.7941e+00, var(R): 5.7654e-09, var(L*R): 6.8389e-09, WD: 1.8553e-06
[2025-08-03 01:08:12] - Epoch 11/500,it:4488, Train Loss: 6.0232e-01, Val Loss: 9.8235e-02, best model: 11, LR: 9.9881e-04, epoch time: 87.52, snr: 2.6872e+00, var(R): 7.4098e-09, var(L*R): 9.4077e-09, WD: 2.0055e-06
[2025-08-03 01:09:39] - Epoch 12/500,it:4896, Train Loss: 5.6811e-01, Val Loss: 1.3334e-01, best model: 11, LR: 9.9858e-04, epoch time: 87.60, snr: 7.5288e-01, var(R): 2.3140e-09, var(L*R): 2.8364e-09, WD: 2.1490e-06
[2025-08-03 01:11:07] - Epoch 13/500,it:5304, Train Loss: 6.2359e-01, Val Loss: 1.0718e-01, best model: 11, LR: 9.9833e-04, epoch time: 87.70, snr: 1.5110e+01, var(R): 7.1727e-09, var(L*R): 9.6246e-09, WD: 2.2942e-06
[2025-08-03 01:12:35] - Epoch 14/500,it:5712, Train Loss: 5.4842e-01, Val Loss: 1.0248e-01, best model: 11, LR: 9.9807e-04, epoch time: 87.65, snr: 7.1860e+00, var(R): 3.9639e-09, var(L*R): 5.1736e-09, WD: 2.4425e-06
[2025-08-03 01:14:02] - Epoch 15/500,it:6120, Train Loss: 6.7555e-01, Val Loss: 1.0703e-01, best model: 11, LR: 9.9778e-04, epoch time: 87.43, snr: 1.4664e+01, var(R): 3.0355e-09, var(L*R): 3.9666e-09, WD: 2.5847e-06
[2025-08-03 01:15:30] - Epoch 16/500,it:6528, Train Loss: 4.8367e-01, Val Loss: 1.3757e-01, best model: 11, LR: 9.9748e-04, epoch time: 87.58, snr: 8.7905e+00, var(R): 4.9235e-09, var(L*R): 7.7841e-09, WD: 2.7403e-06
[2025-08-03 01:16:58] - Epoch 17/500,it:6936, Train Loss: 4.9404e-01, Val Loss: 1.6075e-01, best model: 11, LR: 9.9715e-04, epoch time: 87.66, snr: 1.4200e+01, var(R): 2.5027e-08, var(L*R): 4.7917e-08, WD: 2.8814e-06
[2025-08-03 01:18:25] - Epoch 18/500,it:7344, Train Loss: 4.7879e-01, Val Loss: 9.6055e-02, best model: 18, LR: 9.9681e-04, epoch time: 87.96, snr: 1.1601e+01, var(R): 2.3003e-08, var(L*R): 4.0871e-08, WD: 3.0222e-06
[2025-08-03 01:19:54] - Epoch 19/500,it:7752, Train Loss: 6.4282e-01, Val Loss: 8.0423e-02, best model: 19, LR: 9.9644e-04, epoch time: 88.19, snr: 1.6064e+01, var(R): 2.1960e-09, var(L*R): 3.1700e-09, WD: 3.1657e-06
[2025-08-03 01:21:22] - Epoch 20/500,it:8160, Train Loss: 4.4929e-01, Val Loss: 8.9960e-02, best model: 19, LR: 9.9606e-04, epoch time: 88.09, snr: 8.5160e-01, var(R): 1.3916e-09, var(L*R): 2.0500e-09, WD: 3.3233e-06
[2025-08-03 01:22:50] - Epoch 21/500,it:8568, Train Loss: 4.7929e-01, Val Loss: 8.2156e-02, best model: 19, LR: 9.9565e-04, epoch time: 87.84, snr: 1.6736e+01, var(R): 1.6102e-09, var(L*R): 2.3989e-09, WD: 3.4614e-06
[2025-08-03 01:24:17] - Epoch 22/500,it:8976, Train Loss: 5.1358e-01, Val Loss: 7.7319e-02, best model: 22, LR: 9.9523e-04, epoch time: 87.65, snr: 6.9530e-01, var(R): 1.3840e-09, var(L*R): 2.0908e-09, WD: 3.6116e-06
[2025-08-03 01:25:45] - Epoch 23/500,it:9384, Train Loss: 5.6739e-01, Val Loss: 1.0682e-01, best model: 22, LR: 9.9479e-04, epoch time: 88.01, snr: 7.4787e+00, var(R): 1.2942e-09, var(L*R): 2.6376e-09, WD: 3.7577e-06
[2025-08-03 01:27:13] - Epoch 24/500,it:9792, Train Loss: 4.6591e-01, Val Loss: 6.6713e-02, best model: 24, LR: 9.9433e-04, epoch time: 88.08, snr: 1.2395e+01, var(R): 3.5509e-09, var(L*R): 5.1474e-09, WD: 3.9137e-06
[2025-08-03 01:28:41] - Epoch 25/500,it:10200, Train Loss: 4.9099e-01, Val Loss: 7.2373e-02, best model: 24, LR: 9.9384e-04, epoch time: 87.95, snr: 6.5166e-01, var(R): 7.8783e-10, var(L*R): 1.2139e-09, WD: 4.0585e-06
[2025-08-03 01:30:09] - Epoch 26/500,it:10608, Train Loss: 4.7103e-01, Val Loss: 6.0306e-02, best model: 26, LR: 9.9334e-04, epoch time: 87.79, snr: 7.2779e+00, var(R): 8.6193e-10, var(L*R): 1.3588e-09, WD: 4.2067e-06
[2025-08-03 01:31:37] - Epoch 27/500,it:11016, Train Loss: 4.6782e-01, Val Loss: 1.0139e-01, best model: 26, LR: 9.9282e-04, epoch time: 87.82, snr: 5.6033e-01, var(R): 3.3362e-10, var(L*R): 5.7084e-10, WD: 4.3590e-06
[2025-08-03 01:33:05] - Epoch 28/500,it:11424, Train Loss: 4.5220e-01, Val Loss: 8.2008e-02, best model: 26, LR: 9.9228e-04, epoch time: 88.09, snr: 3.9238e+00, var(R): 3.0474e-09, var(L*R): 4.7274e-09, WD: 4.5068e-06
[2025-08-03 01:34:33] - Epoch 29/500,it:11832, Train Loss: 4.5659e-01, Val Loss: 9.8418e-02, best model: 26, LR: 9.9172e-04, epoch time: 88.23, snr: 1.0599e+01, var(R): 1.2565e-09, var(L*R): 2.5500e-09, WD: 4.6587e-06
[2025-08-03 01:36:01] - Epoch 30/500,it:12240, Train Loss: 4.8460e-01, Val Loss: 7.9250e-02, best model: 26, LR: 9.9114e-04, epoch time: 87.97, snr: 2.0825e+01, var(R): 1.6468e-09, var(L*R): 2.9630e-09, WD: 4.8099e-06
[2025-08-03 01:37:29] - Epoch 31/500,it:12648, Train Loss: 4.8472e-01, Val Loss: 9.8352e-02, best model: 26, LR: 9.9055e-04, epoch time: 88.06, snr: 5.6359e+00, var(R): 1.3156e-09, var(L*R): 3.1224e-09, WD: 4.9628e-06
[2025-08-03 01:38:57] - Epoch 32/500,it:13056, Train Loss: 4.2000e-01, Val Loss: 8.1028e-02, best model: 26, LR: 9.8993e-04, epoch time: 87.99, snr: 2.0192e+01, var(R): 2.2388e-09, var(L*R): 4.0852e-09, WD: 5.1174e-06
[2025-08-03 01:40:25] - Epoch 33/500,it:13464, Train Loss: 4.8995e-01, Val Loss: 6.2551e-02, best model: 26, LR: 9.8929e-04, epoch time: 87.86, snr: 2.7239e+00, var(R): 1.6761e-09, var(L*R): 3.9028e-09, WD: 5.2679e-06
[2025-08-03 01:41:53] - Epoch 34/500,it:13872, Train Loss: 4.8133e-01, Val Loss: 7.7337e-02, best model: 26, LR: 9.8863e-04, epoch time: 87.93, snr: 8.8064e+00, var(R): 3.9843e-10, var(L*R): 9.2377e-10, WD: 5.4230e-06
[2025-08-03 01:43:21] - Epoch 35/500,it:14280, Train Loss: 3.9694e-01, Val Loss: 6.3735e-02, best model: 26, LR: 9.8796e-04, epoch time: 88.16, snr: 5.7372e+00, var(R): 8.7802e-10, var(L*R): 2.2370e-09, WD: 5.5764e-06
[2025-08-03 01:44:49] - Epoch 36/500,it:14688, Train Loss: 3.8733e-01, Val Loss: 6.2666e-02, best model: 26, LR: 9.8726e-04, epoch time: 88.12, snr: 1.4807e+00, var(R): 3.9451e-10, var(L*R): 7.5896e-10, WD: 5.7338e-06
[2025-08-03 01:46:17] - Epoch 37/500,it:15096, Train Loss: 4.0039e-01, Val Loss: 1.1919e-01, best model: 26, LR: 9.8655e-04, epoch time: 87.91, snr: 1.2141e+01, var(R): 4.1636e-10, var(L*R): 1.0307e-09, WD: 5.8833e-06
[2025-08-03 01:47:45] - Epoch 38/500,it:15504, Train Loss: 4.1588e-01, Val Loss: 1.0767e-01, best model: 26, LR: 9.8582e-04, epoch time: 88.25, snr: 1.7922e+01, var(R): 6.4005e-09, var(L*R): 1.7675e-08, WD: 6.0344e-06
[2025-08-03 01:49:13] - Epoch 39/500,it:15912, Train Loss: 4.2173e-01, Val Loss: 1.3104e-01, best model: 26, LR: 9.8506e-04, epoch time: 88.00, snr: 1.1974e+00, var(R): 4.0352e-09, var(L*R): 7.6391e-09, WD: 6.1917e-06
[2025-08-03 01:50:42] - Epoch 40/500,it:16320, Train Loss: 3.9118e-01, Val Loss: 7.2533e-02, best model: 26, LR: 9.8429e-04, epoch time: 88.10, snr: 2.2556e+01, var(R): 6.1531e-09, var(L*R): 1.5054e-08, WD: 6.3392e-06
[2025-08-03 01:52:10] - Epoch 41/500,it:16728, Train Loss: 4.1625e-01, Val Loss: 1.0923e-01, best model: 26, LR: 9.8350e-04, epoch time: 87.97, snr: 3.7657e+00, var(R): 6.6829e-10, var(L*R): 1.4405e-09, WD: 6.5013e-06
[2025-08-03 01:53:38] - Epoch 42/500,it:17136, Train Loss: 4.3241e-01, Val Loss: 8.0524e-02, best model: 26, LR: 9.8269e-04, epoch time: 88.07, snr: 2.2572e+01, var(R): 1.3112e-08, var(L*R): 7.2531e-08, WD: 6.6500e-06
[2025-08-03 01:55:06] - Epoch 43/500,it:17544, Train Loss: 4.7036e-01, Val Loss: 8.0975e-02, best model: 26, LR: 9.8186e-04, epoch time: 88.05, snr: 1.1030e+01, var(R): 1.4765e-09, var(L*R): 5.3279e-09, WD: 6.8129e-06
[2025-08-03 01:56:34] - Epoch 44/500,it:17952, Train Loss: 3.8934e-01, Val Loss: 6.8851e-02, best model: 26, LR: 9.8101e-04, epoch time: 87.86, snr: 1.4031e+01, var(R): 1.5688e-09, var(L*R): 5.4984e-09, WD: 6.9731e-06
[2025-08-03 01:58:01] - Epoch 45/500,it:18360, Train Loss: 4.2732e-01, Val Loss: 7.5384e-02, best model: 26, LR: 9.8015e-04, epoch time: 87.84, snr: 7.8662e+00, var(R): 5.8445e-10, var(L*R): 1.5889e-09, WD: 7.1302e-06
[2025-08-03 01:59:29] - Epoch 46/500,it:18768, Train Loss: 3.6927e-01, Val Loss: 8.4589e-02, best model: 26, LR: 9.7926e-04, epoch time: 88.00, snr: 1.2145e+01, var(R): 7.4582e-10, var(L*R): 1.7018e-09, WD: 7.2975e-06
[2025-08-03 02:00:57] - Epoch 47/500,it:19176, Train Loss: 3.7414e-01, Val Loss: 5.3362e-02, best model: 47, LR: 9.7836e-04, epoch time: 87.94, snr: 1.4958e+01, var(R): 1.2717e-09, var(L*R): 3.1727e-09, WD: 7.4447e-06
[2025-08-03 02:02:25] - Epoch 48/500,it:19584, Train Loss: 3.7850e-01, Val Loss: 9.6828e-02, best model: 47, LR: 9.7743e-04, epoch time: 87.94, snr: 1.1234e+00, var(R): 2.9366e-10, var(L*R): 1.1112e-09, WD: 7.5993e-06
[2025-08-03 02:03:53] - Epoch 49/500,it:19992, Train Loss: 3.9073e-01, Val Loss: 8.9603e-02, best model: 47, LR: 9.7649e-04, epoch time: 87.89, snr: 1.9639e+01, var(R): 2.1630e-09, var(L*R): 4.4598e-09, WD: 7.7592e-06
[2025-08-03 02:05:21] - Epoch 50/500,it:20400, Train Loss: 4.0887e-01, Val Loss: 9.1028e-02, best model: 47, LR: 9.7553e-04, epoch time: 87.88, snr: 1.0788e+01, var(R): 1.9514e-09, var(L*R): 8.2792e-09, WD: 7.9149e-06
[2025-08-03 02:06:49] - Epoch 51/500,it:20808, Train Loss: 4.1556e-01, Val Loss: 1.1416e-01, best model: 47, LR: 9.7455e-04, epoch time: 87.88, snr: 1.8580e+01, var(R): 5.8697e-09, var(L*R): 4.4883e-08, WD: 8.0741e-06
[2025-08-03 02:08:17] - Epoch 52/500,it:21216, Train Loss: 4.0172e-01, Val Loss: 6.7079e-02, best model: 47, LR: 9.7355e-04, epoch time: 87.67, snr: 2.0721e+01, var(R): 3.9743e-09, var(L*R): 1.3003e-08, WD: 8.2406e-06
[2025-08-03 02:09:45] - Epoch 53/500,it:21624, Train Loss: 3.3743e-01, Val Loss: 8.9258e-02, best model: 47, LR: 9.7253e-04, epoch time: 87.92, snr: 1.6514e+01, var(R): 1.0518e-09, var(L*R): 7.4901e-09, WD: 8.3977e-06
[2025-08-03 02:11:12] - Epoch 54/500,it:22032, Train Loss: 4.3263e-01, Val Loss: 1.0068e-01, best model: 47, LR: 9.7150e-04, epoch time: 87.90, snr: 2.0991e+01, var(R): 2.6892e-09, var(L*R): 1.9475e-08, WD: 8.5541e-06
[2025-08-03 02:12:40] - Epoch 55/500,it:22440, Train Loss: 4.1698e-01, Val Loss: 7.1567e-02, best model: 47, LR: 9.7044e-04, epoch time: 87.99, snr: 2.0534e+01, var(R): 6.6244e-09, var(L*R): 5.5107e-08, WD: 8.7241e-06
[2025-08-03 02:14:08] - Epoch 56/500,it:22848, Train Loss: 4.1961e-01, Val Loss: 5.4779e-02, best model: 47, LR: 9.6937e-04, epoch time: 87.76, snr: 1.5444e+01, var(R): 7.6868e-10, var(L*R): 2.8369e-09, WD: 8.8817e-06
[2025-08-03 02:15:36] - Epoch 57/500,it:23256, Train Loss: 3.0045e-01, Val Loss: 8.0777e-02, best model: 47, LR: 9.6827e-04, epoch time: 87.89, snr: 1.3188e+01, var(R): 3.3968e-10, var(L*R): 9.0369e-10, WD: 9.0538e-06
[2025-08-03 02:17:04] - Epoch 58/500,it:23664, Train Loss: 3.4876e-01, Val Loss: 7.6500e-02, best model: 47, LR: 9.6716e-04, epoch time: 87.79, snr: 1.3296e+01, var(R): 1.1689e-09, var(L*R): 3.6553e-09, WD: 9.2029e-06
[2025-08-03 02:18:32] - Epoch 59/500,it:24072, Train Loss: 4.4541e-01, Val Loss: 8.9854e-02, best model: 47, LR: 9.6604e-04, epoch time: 87.87, snr: 1.3724e+01, var(R): 1.5342e-09, var(L*R): 9.3719e-09, WD: 9.3635e-06
[2025-08-03 02:19:59] - Epoch 60/500,it:24480, Train Loss: 3.8688e-01, Val Loss: 8.4157e-02, best model: 47, LR: 9.6489e-04, epoch time: 87.65, snr: 1.4717e+01, var(R): 1.8005e-09, var(L*R): 9.0167e-09, WD: 9.5332e-06
[2025-08-03 02:21:27] - Epoch 61/500,it:24888, Train Loss: 3.6076e-01, Val Loss: 9.4375e-02, best model: 47, LR: 9.6372e-04, epoch time: 87.83, snr: 2.1109e+01, var(R): 1.4157e-09, var(L*R): 7.4086e-09, WD: 9.6932e-06
[2025-08-03 02:22:55] - Epoch 62/500,it:25296, Train Loss: 3.4903e-01, Val Loss: 8.8929e-02, best model: 47, LR: 9.6254e-04, epoch time: 87.75, snr: 2.0321e+01, var(R): 2.0716e-09, var(L*R): 8.0963e-09, WD: 9.8485e-06
[2025-08-03 02:24:23] - Epoch 63/500,it:25704, Train Loss: 3.5856e-01, Val Loss: 6.5536e-02, best model: 47, LR: 9.6134e-04, epoch time: 87.96, snr: 1.9697e+01, var(R): 1.4752e-09, var(L*R): 5.4603e-09, WD: 1.0024e-05
[2025-08-03 02:25:51] - Epoch 64/500,it:26112, Train Loss: 3.3316e-01, Val Loss: 6.3062e-02, best model: 47, LR: 9.6012e-04, epoch time: 87.73, snr: 1.5811e+00, var(R): 5.8488e-10, var(L*R): 1.9998e-09, WD: 1.0171e-05
[2025-08-03 02:27:18] - Epoch 65/500,it:26520, Train Loss: 3.4996e-01, Val Loss: 7.4330e-02, best model: 47, LR: 9.5888e-04, epoch time: 87.84, snr: 1.8906e+01, var(R): 4.6334e-10, var(L*R): 1.9499e-09, WD: 1.0331e-05
[2025-08-03 02:28:46] - Epoch 66/500,it:26928, Train Loss: 3.5825e-01, Val Loss: 9.3472e-02, best model: 47, LR: 9.5762e-04, epoch time: 87.90, snr: 1.7791e+01, var(R): 6.4167e-10, var(L*R): 2.2126e-09, WD: 1.0489e-05
[2025-08-03 02:30:14] - Epoch 67/500,it:27336, Train Loss: 3.8134e-01, Val Loss: 5.2098e-02, best model: 67, LR: 9.5635e-04, epoch time: 87.71, snr: 2.4121e+01, var(R): 2.9967e-09, var(L*R): 2.4955e-08, WD: 1.0658e-05
[2025-08-03 02:31:42] - Epoch 68/500,it:27744, Train Loss: 3.0970e-01, Val Loss: 7.8118e-02, best model: 67, LR: 9.5505e-04, epoch time: 87.68, snr: 4.2141e+00, var(R): 2.6295e-10, var(L*R): 9.9684e-10, WD: 1.0831e-05
[2025-08-03 02:33:10] - Epoch 69/500,it:28152, Train Loss: 3.7267e-01, Val Loss: 1.2199e-01, best model: 67, LR: 9.5374e-04, epoch time: 87.82, snr: 1.9671e+01, var(R): 1.0219e-09, var(L*R): 3.2991e-09, WD: 1.0978e-05
[2025-08-03 02:34:38] - Epoch 70/500,it:28560, Train Loss: 3.7524e-01, Val Loss: 7.0257e-02, best model: 67, LR: 9.5241e-04, epoch time: 87.91, snr: 2.2028e+01, var(R): 5.7989e-09, var(L*R): 4.1438e-08, WD: 1.1152e-05
[2025-08-03 02:36:05] - Epoch 71/500,it:28968, Train Loss: 3.0121e-01, Val Loss: 6.6488e-02, best model: 67, LR: 9.5107e-04, epoch time: 87.79, snr: 2.2948e+01, var(R): 8.9394e-10, var(L*R): 9.0673e-09, WD: 1.1312e-05
[2025-08-03 02:37:33] - Epoch 72/500,it:29376, Train Loss: 3.6831e-01, Val Loss: 8.8852e-02, best model: 67, LR: 9.4970e-04, epoch time: 88.06, snr: 1.6872e+01, var(R): 6.8644e-10, var(L*R): 5.1250e-09, WD: 1.1470e-05
[2025-08-03 02:39:01] - Epoch 73/500,it:29784, Train Loss: 3.9983e-01, Val Loss: 7.1635e-02, best model: 67, LR: 9.4832e-04, epoch time: 87.82, snr: 1.8417e+01, var(R): 2.1107e-09, var(L*R): 1.9320e-08, WD: 1.1632e-05
[2025-08-03 02:40:29] - Epoch 74/500,it:30192, Train Loss: 3.1324e-01, Val Loss: 7.4448e-02, best model: 67, LR: 9.4692e-04, epoch time: 87.74, snr: 1.9373e+01, var(R): 1.1948e-09, var(L*R): 1.4610e-08, WD: 1.1807e-05
[2025-08-03 02:41:57] - Epoch 75/500,it:30600, Train Loss: 2.9644e-01, Val Loss: 8.1946e-02, best model: 67, LR: 9.4550e-04, epoch time: 87.64, snr: 2.2702e+01, var(R): 1.4276e-09, var(L*R): 1.8337e-08, WD: 1.1966e-05
[2025-08-03 02:43:24] - Epoch 76/500,it:31008, Train Loss: 2.8729e-01, Val Loss: 9.5450e-02, best model: 67, LR: 9.4407e-04, epoch time: 87.89, snr: 1.3100e+01, var(R): 1.3793e-09, var(L*R): 5.2861e-09, WD: 1.2124e-05
[2025-08-03 02:44:52] - Epoch 77/500,it:31416, Train Loss: 3.6313e-01, Val Loss: 6.6519e-02, best model: 67, LR: 9.4262e-04, epoch time: 87.91, snr: 8.7678e+00, var(R): 2.0085e-09, var(L*R): 9.1171e-09, WD: 1.2280e-05
[2025-08-03 02:46:20] - Epoch 78/500,it:31824, Train Loss: 3.4232e-01, Val Loss: 6.3590e-02, best model: 67, LR: 9.4115e-04, epoch time: 87.96, snr: 1.1347e+01, var(R): 5.5381e-10, var(L*R): 3.5025e-09, WD: 1.2443e-05
[2025-08-03 02:47:48] - Epoch 79/500,it:32232, Train Loss: 3.6798e-01, Val Loss: 7.5284e-02, best model: 67, LR: 9.3966e-04, epoch time: 87.80, snr: 1.7710e+01, var(R): 5.0141e-10, var(L*R): 2.4208e-09, WD: 1.2612e-05
[2025-08-03 02:49:16] - Epoch 80/500,it:32640, Train Loss: 3.2984e-01, Val Loss: 7.9149e-02, best model: 67, LR: 9.3815e-04, epoch time: 88.05, snr: 1.4691e+01, var(R): 1.6205e-09, var(L*R): 2.1645e-08, WD: 1.2773e-05
[2025-08-03 02:50:44] - Epoch 81/500,it:33048, Train Loss: 3.9781e-01, Val Loss: 7.5479e-02, best model: 67, LR: 9.3663e-04, epoch time: 87.88, snr: 1.8103e+01, var(R): 1.1947e-09, var(L*R): 1.0556e-08, WD: 1.2942e-05
[2025-08-03 02:52:12] - Epoch 82/500,it:33456, Train Loss: 3.5381e-01, Val Loss: 5.3211e-02, best model: 67, LR: 9.3509e-04, epoch time: 87.74, snr: 2.2361e+01, var(R): 1.0918e-09, var(L*R): 1.3318e-08, WD: 1.3125e-05
[2025-08-03 02:53:40] - Epoch 83/500,it:33864, Train Loss: 3.6405e-01, Val Loss: 9.6975e-02, best model: 67, LR: 9.3354e-04, epoch time: 87.93, snr: 6.0113e+00, var(R): 2.1068e-10, var(L*R): 1.1459e-09, WD: 1.3289e-05
[2025-08-03 02:55:08] - Epoch 84/500,it:34272, Train Loss: 2.9306e-01, Val Loss: 4.9421e-02, best model: 84, LR: 9.3196e-04, epoch time: 87.82, snr: 2.0827e+01, var(R): 1.9394e-09, var(L*R): 1.2416e-08, WD: 1.3454e-05
[2025-08-03 02:56:35] - Epoch 85/500,it:34680, Train Loss: 3.7306e-01, Val Loss: 1.0464e-01, best model: 84, LR: 9.3037e-04, epoch time: 87.93, snr: 1.4410e+01, var(R): 1.6217e-10, var(L*R): 9.3698e-10, WD: 1.3618e-05
[2025-08-03 02:58:03] - Epoch 86/500,it:35088, Train Loss: 3.7565e-01, Val Loss: 8.0907e-02, best model: 84, LR: 9.2876e-04, epoch time: 87.85, snr: 1.7622e+01, var(R): 2.5738e-09, var(L*R): 1.2358e-08, WD: 1.3800e-05
[2025-08-03 02:59:31] - Epoch 87/500,it:35496, Train Loss: 3.1779e-01, Val Loss: 5.1250e-02, best model: 84, LR: 9.2714e-04, epoch time: 87.91, snr: 2.2344e+01, var(R): 1.5755e-09, var(L*R): 2.2227e-08, WD: 1.3968e-05
[2025-08-03 03:00:59] - Epoch 88/500,it:35904, Train Loss: 2.6123e-01, Val Loss: 6.3721e-02, best model: 84, LR: 9.2550e-04, epoch time: 87.82, snr: 1.2904e+00, var(R): 2.6113e-10, var(L*R): 1.0321e-09, WD: 1.4123e-05
[2025-08-03 03:02:27] - Epoch 89/500,it:36312, Train Loss: 2.7027e-01, Val Loss: 4.7732e-02, best model: 89, LR: 9.2384e-04, epoch time: 87.84, snr: 1.8288e+01, var(R): 3.1248e-10, var(L*R): 2.5985e-09, WD: 1.4281e-05
[2025-08-03 03:03:55] - Epoch 90/500,it:36720, Train Loss: 3.7240e-01, Val Loss: 9.3985e-02, best model: 89, LR: 9.2216e-04, epoch time: 87.83, snr: 1.3114e+01, var(R): 2.1617e-10, var(L*R): 1.8577e-09, WD: 1.4440e-05
[2025-08-03 03:05:23] - Epoch 91/500,it:37128, Train Loss: 3.2268e-01, Val Loss: 5.3532e-02, best model: 89, LR: 9.2047e-04, epoch time: 87.89, snr: 2.1226e+01, var(R): 3.1831e-09, var(L*R): 6.7857e-08, WD: 1.4621e-05
[2025-08-03 03:06:51] - Epoch 92/500,it:37536, Train Loss: 3.2996e-01, Val Loss: 4.5569e-02, best model: 92, LR: 9.1876e-04, epoch time: 88.02, snr: 1.5560e+01, var(R): 2.6824e-10, var(L*R): 1.7284e-09, WD: 1.4769e-05
[2025-08-03 03:08:19] - Epoch 93/500,it:37944, Train Loss: 3.0738e-01, Val Loss: 4.4362e-02, best model: 93, LR: 9.1704e-04, epoch time: 88.07, snr: 1.5695e+01, var(R): 1.6677e-10, var(L*R): 1.7732e-09, WD: 1.4932e-05
[2025-08-03 03:09:46] - Epoch 94/500,it:38352, Train Loss: 2.6573e-01, Val Loss: 6.8979e-02, best model: 93, LR: 9.1530e-04, epoch time: 87.68, snr: 4.0789e+00, var(R): 1.0535e-10, var(L*R): 6.7778e-10, WD: 1.5103e-05
[2025-08-03 03:11:14] - Epoch 95/500,it:38760, Train Loss: 3.3900e-01, Val Loss: 4.5382e-02, best model: 93, LR: 9.1354e-04, epoch time: 87.73, snr: 1.1522e+00, var(R): 6.1946e-10, var(L*R): 3.7485e-09, WD: 1.5276e-05
[2025-08-03 03:12:42] - Epoch 96/500,it:39168, Train Loss: 2.8731e-01, Val Loss: 5.2082e-02, best model: 93, LR: 9.1177e-04, epoch time: 87.74, snr: 4.9952e-01, var(R): 1.5896e-10, var(L*R): 9.5824e-10, WD: 1.5430e-05
[2025-08-03 03:14:10] - Epoch 97/500,it:39576, Train Loss: 2.6962e-01, Val Loss: 6.2010e-02, best model: 93, LR: 9.0998e-04, epoch time: 87.81, snr: 1.7170e+01, var(R): 2.1621e-10, var(L*R): 1.2811e-09, WD: 1.5578e-05
[2025-08-03 03:15:38] - Epoch 98/500,it:39984, Train Loss: 3.5965e-01, Val Loss: 6.5590e-02, best model: 93, LR: 9.0817e-04, epoch time: 87.87, snr: 6.8576e+00, var(R): 5.2340e-10, var(L*R): 6.4115e-09, WD: 1.5745e-05
[2025-08-03 03:17:05] - Epoch 99/500,it:40392, Train Loss: 3.4182e-01, Val Loss: 5.9424e-02, best model: 93, LR: 9.0635e-04, epoch time: 87.81, snr: 7.4797e+00, var(R): 4.7527e-10, var(L*R): 3.9989e-09, WD: 1.5917e-05
[2025-08-03 03:18:33] - Epoch 100/500,it:40800, Train Loss: 3.2636e-01, Val Loss: 5.1045e-02, best model: 93, LR: 9.0451e-04, epoch time: 87.74, snr: 1.4586e+01, var(R): 4.7685e-10, var(L*R): 6.1211e-09, WD: 1.6100e-05
[2025-08-03 03:20:01] - Epoch 101/500,it:41208, Train Loss: 2.8247e-01, Val Loss: 5.9042e-02, best model: 93, LR: 9.0265e-04, epoch time: 87.73, snr: 1.0518e+01, var(R): 2.5676e-10, var(L*R): 1.9564e-09, WD: 1.6261e-05
[2025-08-03 03:21:29] - Epoch 102/500,it:41616, Train Loss: 3.0752e-01, Val Loss: 4.6117e-02, best model: 93, LR: 9.0078e-04, epoch time: 87.76, snr: 2.0074e+01, var(R): 3.4040e-10, var(L*R): 3.9282e-09, WD: 1.6406e-05
[2025-08-03 03:22:56] - Epoch 103/500,it:42024, Train Loss: 2.7408e-01, Val Loss: 1.1160e-01, best model: 93, LR: 8.9890e-04, epoch time: 87.79, snr: 2.9400e+00, var(R): 2.1329e-10, var(L*R): 2.3398e-09, WD: 1.6589e-05
[2025-08-03 03:24:24] - Epoch 104/500,it:42432, Train Loss: 3.8289e-01, Val Loss: 7.2324e-02, best model: 93, LR: 8.9700e-04, epoch time: 87.72, snr: 2.4648e+01, var(R): 3.4465e-09, var(L*R): 4.4636e-08, WD: 1.6743e-05
[2025-08-03 03:25:52] - Epoch 105/500,it:42840, Train Loss: 3.0609e-01, Val Loss: 5.9407e-02, best model: 93, LR: 8.9508e-04, epoch time: 87.56, snr: 2.0990e+01, var(R): 6.5082e-10, var(L*R): 9.9555e-09, WD: 1.6916e-05
[2025-08-03 03:27:19] - Epoch 106/500,it:43248, Train Loss: 3.0323e-01, Val Loss: 4.2047e-02, best model: 106, LR: 8.9314e-04, epoch time: 87.77, snr: 7.5672e+00, var(R): 4.2138e-10, var(L*R): 9.2122e-09, WD: 1.7096e-05
[2025-08-03 03:28:47] - Epoch 107/500,it:43656, Train Loss: 2.9981e-01, Val Loss: 4.2540e-02, best model: 106, LR: 8.9120e-04, epoch time: 87.91, snr: 5.5276e+00, var(R): 1.5134e-10, var(L*R): 1.2257e-09, WD: 1.7267e-05
[2025-08-03 03:30:15] - Epoch 108/500,it:44064, Train Loss: 3.0616e-01, Val Loss: 4.8022e-02, best model: 106, LR: 8.8923e-04, epoch time: 87.90, snr: 1.2051e+00, var(R): 1.0606e-10, var(L*R): 6.0851e-10, WD: 1.7423e-05
[2025-08-03 03:31:43] - Epoch 109/500,it:44472, Train Loss: 3.0081e-01, Val Loss: 4.5075e-02, best model: 106, LR: 8.8725e-04, epoch time: 87.76, snr: 8.7173e+00, var(R): 1.3660e-10, var(L*R): 1.1405e-09, WD: 1.7591e-05
[2025-08-03 03:33:11] - Epoch 110/500,it:44880, Train Loss: 3.4422e-01, Val Loss: 9.3075e-02, best model: 106, LR: 8.8526e-04, epoch time: 87.73, snr: 1.2190e+01, var(R): 1.5009e-10, var(L*R): 1.0427e-09, WD: 1.7754e-05
[2025-08-03 03:34:39] - Epoch 111/500,it:45288, Train Loss: 3.1289e-01, Val Loss: 9.9360e-02, best model: 106, LR: 8.8325e-04, epoch time: 87.77, snr: 2.3457e+01, var(R): 1.8061e-09, var(L*R): 3.1572e-08, WD: 1.7912e-05
[2025-08-03 03:36:06] - Epoch 112/500,it:45696, Train Loss: 2.6798e-01, Val Loss: 4.5015e-02, best model: 106, LR: 8.8122e-04, epoch time: 87.54, snr: 2.2477e+01, var(R): 2.6282e-09, var(L*R): 4.0604e-08, WD: 1.8087e-05
[2025-08-03 03:37:34] - Epoch 113/500,it:46104, Train Loss: 2.8226e-01, Val Loss: 6.1893e-02, best model: 106, LR: 8.7918e-04, epoch time: 87.83, snr: 6.5364e+00, var(R): 1.6031e-10, var(L*R): 1.0481e-09, WD: 1.8246e-05
[2025-08-03 03:39:02] - Epoch 114/500,it:46512, Train Loss: 2.7920e-01, Val Loss: 1.1252e-01, best model: 106, LR: 8.7713e-04, epoch time: 87.92, snr: 1.9752e+01, var(R): 5.7205e-10, var(L*R): 1.8847e-08, WD: 1.8398e-05
[2025-08-03 03:40:30] - Epoch 115/500,it:46920, Train Loss: 2.9674e-01, Val Loss: 4.3565e-02, best model: 106, LR: 8.7506e-04, epoch time: 87.75, snr: 2.4661e+01, var(R): 4.1563e-09, var(L*R): 1.0933e-07, WD: 1.8564e-05
[2025-08-03 03:41:57] - Epoch 116/500,it:47328, Train Loss: 2.4144e-01, Val Loss: 6.3630e-02, best model: 106, LR: 8.7297e-04, epoch time: 87.55, snr: 9.2010e-01, var(R): 1.4755e-10, var(L*R): 9.5474e-10, WD: 1.8742e-05
[2025-08-03 03:43:25] - Epoch 117/500,it:47736, Train Loss: 3.1675e-01, Val Loss: 8.0614e-02, best model: 106, LR: 8.7087e-04, epoch time: 87.85, snr: 2.1277e+01, var(R): 1.4753e-09, var(L*R): 7.7547e-08, WD: 1.8898e-05
[2025-08-03 03:44:53] - Epoch 118/500,it:48144, Train Loss: 2.9031e-01, Val Loss: 6.3179e-02, best model: 106, LR: 8.6876e-04, epoch time: 87.86, snr: 2.1590e+01, var(R): 1.2591e-09, var(L*R): 1.8811e-08, WD: 1.9042e-05
[2025-08-03 03:46:21] - Epoch 119/500,it:48552, Train Loss: 3.3379e-01, Val Loss: 5.7896e-02, best model: 106, LR: 8.6663e-04, epoch time: 87.83, snr: 7.8035e+00, var(R): 6.0685e-10, var(L*R): 1.0756e-08, WD: 1.9220e-05
[2025-08-03 03:47:48] - Epoch 120/500,it:48960, Train Loss: 2.6442e-01, Val Loss: 4.7821e-02, best model: 106, LR: 8.6448e-04, epoch time: 87.68, snr: 2.1011e+01, var(R): 4.1380e-10, var(L*R): 3.6162e-09, WD: 1.9387e-05
[2025-08-03 03:49:16] - Epoch 121/500,it:49368, Train Loss: 2.6986e-01, Val Loss: 5.9445e-02, best model: 106, LR: 8.6233e-04, epoch time: 87.82, snr: 5.4134e-01, var(R): 1.6124e-10, var(L*R): 2.9202e-09, WD: 1.9551e-05
[2025-08-03 03:50:44] - Epoch 122/500,it:49776, Train Loss: 2.8657e-01, Val Loss: 7.1546e-02, best model: 106, LR: 8.6015e-04, epoch time: 87.68, snr: 1.0896e+01, var(R): 4.7513e-10, var(L*R): 3.6890e-09, WD: 1.9691e-05
[2025-08-03 03:52:12] - Epoch 123/500,it:50184, Train Loss: 3.4923e-01, Val Loss: 4.3609e-02, best model: 106, LR: 8.5797e-04, epoch time: 87.75, snr: 2.3148e+01, var(R): 9.3678e-10, var(L*R): 2.0211e-08, WD: 1.9882e-05
[2025-08-03 03:53:39] - Epoch 124/500,it:50592, Train Loss: 2.3831e-01, Val Loss: 5.5058e-02, best model: 106, LR: 8.5577e-04, epoch time: 87.68, snr: 9.3052e-01, var(R): 1.4594e-10, var(L*R): 1.4795e-09, WD: 2.0032e-05
[2025-08-03 03:55:07] - Epoch 125/500,it:51000, Train Loss: 3.2594e-01, Val Loss: 4.5990e-02, best model: 106, LR: 8.5355e-04, epoch time: 87.79, snr: 1.8229e+01, var(R): 3.0865e-10, var(L*R): 7.6607e-09, WD: 2.0199e-05
[2025-08-03 03:56:35] - Epoch 126/500,it:51408, Train Loss: 2.4083e-01, Val Loss: 4.7220e-02, best model: 106, LR: 8.5132e-04, epoch time: 87.56, snr: 4.0726e+00, var(R): 1.5599e-10, var(L*R): 1.4208e-09, WD: 2.0360e-05
[2025-08-03 03:58:02] - Epoch 127/500,it:51816, Train Loss: 2.9885e-01, Val Loss: 4.5199e-02, best model: 106, LR: 8.4908e-04, epoch time: 87.48, snr: 1.7406e+01, var(R): 3.7914e-10, var(L*R): 1.7886e-08, WD: 2.0535e-05
[2025-08-03 03:59:30] - Epoch 128/500,it:52224, Train Loss: 2.6430e-01, Val Loss: 5.8953e-02, best model: 106, LR: 8.4683e-04, epoch time: 87.65, snr: 3.7567e+00, var(R): 1.5047e-10, var(L*R): 4.3836e-09, WD: 2.0687e-05
[2025-08-03 04:00:57] - Epoch 129/500,it:52632, Train Loss: 2.9090e-01, Val Loss: 6.0593e-02, best model: 106, LR: 8.4456e-04, epoch time: 87.71, snr: 1.6662e+01, var(R): 4.6910e-10, var(L*R): 5.2040e-09, WD: 2.0835e-05
[2025-08-03 04:02:25] - Epoch 130/500,it:53040, Train Loss: 2.4231e-01, Val Loss: 4.1752e-02, best model: 130, LR: 8.4227e-04, epoch time: 87.72, snr: 3.2751e+00, var(R): 4.7307e-10, var(L*R): 5.5733e-09, WD: 2.1020e-05
[2025-08-03 04:03:53] - Epoch 131/500,it:53448, Train Loss: 3.0738e-01, Val Loss: 4.4112e-02, best model: 130, LR: 8.3998e-04, epoch time: 87.48, snr: 1.5057e+00, var(R): 1.1589e-10, var(L*R): 1.2531e-09, WD: 2.1164e-05
[2025-08-03 04:05:20] - Epoch 132/500,it:53856, Train Loss: 2.3898e-01, Val Loss: 4.5546e-02, best model: 130, LR: 8.3767e-04, epoch time: 87.54, snr: 1.9839e+01, var(R): 1.4801e-10, var(L*R): 1.6371e-09, WD: 2.1314e-05
[2025-08-03 04:06:48] - Epoch 133/500,it:54264, Train Loss: 2.3954e-01, Val Loss: 3.8953e-02, best model: 133, LR: 8.3534e-04, epoch time: 87.61, snr: 1.9188e+00, var(R): 1.8469e-10, var(L*R): 1.6491e-09, WD: 2.1457e-05
[2025-08-03 04:08:15] - Epoch 134/500,it:54672, Train Loss: 2.8009e-01, Val Loss: 4.2228e-02, best model: 133, LR: 8.3301e-04, epoch time: 87.37, snr: 9.1952e-01, var(R): 9.3929e-11, var(L*R): 7.9580e-10, WD: 2.1626e-05
[2025-08-03 04:09:43] - Epoch 135/500,it:55080, Train Loss: 2.5507e-01, Val Loss: 8.6233e-02, best model: 133, LR: 8.3066e-04, epoch time: 87.34, snr: 9.1136e-01, var(R): 1.3451e-10, var(L*R): 1.2854e-09, WD: 2.1779e-05
[2025-08-03 04:11:10] - Epoch 136/500,it:55488, Train Loss: 2.9927e-01, Val Loss: 4.6664e-02, best model: 133, LR: 8.2829e-04, epoch time: 87.39, snr: 1.9681e+01, var(R): 1.4041e-09, var(L*R): 2.3716e-08, WD: 2.1947e-05
[2025-08-03 04:12:37] - Epoch 137/500,it:55896, Train Loss: 3.0187e-01, Val Loss: 4.6295e-02, best model: 133, LR: 8.2592e-04, epoch time: 87.49, snr: 9.4911e+00, var(R): 2.7317e-10, var(L*R): 3.9431e-09, WD: 2.2110e-05
[2025-08-03 04:14:05] - Epoch 138/500,it:56304, Train Loss: 2.8320e-01, Val Loss: 8.3260e-02, best model: 133, LR: 8.2353e-04, epoch time: 87.38, snr: 1.0174e+01, var(R): 2.1567e-10, var(L*R): 3.8424e-09, WD: 2.2272e-05
[2025-08-03 04:15:32] - Epoch 139/500,it:56712, Train Loss: 2.4462e-01, Val Loss: 4.5379e-02, best model: 133, LR: 8.2113e-04, epoch time: 87.29, snr: 2.3794e+01, var(R): 1.3019e-09, var(L*R): 2.5485e-08, WD: 2.2436e-05
[2025-08-03 04:16:59] - Epoch 140/500,it:57120, Train Loss: 2.4673e-01, Val Loss: 5.7575e-02, best model: 133, LR: 8.1871e-04, epoch time: 87.38, snr: 1.3469e+01, var(R): 2.0665e-10, var(L*R): 6.0906e-09, WD: 2.2584e-05
[2025-08-03 04:18:27] - Epoch 141/500,it:57528, Train Loss: 2.6224e-01, Val Loss: 3.7805e-02, best model: 141, LR: 8.1629e-04, epoch time: 87.27, snr: 1.1020e+01, var(R): 5.4687e-10, var(L*R): 3.0996e-08, WD: 2.2742e-05
[2025-08-03 04:19:54] - Epoch 142/500,it:57936, Train Loss: 2.6200e-01, Val Loss: 5.0416e-02, best model: 141, LR: 8.1385e-04, epoch time: 87.33, snr: 2.9514e+00, var(R): 1.0674e-10, var(L*R): 1.0003e-09, WD: 2.2891e-05
[2025-08-03 04:21:21] - Epoch 143/500,it:58344, Train Loss: 2.8988e-01, Val Loss: 4.1478e-02, best model: 141, LR: 8.1139e-04, epoch time: 87.35, snr: 6.7834e+00, var(R): 2.6495e-10, var(L*R): 1.9811e-09, WD: 2.3059e-05
[2025-08-03 04:22:49] - Epoch 144/500,it:58752, Train Loss: 2.8759e-01, Val Loss: 4.8549e-02, best model: 141, LR: 8.0893e-04, epoch time: 87.14, snr: 4.1616e+00, var(R): 1.5447e-10, var(L*R): 1.9607e-09, WD: 2.3204e-05
[2025-08-03 04:24:16] - Epoch 145/500,it:59160, Train Loss: 2.6178e-01, Val Loss: 7.2470e-02, best model: 141, LR: 8.0645e-04, epoch time: 87.26, snr: 8.1425e+00, var(R): 3.1571e-10, var(L*R): 5.4079e-09, WD: 2.3386e-05
[2025-08-03 04:25:43] - Epoch 146/500,it:59568, Train Loss: 2.9080e-01, Val Loss: 7.3920e-02, best model: 141, LR: 8.0397e-04, epoch time: 87.07, snr: 2.2904e+01, var(R): 1.6805e-09, var(L*R): 8.0451e-08, WD: 2.3527e-05
[2025-08-03 04:27:10] - Epoch 147/500,it:59976, Train Loss: 2.2413e-01, Val Loss: 6.4003e-02, best model: 141, LR: 8.0146e-04, epoch time: 87.14, snr: 1.7224e+01, var(R): 1.1115e-09, var(L*R): 3.3017e-08, WD: 2.3719e-05
[2025-08-03 04:28:37] - Epoch 148/500,it:60384, Train Loss: 2.6458e-01, Val Loss: 8.9366e-02, best model: 141, LR: 7.9895e-04, epoch time: 87.26, snr: 1.9800e+01, var(R): 7.9819e-10, var(L*R): 5.9605e-08, WD: 2.3862e-05
[2025-08-03 04:30:05] - Epoch 149/500,it:60792, Train Loss: 2.2691e-01, Val Loss: 4.2905e-02, best model: 141, LR: 7.9643e-04, epoch time: 87.20, snr: 2.2001e+01, var(R): 4.2080e-09, var(L*R): 3.6641e-07, WD: 2.4020e-05
[2025-08-03 04:31:32] - Epoch 150/500,it:61200, Train Loss: 2.3435e-01, Val Loss: 4.5479e-02, best model: 141, LR: 7.9389e-04, epoch time: 87.02, snr: 1.1350e+01, var(R): 1.4711e-10, var(L*R): 2.2182e-09, WD: 2.4147e-05
[2025-08-03 04:32:59] - Epoch 151/500,it:61608, Train Loss: 2.7282e-01, Val Loss: 6.4167e-02, best model: 141, LR: 7.9135e-04, epoch time: 87.06, snr: 1.6000e+00, var(R): 2.0899e-10, var(L*R): 2.3736e-09, WD: 2.4296e-05
[2025-08-03 04:34:26] - Epoch 152/500,it:62016, Train Loss: 2.5661e-01, Val Loss: 5.5648e-02, best model: 141, LR: 7.8879e-04, epoch time: 87.19, snr: 2.0514e+01, var(R): 5.5775e-10, var(L*R): 7.9540e-09, WD: 2.4428e-05
[2025-08-03 04:35:53] - Epoch 153/500,it:62424, Train Loss: 2.7910e-01, Val Loss: 5.4226e-02, best model: 141, LR: 7.8622e-04, epoch time: 87.03, snr: 1.8544e+01, var(R): 3.1347e-10, var(L*R): 1.2063e-08, WD: 2.4615e-05
[2025-08-03 04:37:20] - Epoch 154/500,it:62832, Train Loss: 2.5576e-01, Val Loss: 5.7598e-02, best model: 141, LR: 7.8363e-04, epoch time: 86.90, snr: 1.6900e+01, var(R): 3.5615e-10, var(L*R): 1.1481e-08, WD: 2.4791e-05
[2025-08-03 04:38:47] - Epoch 155/500,it:63240, Train Loss: 2.3429e-01, Val Loss: 3.6621e-02, best model: 155, LR: 7.8104e-04, epoch time: 87.01, snr: 1.3326e+01, var(R): 3.6412e-10, var(L*R): 7.4682e-09, WD: 2.4947e-05
[2025-08-03 04:40:14] - Epoch 156/500,it:63648, Train Loss: 2.5214e-01, Val Loss: 6.8342e-02, best model: 155, LR: 7.7844e-04, epoch time: 87.15, snr: 9.3878e-01, var(R): 9.7242e-11, var(L*R): 2.6180e-09, WD: 2.5076e-05
[2025-08-03 04:41:41] - Epoch 157/500,it:64056, Train Loss: 2.4057e-01, Val Loss: 4.4995e-02, best model: 155, LR: 7.7582e-04, epoch time: 87.01, snr: 1.8037e+01, var(R): 7.3776e-10, var(L*R): 9.0016e-09, WD: 2.5231e-05
[2025-08-03 04:43:08] - Epoch 158/500,it:64464, Train Loss: 2.9983e-01, Val Loss: 3.6291e-02, best model: 158, LR: 7.7320e-04, epoch time: 87.29, snr: 1.5837e+00, var(R): 2.3737e-10, var(L*R): 1.4984e-08, WD: 2.5392e-05
[2025-08-03 04:44:35] - Epoch 159/500,it:64872, Train Loss: 2.3917e-01, Val Loss: 3.8744e-02, best model: 158, LR: 7.7056e-04, epoch time: 87.06, snr: 9.6962e-01, var(R): 1.0918e-10, var(L*R): 1.1144e-09, WD: 2.5546e-05
[2025-08-03 04:46:02] - Epoch 160/500,it:65280, Train Loss: 2.4189e-01, Val Loss: 5.1747e-02, best model: 158, LR: 7.6791e-04, epoch time: 86.96, snr: 9.9998e+00, var(R): 1.2278e-10, var(L*R): 2.7817e-09, WD: 2.5713e-05
[2025-08-03 04:47:29] - Epoch 161/500,it:65688, Train Loss: 2.4697e-01, Val Loss: 5.9992e-02, best model: 158, LR: 7.6526e-04, epoch time: 86.75, snr: 1.7088e+01, var(R): 1.9942e-10, var(L*R): 2.7104e-09, WD: 2.5850e-05
[2025-08-03 04:48:56] - Epoch 162/500,it:66096, Train Loss: 2.4909e-01, Val Loss: 6.3159e-02, best model: 158, LR: 7.6259e-04, epoch time: 86.76, snr: 2.2623e+01, var(R): 4.9138e-10, var(L*R): 2.3876e-08, WD: 2.6013e-05
[2025-08-03 04:50:23] - Epoch 163/500,it:66504, Train Loss: 2.6459e-01, Val Loss: 3.3176e-02, best model: 163, LR: 7.5991e-04, epoch time: 86.82, snr: 1.0489e+01, var(R): 7.4996e-10, var(L*R): 9.3208e-09, WD: 2.6177e-05
[2025-08-03 04:51:49] - Epoch 164/500,it:66912, Train Loss: 2.3476e-01, Val Loss: 4.3406e-02, best model: 163, LR: 7.5722e-04, epoch time: 86.85, snr: 9.2748e+00, var(R): 7.0515e-11, var(L*R): 1.1692e-09, WD: 2.6306e-05
[2025-08-03 04:53:16] - Epoch 165/500,it:67320, Train Loss: 2.3923e-01, Val Loss: 6.5277e-02, best model: 163, LR: 7.5452e-04, epoch time: 86.69, snr: 1.4065e+01, var(R): 2.4342e-10, var(L*R): 7.7999e-09, WD: 2.6455e-05
[2025-08-03 04:54:43] - Epoch 166/500,it:67728, Train Loss: 2.6459e-01, Val Loss: 3.6099e-02, best model: 163, LR: 7.5181e-04, epoch time: 86.83, snr: 1.8656e+01, var(R): 5.2591e-10, var(L*R): 1.9679e-08, WD: 2.6607e-05
[2025-08-03 04:56:10] - Epoch 167/500,it:68136, Train Loss: 2.1392e-01, Val Loss: 4.0377e-02, best model: 163, LR: 7.4909e-04, epoch time: 86.80, snr: 3.5912e+00, var(R): 9.9239e-11, var(L*R): 2.9719e-09, WD: 2.6762e-05
[2025-08-03 04:57:36] - Epoch 168/500,it:68544, Train Loss: 2.2880e-01, Val Loss: 7.9557e-02, best model: 163, LR: 7.4636e-04, epoch time: 86.66, snr: 2.2055e+00, var(R): 1.6314e-10, var(L*R): 2.1158e-09, WD: 2.6908e-05
[2025-08-03 04:59:03] - Epoch 169/500,it:68952, Train Loss: 2.4209e-01, Val Loss: 8.5671e-02, best model: 163, LR: 7.4363e-04, epoch time: 86.65, snr: 2.4480e+01, var(R): 1.2396e-09, var(L*R): 6.1192e-08, WD: 2.7054e-05
[2025-08-03 05:00:30] - Epoch 170/500,it:69360, Train Loss: 2.8410e-01, Val Loss: 3.9433e-02, best model: 163, LR: 7.4088e-04, epoch time: 86.59, snr: 1.5843e+01, var(R): 1.0741e-09, var(L*R): 3.4917e-08, WD: 2.7207e-05
[2025-08-03 05:01:56] - Epoch 171/500,it:69768, Train Loss: 2.0985e-01, Val Loss: 4.7421e-02, best model: 163, LR: 7.3812e-04, epoch time: 86.53, snr: 1.4940e+01, var(R): 1.5166e-10, var(L*R): 5.4428e-09, WD: 2.7383e-05
[2025-08-03 05:03:23] - Epoch 172/500,it:70176, Train Loss: 2.6702e-01, Val Loss: 4.5657e-02, best model: 163, LR: 7.3535e-04, epoch time: 86.54, snr: 1.4859e+01, var(R): 1.7488e-10, var(L*R): 2.4062e-09, WD: 2.7505e-05
[2025-08-03 05:04:49] - Epoch 173/500,it:70584, Train Loss: 2.0466e-01, Val Loss: 4.0402e-02, best model: 163, LR: 7.3258e-04, epoch time: 86.52, snr: 9.2688e+00, var(R): 1.7202e-10, var(L*R): 4.6164e-09, WD: 2.7673e-05
[2025-08-03 05:06:16] - Epoch 174/500,it:70992, Train Loss: 2.6492e-01, Val Loss: 5.2783e-02, best model: 163, LR: 7.2979e-04, epoch time: 86.47, snr: 1.7154e+00, var(R): 1.2920e-10, var(L*R): 1.9010e-09, WD: 2.7811e-05
[2025-08-03 05:07:42] - Epoch 175/500,it:71400, Train Loss: 2.1080e-01, Val Loss: 5.5998e-02, best model: 163, LR: 7.2700e-04, epoch time: 86.58, snr: 1.7588e+01, var(R): 2.2544e-10, var(L*R): 1.1023e-08, WD: 2.7941e-05
[2025-08-03 05:09:09] - Epoch 176/500,it:71808, Train Loss: 2.3384e-01, Val Loss: 3.2527e-02, best model: 176, LR: 7.2419e-04, epoch time: 86.49, snr: 1.8593e+01, var(R): 4.0431e-10, var(L*R): 8.2409e-09, WD: 2.8098e-05
[2025-08-03 05:10:35] - Epoch 177/500,it:72216, Train Loss: 2.4618e-01, Val Loss: 6.1108e-02, best model: 176, LR: 7.2138e-04, epoch time: 86.63, snr: 4.7128e-01, var(R): 8.4814e-11, var(L*R): 1.0124e-09, WD: 2.8249e-05
[2025-08-03 05:12:02] - Epoch 178/500,it:72624, Train Loss: 2.6740e-01, Val Loss: 3.4552e-02, best model: 176, LR: 7.1856e-04, epoch time: 86.59, snr: 1.5525e+01, var(R): 3.7829e-10, var(L*R): 1.0301e-08, WD: 2.8392e-05
[2025-08-03 05:13:29] - Epoch 179/500,it:73032, Train Loss: 2.0627e-01, Val Loss: 4.6444e-02, best model: 176, LR: 7.1573e-04, epoch time: 86.50, snr: 1.5379e+00, var(R): 8.0864e-11, var(L*R): 1.0063e-09, WD: 2.8553e-05
[2025-08-03 05:14:55] - Epoch 180/500,it:73440, Train Loss: 2.2782e-01, Val Loss: 3.2675e-02, best model: 176, LR: 7.1289e-04, epoch time: 86.37, snr: 1.8112e+01, var(R): 2.2537e-10, var(L*R): 8.2576e-09, WD: 2.8652e-05
[2025-08-03 05:16:21] - Epoch 181/500,it:73848, Train Loss: 2.5024e-01, Val Loss: 4.0330e-02, best model: 176, LR: 7.1004e-04, epoch time: 86.50, snr: 6.4070e-01, var(R): 6.1125e-11, var(L*R): 1.3555e-09, WD: 2.8844e-05
[2025-08-03 05:17:48] - Epoch 182/500,it:74256, Train Loss: 2.0170e-01, Val Loss: 3.5878e-02, best model: 176, LR: 7.0719e-04, epoch time: 86.51, snr: 9.3526e+00, var(R): 1.0980e-10, var(L*R): 2.1755e-09, WD: 2.8977e-05
[2025-08-03 05:19:14] - Epoch 183/500,it:74664, Train Loss: 2.6457e-01, Val Loss: 6.0364e-02, best model: 176, LR: 7.0432e-04, epoch time: 86.44, snr: 9.7197e-01, var(R): 6.9009e-11, var(L*R): 2.0911e-09, WD: 2.9110e-05
[2025-08-03 05:20:41] - Epoch 184/500,it:75072, Train Loss: 2.0960e-01, Val Loss: 3.4796e-02, best model: 176, LR: 7.0145e-04, epoch time: 86.42, snr: 5.7259e+00, var(R): 6.1931e-10, var(L*R): 1.4909e-08, WD: 2.9266e-05
[2025-08-03 05:22:07] - Epoch 185/500,it:75480, Train Loss: 2.0583e-01, Val Loss: 8.9384e-02, best model: 176, LR: 6.9857e-04, epoch time: 86.48, snr: 4.7470e+00, var(R): 9.0709e-11, var(L*R): 1.9450e-09, WD: 2.9400e-05
[2025-08-03 05:23:34] - Epoch 186/500,it:75888, Train Loss: 2.8051e-01, Val Loss: 5.0798e-02, best model: 176, LR: 6.9569e-04, epoch time: 86.45, snr: 2.0873e+01, var(R): 1.9207e-09, var(L*R): 1.7938e-07, WD: 2.9532e-05
[2025-08-03 05:25:00] - Epoch 187/500,it:76296, Train Loss: 1.8961e-01, Val Loss: 3.8972e-02, best model: 176, LR: 6.9279e-04, epoch time: 86.41, snr: 1.0078e+01, var(R): 1.9536e-10, var(L*R): 5.1175e-09, WD: 2.9696e-05
[2025-08-03 05:26:27] - Epoch 188/500,it:76704, Train Loss: 2.3730e-01, Val Loss: 5.1521e-02, best model: 176, LR: 6.8989e-04, epoch time: 86.48, snr: 2.1137e+01, var(R): 1.3238e-10, var(L*R): 4.5871e-09, WD: 2.9815e-05
[2025-08-03 05:27:53] - Epoch 189/500,it:77112, Train Loss: 2.2471e-01, Val Loss: 6.1197e-02, best model: 176, LR: 6.8698e-04, epoch time: 86.70, snr: 1.7106e+01, var(R): 4.0340e-10, var(L*R): 6.4033e-09, WD: 2.9973e-05
[2025-08-03 05:29:20] - Epoch 190/500,it:77520, Train Loss: 1.8947e-01, Val Loss: 5.5960e-02, best model: 176, LR: 6.8406e-04, epoch time: 86.50, snr: 1.9683e+01, var(R): 5.5495e-10, var(L*R): 3.8725e-08, WD: 3.0088e-05
[2025-08-03 05:30:46] - Epoch 191/500,it:77928, Train Loss: 2.3562e-01, Val Loss: 4.2068e-02, best model: 176, LR: 6.8114e-04, epoch time: 86.35, snr: 1.3906e+01, var(R): 5.7418e-10, var(L*R): 3.0757e-08, WD: 3.0240e-05
[2025-08-03 05:32:13] - Epoch 192/500,it:78336, Train Loss: 2.6414e-01, Val Loss: 3.9530e-02, best model: 176, LR: 6.7821e-04, epoch time: 86.49, snr: 1.9622e+01, var(R): 2.0280e-10, var(L*R): 1.4331e-08, WD: 3.0373e-05
[2025-08-03 05:33:39] - Epoch 193/500,it:78744, Train Loss: 2.1940e-01, Val Loss: 6.6849e-02, best model: 176, LR: 6.7527e-04, epoch time: 86.56, snr: 4.4233e+00, var(R): 1.4695e-10, var(L*R): 9.0327e-09, WD: 3.0545e-05
[2025-08-03 05:35:06] - Epoch 194/500,it:79152, Train Loss: 2.2001e-01, Val Loss: 7.6148e-02, best model: 176, LR: 6.7232e-04, epoch time: 86.54, snr: 1.8402e+01, var(R): 4.2863e-10, var(L*R): 3.1670e-08, WD: 3.0657e-05
[2025-08-03 05:36:32] - Epoch 195/500,it:79560, Train Loss: 2.3647e-01, Val Loss: 4.0935e-02, best model: 176, LR: 6.6937e-04, epoch time: 86.47, snr: 1.7435e+01, var(R): 8.8140e-10, var(L*R): 1.9555e-08, WD: 3.0810e-05
[2025-08-03 05:37:59] - Epoch 196/500,it:79968, Train Loss: 2.1770e-01, Val Loss: 4.1434e-02, best model: 176, LR: 6.6641e-04, epoch time: 86.45, snr: 1.3048e+00, var(R): 1.9036e-10, var(L*R): 6.5154e-09, WD: 3.0934e-05
[2025-08-03 05:39:25] - Epoch 197/500,it:80376, Train Loss: 2.2112e-01, Val Loss: 4.1970e-02, best model: 176, LR: 6.6344e-04, epoch time: 86.49, snr: 4.2585e+00, var(R): 1.8648e-10, var(L*R): 4.3541e-09, WD: 3.1088e-05
[2025-08-03 05:40:52] - Epoch 198/500,it:80784, Train Loss: 1.6929e-01, Val Loss: 3.6020e-02, best model: 176, LR: 6.6047e-04, epoch time: 86.52, snr: 9.7609e+00, var(R): 2.3426e-10, var(L*R): 1.5803e-08, WD: 3.1207e-05
[2025-08-03 05:42:18] - Epoch 199/500,it:81192, Train Loss: 2.3193e-01, Val Loss: 3.6293e-02, best model: 176, LR: 6.5749e-04, epoch time: 86.53, snr: 1.5461e+01, var(R): 1.2750e-10, var(L*R): 7.3560e-09, WD: 3.1328e-05
[2025-08-03 05:43:45] - Epoch 200/500,it:81600, Train Loss: 2.0003e-01, Val Loss: 3.3136e-02, best model: 176, LR: 6.5451e-04, epoch time: 86.47, snr: 9.2528e-01, var(R): 1.7686e-10, var(L*R): 3.6246e-09, WD: 3.1474e-05
[2025-08-03 05:45:11] - Epoch 201/500,it:82008, Train Loss: 2.0118e-01, Val Loss: 3.8257e-02, best model: 176, LR: 6.5152e-04, epoch time: 86.44, snr: 1.4642e+00, var(R): 1.1424e-10, var(L*R): 1.7359e-09, WD: 3.1598e-05
[2025-08-03 05:46:37] - Epoch 202/500,it:82416, Train Loss: 2.2880e-01, Val Loss: 4.0041e-02, best model: 176, LR: 6.4852e-04, epoch time: 86.36, snr: 7.3656e+00, var(R): 1.2838e-10, var(L*R): 5.6324e-09, WD: 3.1755e-05
[2025-08-03 05:48:04] - Epoch 203/500,it:82824, Train Loss: 1.7428e-01, Val Loss: 3.1594e-02, best model: 203, LR: 6.4552e-04, epoch time: 86.60, snr: 4.1559e+00, var(R): 9.5564e-11, var(L*R): 2.5934e-09, WD: 3.1878e-05
[2025-08-03 05:49:31] - Epoch 204/500,it:83232, Train Loss: 2.2115e-01, Val Loss: 4.4048e-02, best model: 203, LR: 6.4251e-04, epoch time: 86.46, snr: 8.3191e+00, var(R): 1.0305e-10, var(L*R): 1.2218e-09, WD: 3.2012e-05
[2025-08-03 05:50:57] - Epoch 205/500,it:83640, Train Loss: 2.2161e-01, Val Loss: 3.3061e-02, best model: 203, LR: 6.3950e-04, epoch time: 86.46, snr: 1.5922e+01, var(R): 2.3034e-10, var(L*R): 3.1529e-08, WD: 3.2149e-05
[2025-08-03 05:52:23] - Epoch 206/500,it:84048, Train Loss: 2.1132e-01, Val Loss: 4.8672e-02, best model: 203, LR: 6.3648e-04, epoch time: 86.40, snr: 1.3440e+01, var(R): 9.3859e-11, var(L*R): 2.3201e-09, WD: 3.2295e-05
[2025-08-03 05:53:50] - Epoch 207/500,it:84456, Train Loss: 2.1154e-01, Val Loss: 3.6253e-02, best model: 203, LR: 6.3345e-04, epoch time: 86.51, snr: 1.7868e+01, var(R): 3.4034e-10, var(L*R): 2.2555e-08, WD: 3.2413e-05
[2025-08-03 05:55:16] - Epoch 208/500,it:84864, Train Loss: 2.3897e-01, Val Loss: 4.7922e-02, best model: 203, LR: 6.3042e-04, epoch time: 86.52, snr: 2.1271e+00, var(R): 9.5895e-11, var(L*R): 6.2711e-09, WD: 3.2545e-05
[2025-08-03 05:56:43] - Epoch 209/500,it:85272, Train Loss: 1.7761e-01, Val Loss: 3.1850e-02, best model: 203, LR: 6.2739e-04, epoch time: 86.52, snr: 1.8908e+01, var(R): 4.0276e-10, var(L*R): 2.5359e-08, WD: 3.2699e-05
[2025-08-03 05:58:09] - Epoch 210/500,it:85680, Train Loss: 1.7824e-01, Val Loss: 4.9113e-02, best model: 203, LR: 6.2434e-04, epoch time: 86.43, snr: 1.2158e+01, var(R): 1.2583e-10, var(L*R): 6.4085e-09, WD: 3.2810e-05
[2025-08-03 05:59:36] - Epoch 211/500,it:86088, Train Loss: 1.9988e-01, Val Loss: 4.0756e-02, best model: 203, LR: 6.2130e-04, epoch time: 86.57, snr: 1.5881e+01, var(R): 2.4493e-10, var(L*R): 7.7153e-09, WD: 3.2912e-05
[2025-08-03 06:01:03] - Epoch 212/500,it:86496, Train Loss: 2.1030e-01, Val Loss: 3.2105e-02, best model: 203, LR: 6.1825e-04, epoch time: 86.64, snr: 9.8418e+00, var(R): 2.1423e-10, var(L*R): 5.0164e-08, WD: 3.3063e-05
[2025-08-03 06:02:29] - Epoch 213/500,it:86904, Train Loss: 1.9988e-01, Val Loss: 3.1596e-02, best model: 203, LR: 6.1519e-04, epoch time: 86.49, snr: 1.6473e+00, var(R): 1.4005e-10, var(L*R): 2.5384e-09, WD: 3.3175e-05
[2025-08-03 06:03:56] - Epoch 214/500,it:87312, Train Loss: 2.1588e-01, Val Loss: 3.3082e-02, best model: 203, LR: 6.1214e-04, epoch time: 86.54, snr: 3.8608e+00, var(R): 1.0415e-10, var(L*R): 2.3023e-09, WD: 3.3317e-05
[2025-08-03 06:05:22] - Epoch 215/500,it:87720, Train Loss: 2.0357e-01, Val Loss: 5.1645e-02, best model: 203, LR: 6.0907e-04, epoch time: 86.47, snr: 6.1982e-01, var(R): 1.1724e-10, var(L*R): 2.3294e-09, WD: 3.3492e-05
[2025-08-03 06:06:49] - Epoch 216/500,it:88128, Train Loss: 2.2203e-01, Val Loss: 5.0420e-02, best model: 203, LR: 6.0600e-04, epoch time: 86.54, snr: 1.7330e+01, var(R): 2.8617e-10, var(L*R): 3.5862e-08, WD: 3.3575e-05
[2025-08-03 06:08:15] - Epoch 217/500,it:88536, Train Loss: 2.1736e-01, Val Loss: 2.9988e-02, best model: 217, LR: 6.0293e-04, epoch time: 86.54, snr: 1.1765e+01, var(R): 2.6761e-10, var(L*R): 7.9345e-09, WD: 3.3699e-05
[2025-08-03 06:09:42] - Epoch 218/500,it:88944, Train Loss: 1.9597e-01, Val Loss: 4.3045e-02, best model: 217, LR: 5.9985e-04, epoch time: 86.54, snr: 5.5208e+00, var(R): 9.7333e-11, var(L*R): 1.7049e-09, WD: 3.3849e-05
[2025-08-03 06:11:08] - Epoch 219/500,it:89352, Train Loss: 1.9072e-01, Val Loss: 4.8754e-02, best model: 217, LR: 5.9677e-04, epoch time: 86.53, snr: 9.6399e+00, var(R): 1.4845e-10, var(L*R): 6.5290e-09, WD: 3.3982e-05
[2025-08-03 06:12:35] - Epoch 220/500,it:89760, Train Loss: 2.4425e-01, Val Loss: 5.0635e-02, best model: 217, LR: 5.9369e-04, epoch time: 86.80, snr: 1.5083e+01, var(R): 4.0788e-10, var(L*R): 2.0703e-08, WD: 3.4090e-05
[2025-08-03 06:14:02] - Epoch 221/500,it:90168, Train Loss: 1.7902e-01, Val Loss: 3.4129e-02, best model: 217, LR: 5.9060e-04, epoch time: 86.47, snr: 2.1170e+01, var(R): 4.1726e-10, var(L*R): 2.2156e-08, WD: 3.4240e-05
[2025-08-03 06:15:28] - Epoch 222/500,it:90576, Train Loss: 1.9761e-01, Val Loss: 5.1174e-02, best model: 217, LR: 5.8751e-04, epoch time: 86.52, snr: 6.2409e+00, var(R): 9.4876e-11, var(L*R): 5.9158e-09, WD: 3.4365e-05
[2025-08-03 06:16:55] - Epoch 223/500,it:90984, Train Loss: 2.0247e-01, Val Loss: 4.4743e-02, best model: 217, LR: 5.8442e-04, epoch time: 86.53, snr: 2.1820e+01, var(R): 4.6778e-10, var(L*R): 6.5765e-08, WD: 3.4467e-05
[2025-08-03 06:18:21] - Epoch 224/500,it:91392, Train Loss: 2.0311e-01, Val Loss: 3.2484e-02, best model: 217, LR: 5.8132e-04, epoch time: 86.56, snr: 1.1460e+01, var(R): 1.2196e-10, var(L*R): 5.8267e-09, WD: 3.4608e-05
[2025-08-03 06:19:48] - Epoch 225/500,it:91800, Train Loss: 1.6383e-01, Val Loss: 3.9334e-02, best model: 217, LR: 5.7822e-04, epoch time: 86.38, snr: 1.1688e+01, var(R): 1.0490e-10, var(L*R): 7.3923e-09, WD: 3.4726e-05
[2025-08-03 06:21:14] - Epoch 226/500,it:92208, Train Loss: 2.1957e-01, Val Loss: 4.4916e-02, best model: 217, LR: 5.7511e-04, epoch time: 86.52, snr: 1.9715e+01, var(R): 1.8518e-10, var(L*R): 7.6081e-09, WD: 3.4836e-05
[2025-08-03 06:22:41] - Epoch 227/500,it:92616, Train Loss: 2.0717e-01, Val Loss: 3.2122e-02, best model: 217, LR: 5.7201e-04, epoch time: 86.56, snr: 2.0673e+01, var(R): 2.7869e-10, var(L*R): 7.1867e-09, WD: 3.4969e-05
[2025-08-03 06:24:07] - Epoch 228/500,it:93024, Train Loss: 1.8430e-01, Val Loss: 4.4387e-02, best model: 217, LR: 5.6890e-04, epoch time: 86.47, snr: 1.6208e+01, var(R): 1.6140e-10, var(L*R): 4.0931e-09, WD: 3.5084e-05
[2025-08-03 06:25:34] - Epoch 229/500,it:93432, Train Loss: 2.0679e-01, Val Loss: 3.1306e-02, best model: 217, LR: 5.6578e-04, epoch time: 86.53, snr: 1.4732e+01, var(R): 2.6946e-10, var(L*R): 6.8771e-09, WD: 3.5208e-05
[2025-08-03 06:27:00] - Epoch 230/500,it:93840, Train Loss: 1.6626e-01, Val Loss: 3.1997e-02, best model: 217, LR: 5.6267e-04, epoch time: 86.51, snr: 1.4253e+01, var(R): 1.3820e-10, var(L*R): 8.6752e-09, WD: 3.5329e-05
[2025-08-03 06:28:27] - Epoch 231/500,it:94248, Train Loss: 1.8541e-01, Val Loss: 5.2759e-02, best model: 217, LR: 5.5955e-04, epoch time: 86.51, snr: 3.3524e+00, var(R): 1.2929e-10, var(L*R): 3.3417e-09, WD: 3.5446e-05
[2025-08-03 06:29:53] - Epoch 232/500,it:94656, Train Loss: 2.0033e-01, Val Loss: 5.7977e-02, best model: 217, LR: 5.5643e-04, epoch time: 86.37, snr: 1.8096e+01, var(R): 3.6853e-10, var(L*R): 1.5223e-08, WD: 3.5572e-05
[2025-08-03 06:31:20] - Epoch 233/500,it:95064, Train Loss: 1.8493e-01, Val Loss: 2.8444e-02, best model: 233, LR: 5.5331e-04, epoch time: 86.54, snr: 1.6592e+01, var(R): 4.0232e-10, var(L*R): 2.4875e-08, WD: 3.5680e-05
[2025-08-03 06:32:46] - Epoch 234/500,it:95472, Train Loss: 1.5650e-01, Val Loss: 3.5097e-02, best model: 233, LR: 5.5018e-04, epoch time: 86.67, snr: 3.2778e+00, var(R): 1.2429e-10, var(L*R): 2.1575e-09, WD: 3.5795e-05
[2025-08-03 06:34:13] - Epoch 235/500,it:95880, Train Loss: 1.9965e-01, Val Loss: 3.4958e-02, best model: 233, LR: 5.4705e-04, epoch time: 86.47, snr: 6.4593e+00, var(R): 1.0093e-10, var(L*R): 3.5657e-09, WD: 3.5915e-05
[2025-08-03 06:35:39] - Epoch 236/500,it:96288, Train Loss: 1.6921e-01, Val Loss: 2.9300e-02, best model: 233, LR: 5.4393e-04, epoch time: 86.38, snr: 1.0956e+01, var(R): 9.5303e-11, var(L*R): 2.4937e-09, WD: 3.6032e-05
[2025-08-03 06:37:06] - Epoch 237/500,it:96696, Train Loss: 2.0159e-01, Val Loss: 5.6704e-02, best model: 233, LR: 5.4080e-04, epoch time: 86.52, snr: 2.4913e+00, var(R): 1.1211e-10, var(L*R): 1.7621e-09, WD: 3.6140e-05
[2025-08-03 06:38:32] - Epoch 238/500,it:97104, Train Loss: 1.8676e-01, Val Loss: 3.4363e-02, best model: 233, LR: 5.3766e-04, epoch time: 86.51, snr: 1.3348e+01, var(R): 3.0482e-10, var(L*R): 1.1800e-08, WD: 3.6266e-05
[2025-08-03 06:39:59] - Epoch 239/500,it:97512, Train Loss: 1.7679e-01, Val Loss: 4.5461e-02, best model: 233, LR: 5.3453e-04, epoch time: 86.50, snr: 2.8631e+00, var(R): 9.0326e-11, var(L*R): 3.0486e-09, WD: 3.6369e-05
[2025-08-03 06:41:25] - Epoch 240/500,it:97920, Train Loss: 1.9271e-01, Val Loss: 3.0954e-02, best model: 233, LR: 5.3140e-04, epoch time: 86.55, snr: 2.1420e+01, var(R): 2.8607e-10, var(L*R): 1.4451e-08, WD: 3.6476e-05
[2025-08-03 06:42:52] - Epoch 241/500,it:98328, Train Loss: 1.8850e-01, Val Loss: 4.9730e-02, best model: 233, LR: 5.2826e-04, epoch time: 86.61, snr: 1.2254e+01, var(R): 1.1062e-10, var(L*R): 3.0243e-09, WD: 3.6610e-05
[2025-08-03 06:44:18] - Epoch 242/500,it:98736, Train Loss: 2.1662e-01, Val Loss: 2.9229e-02, best model: 233, LR: 5.2512e-04, epoch time: 86.47, snr: 1.8294e+01, var(R): 2.6119e-10, var(L*R): 8.4411e-09, WD: 3.6715e-05
[2025-08-03 06:45:45] - Epoch 243/500,it:99144, Train Loss: 1.6470e-01, Val Loss: 3.4235e-02, best model: 233, LR: 5.2198e-04, epoch time: 86.37, snr: 4.8923e+00, var(R): 9.7711e-11, var(L*R): 5.3205e-09, WD: 3.6856e-05
[2025-08-03 06:47:11] - Epoch 244/500,it:99552, Train Loss: 1.5226e-01, Val Loss: 3.0304e-02, best model: 233, LR: 5.1885e-04, epoch time: 86.52, snr: 1.0488e+01, var(R): 8.7718e-11, var(L*R): 5.3552e-09, WD: 3.6936e-05
[2025-08-03 06:48:38] - Epoch 245/500,it:99960, Train Loss: 1.9289e-01, Val Loss: 2.7830e-02, best model: 245, LR: 5.1571e-04, epoch time: 86.56, snr: 1.3124e+00, var(R): 8.8312e-11, var(L*R): 2.3213e-09, WD: 3.7044e-05
[2025-08-03 06:50:04] - Epoch 246/500,it:100368, Train Loss: 1.7957e-01, Val Loss: 3.3110e-02, best model: 245, LR: 5.1257e-04, epoch time: 86.57, snr: 4.8615e+00, var(R): 1.0256e-10, var(L*R): 2.5688e-09, WD: 3.7183e-05
[2025-08-03 06:51:31] - Epoch 247/500,it:100776, Train Loss: 1.6667e-01, Val Loss: 2.5653e-02, best model: 247, LR: 5.0942e-04, epoch time: 86.46, snr: 1.0234e+01, var(R): 1.2277e-10, var(L*R): 3.3648e-09, WD: 3.7282e-05
[2025-08-03 06:52:57] - Epoch 248/500,it:101184, Train Loss: 1.6382e-01, Val Loss: 3.4189e-02, best model: 247, LR: 5.0628e-04, epoch time: 86.51, snr: 9.5025e+00, var(R): 8.8761e-11, var(L*R): 3.4719e-09, WD: 3.7381e-05
[2025-08-03 06:54:24] - Epoch 249/500,it:101592, Train Loss: 1.9830e-01, Val Loss: 2.8875e-02, best model: 247, LR: 5.0314e-04, epoch time: 86.52, snr: 1.8081e+00, var(R): 1.5506e-10, var(L*R): 4.9106e-09, WD: 3.7493e-05
[2025-08-03 06:55:50] - Epoch 250/500,it:102000, Train Loss: 1.8344e-01, Val Loss: 2.8000e-02, best model: 247, LR: 5.0000e-04, epoch time: 86.51, snr: 5.0941e+00, var(R): 1.1816e-10, var(L*R): 3.3868e-09, WD: 3.7633e-05
[2025-08-03 06:57:17] - Epoch 251/500,it:102408, Train Loss: 1.5573e-01, Val Loss: 3.2477e-02, best model: 247, LR: 4.9686e-04, epoch time: 86.42, snr: 1.5720e+00, var(R): 8.4124e-11, var(L*R): 2.0444e-09, WD: 3.7746e-05
[2025-08-03 06:58:43] - Epoch 252/500,it:102816, Train Loss: 1.7286e-01, Val Loss: 2.7373e-02, best model: 247, LR: 4.9372e-04, epoch time: 86.51, snr: 8.3164e+00, var(R): 1.4542e-10, var(L*R): 4.7409e-09, WD: 3.7824e-05
[2025-08-03 07:00:10] - Epoch 253/500,it:103224, Train Loss: 1.6188e-01, Val Loss: 2.6496e-02, best model: 247, LR: 4.9058e-04, epoch time: 86.47, snr: 1.4140e+01, var(R): 9.2286e-11, var(L*R): 4.5864e-09, WD: 3.7936e-05
[2025-08-03 07:01:36] - Epoch 254/500,it:103632, Train Loss: 1.6813e-01, Val Loss: 4.5849e-02, best model: 247, LR: 4.8743e-04, epoch time: 86.49, snr: 8.9073e+00, var(R): 1.1504e-10, var(L*R): 5.3183e-09, WD: 3.8025e-05
[2025-08-03 07:03:03] - Epoch 255/500,it:104040, Train Loss: 1.7394e-01, Val Loss: 2.7233e-02, best model: 247, LR: 4.8429e-04, epoch time: 86.49, snr: 1.8825e+00, var(R): 3.4384e-10, var(L*R): 1.2836e-08, WD: 3.8117e-05
[2025-08-03 07:04:29] - Epoch 256/500,it:104448, Train Loss: 1.7122e-01, Val Loss: 4.4906e-02, best model: 247, LR: 4.8115e-04, epoch time: 86.53, snr: 1.0569e+00, var(R): 9.5125e-11, var(L*R): 3.9901e-09, WD: 3.8251e-05
[2025-08-03 07:05:56] - Epoch 257/500,it:104856, Train Loss: 1.8765e-01, Val Loss: 2.5862e-02, best model: 247, LR: 4.7802e-04, epoch time: 86.53, snr: 1.8074e+01, var(R): 3.4004e-10, var(L*R): 2.6617e-08, WD: 3.8357e-05
[2025-08-03 07:07:22] - Epoch 258/500,it:105264, Train Loss: 1.5181e-01, Val Loss: 2.3678e-02, best model: 258, LR: 4.7488e-04, epoch time: 86.60, snr: 7.8565e-01, var(R): 1.0065e-10, var(L*R): 1.6731e-09, WD: 3.8455e-05
[2025-08-03 07:08:49] - Epoch 259/500,it:105672, Train Loss: 1.6900e-01, Val Loss: 2.2845e-02, best model: 259, LR: 4.7174e-04, epoch time: 86.55, snr: 2.1340e+00, var(R): 6.9691e-11, var(L*R): 2.6659e-09, WD: 3.8536e-05
[2025-08-03 07:10:15] - Epoch 260/500,it:106080, Train Loss: 1.5711e-01, Val Loss: 4.7720e-02, best model: 259, LR: 4.6860e-04, epoch time: 86.53, snr: 9.9277e+00, var(R): 8.3609e-11, var(L*R): 2.3462e-09, WD: 3.8655e-05
[2025-08-03 07:11:42] - Epoch 261/500,it:106488, Train Loss: 1.8152e-01, Val Loss: 3.1690e-02, best model: 259, LR: 4.6547e-04, epoch time: 86.59, snr: 1.5323e+01, var(R): 2.0726e-10, var(L*R): 1.8148e-08, WD: 3.8778e-05
[2025-08-03 07:13:09] - Epoch 262/500,it:106896, Train Loss: 1.3017e-01, Val Loss: 2.5498e-02, best model: 259, LR: 4.6234e-04, epoch time: 86.61, snr: 8.6996e+00, var(R): 1.1785e-10, var(L*R): 2.8382e-09, WD: 3.8834e-05
[2025-08-03 07:14:35] - Epoch 263/500,it:107304, Train Loss: 1.7467e-01, Val Loss: 2.4863e-02, best model: 259, LR: 4.5920e-04, epoch time: 86.53, snr: 9.6399e+00, var(R): 9.5955e-11, var(L*R): 3.3447e-09, WD: 3.8940e-05
[2025-08-03 07:16:02] - Epoch 264/500,it:107712, Train Loss: 1.6705e-01, Val Loss: 2.7236e-02, best model: 259, LR: 4.5607e-04, epoch time: 86.49, snr: 1.4093e+00, var(R): 1.0503e-10, var(L*R): 1.8454e-09, WD: 3.9048e-05
[2025-08-03 07:17:28] - Epoch 265/500,it:108120, Train Loss: 1.5130e-01, Val Loss: 2.4705e-02, best model: 259, LR: 4.5295e-04, epoch time: 86.62, snr: 9.9733e+00, var(R): 1.3005e-10, var(L*R): 7.0105e-09, WD: 3.9148e-05
[2025-08-03 07:18:55] - Epoch 266/500,it:108528, Train Loss: 1.7507e-01, Val Loss: 3.2071e-02, best model: 259, LR: 4.4982e-04, epoch time: 86.60, snr: 1.2578e+01, var(R): 1.0909e-10, var(L*R): 2.5125e-09, WD: 3.9237e-05
[2025-08-03 07:20:21] - Epoch 267/500,it:108936, Train Loss: 1.3994e-01, Val Loss: 4.5130e-02, best model: 259, LR: 4.4669e-04, epoch time: 86.49, snr: 2.8900e+00, var(R): 1.9624e-10, var(L*R): 6.4772e-09, WD: 3.9332e-05
[2025-08-03 07:21:48] - Epoch 268/500,it:109344, Train Loss: 1.8018e-01, Val Loss: 2.4947e-02, best model: 259, LR: 4.4357e-04, epoch time: 86.55, snr: 1.2242e+01, var(R): 2.0307e-10, var(L*R): 6.3662e-09, WD: 3.9449e-05
[2025-08-03 07:23:14] - Epoch 269/500,it:109752, Train Loss: 1.4450e-01, Val Loss: 3.2288e-02, best model: 259, LR: 4.4045e-04, epoch time: 86.45, snr: 1.4647e+01, var(R): 1.1830e-10, var(L*R): 6.6088e-09, WD: 3.9562e-05
[2025-08-03 07:24:41] - Epoch 270/500,it:110160, Train Loss: 1.3403e-01, Val Loss: 2.5189e-02, best model: 259, LR: 4.3733e-04, epoch time: 86.38, snr: 1.1766e+01, var(R): 2.4032e-10, var(L*R): 2.8710e-08, WD: 3.9622e-05
[2025-08-03 07:26:07] - Epoch 271/500,it:110568, Train Loss: 1.3982e-01, Val Loss: 2.2872e-02, best model: 259, LR: 4.3422e-04, epoch time: 86.46, snr: 1.8196e+00, var(R): 1.0775e-10, var(L*R): 2.9387e-09, WD: 3.9723e-05
[2025-08-03 07:27:34] - Epoch 272/500,it:110976, Train Loss: 1.4803e-01, Val Loss: 2.3736e-02, best model: 259, LR: 4.3110e-04, epoch time: 86.51, snr: 1.6655e+00, var(R): 1.2408e-10, var(L*R): 2.8262e-09, WD: 3.9794e-05
[2025-08-03 07:29:00] - Epoch 273/500,it:111384, Train Loss: 1.6070e-01, Val Loss: 2.8772e-02, best model: 259, LR: 4.2799e-04, epoch time: 86.56, snr: 1.0939e+01, var(R): 1.3270e-10, var(L*R): 7.7961e-09, WD: 3.9884e-05
[2025-08-03 07:30:27] - Epoch 274/500,it:111792, Train Loss: 1.7290e-01, Val Loss: 5.0485e-02, best model: 259, LR: 4.2489e-04, epoch time: 86.38, snr: 1.6015e+01, var(R): 1.8130e-10, var(L*R): 4.6267e-09, WD: 3.9981e-05
[2025-08-03 07:31:53] - Epoch 275/500,it:112200, Train Loss: 1.5513e-01, Val Loss: 4.9397e-02, best model: 259, LR: 4.2178e-04, epoch time: 86.46, snr: 2.1033e+01, var(R): 4.2072e-10, var(L*R): 5.1302e-08, WD: 4.0080e-05
[2025-08-03 07:33:20] - Epoch 276/500,it:112608, Train Loss: 1.4362e-01, Val Loss: 3.3641e-02, best model: 259, LR: 4.1868e-04, epoch time: 86.58, snr: 1.0814e+01, var(R): 3.6845e-10, var(L*R): 3.1485e-08, WD: 4.0179e-05
[2025-08-03 07:34:46] - Epoch 277/500,it:113016, Train Loss: 1.4020e-01, Val Loss: 2.9954e-02, best model: 259, LR: 4.1558e-04, epoch time: 86.40, snr: 1.7844e+01, var(R): 2.5086e-10, var(L*R): 2.6214e-08, WD: 4.0270e-05
[2025-08-03 07:36:13] - Epoch 278/500,it:113424, Train Loss: 1.6299e-01, Val Loss: 3.8205e-02, best model: 259, LR: 4.1249e-04, epoch time: 86.59, snr: 2.5923e+00, var(R): 1.1356e-10, var(L*R): 4.3038e-09, WD: 4.0361e-05
[2025-08-03 07:37:39] - Epoch 279/500,it:113832, Train Loss: 1.5711e-01, Val Loss: 3.9011e-02, best model: 259, LR: 4.0940e-04, epoch time: 86.53, snr: 1.9478e+01, var(R): 2.5942e-10, var(L*R): 2.7182e-08, WD: 4.0482e-05
[2025-08-03 07:39:06] - Epoch 280/500,it:114240, Train Loss: 1.4287e-01, Val Loss: 2.5698e-02, best model: 259, LR: 4.0631e-04, epoch time: 86.51, snr: 1.7477e+01, var(R): 2.8256e-10, var(L*R): 1.5524e-08, WD: 4.0588e-05
[2025-08-03 07:40:32] - Epoch 281/500,it:114648, Train Loss: 1.2503e-01, Val Loss: 2.3233e-02, best model: 259, LR: 4.0323e-04, epoch time: 86.38, snr: 1.2348e+00, var(R): 1.2816e-10, var(L*R): 4.8895e-09, WD: 4.0631e-05
[2025-08-03 07:41:59] - Epoch 282/500,it:115056, Train Loss: 1.6699e-01, Val Loss: 3.7238e-02, best model: 259, LR: 4.0015e-04, epoch time: 86.61, snr: 1.4535e+01, var(R): 1.5080e-10, var(L*R): 6.9799e-09, WD: 4.0713e-05
[2025-08-03 07:43:25] - Epoch 283/500,it:115464, Train Loss: 1.5352e-01, Val Loss: 2.3543e-02, best model: 259, LR: 3.9707e-04, epoch time: 86.48, snr: 2.0554e+01, var(R): 2.2900e-10, var(L*R): 1.6805e-08, WD: 4.0796e-05
[2025-08-03 07:44:52] - Epoch 284/500,it:115872, Train Loss: 1.3883e-01, Val Loss: 3.1200e-02, best model: 259, LR: 3.9400e-04, epoch time: 86.56, snr: 1.5987e+00, var(R): 8.9895e-11, var(L*R): 3.0760e-09, WD: 4.0920e-05
[2025-08-03 07:46:18] - Epoch 285/500,it:116280, Train Loss: 1.2446e-01, Val Loss: 2.6039e-02, best model: 259, LR: 3.9093e-04, epoch time: 86.35, snr: 5.0529e+00, var(R): 1.0322e-10, var(L*R): 5.0019e-09, WD: 4.0984e-05
[2025-08-03 07:47:45] - Epoch 286/500,it:116688, Train Loss: 1.3933e-01, Val Loss: 2.6653e-02, best model: 259, LR: 3.8786e-04, epoch time: 86.61, snr: 4.5674e+00, var(R): 1.4168e-10, var(L*R): 5.3557e-09, WD: 4.1024e-05
[2025-08-03 07:49:11] - Epoch 287/500,it:117096, Train Loss: 1.7269e-01, Val Loss: 3.5231e-02, best model: 259, LR: 3.8481e-04, epoch time: 86.55, snr: 1.7305e+00, var(R): 1.1636e-10, var(L*R): 2.9056e-09, WD: 4.1162e-05
[2025-08-03 07:50:38] - Epoch 288/500,it:117504, Train Loss: 1.4756e-01, Val Loss: 2.4133e-02, best model: 259, LR: 3.8175e-04, epoch time: 86.49, snr: 4.7421e+00, var(R): 1.9328e-10, var(L*R): 5.9162e-09, WD: 4.1247e-05
[2025-08-03 07:52:04] - Epoch 289/500,it:117912, Train Loss: 1.2825e-01, Val Loss: 2.3374e-02, best model: 259, LR: 3.7870e-04, epoch time: 86.53, snr: 5.2162e+00, var(R): 1.5362e-10, var(L*R): 7.0006e-09, WD: 4.1328e-05
[2025-08-03 07:53:31] - Epoch 290/500,it:118320, Train Loss: 1.2185e-01, Val Loss: 2.6797e-02, best model: 259, LR: 3.7566e-04, epoch time: 86.59, snr: 1.0895e+01, var(R): 1.4438e-10, var(L*R): 8.6185e-09, WD: 4.1414e-05
[2025-08-03 07:54:58] - Epoch 291/500,it:118728, Train Loss: 1.4281e-01, Val Loss: 2.6690e-02, best model: 259, LR: 3.7261e-04, epoch time: 86.59, snr: 8.9025e-01, var(R): 8.3488e-11, var(L*R): 2.4667e-09, WD: 4.1497e-05
[2025-08-03 07:56:24] - Epoch 292/500,it:119136, Train Loss: 1.5298e-01, Val Loss: 2.4624e-02, best model: 259, LR: 3.6958e-04, epoch time: 86.44, snr: 9.1269e-01, var(R): 1.0697e-10, var(L*R): 4.9491e-09, WD: 4.1575e-05
[2025-08-03 07:57:51] - Epoch 293/500,it:119544, Train Loss: 1.3939e-01, Val Loss: 2.1426e-02, best model: 293, LR: 3.6655e-04, epoch time: 86.59, snr: 2.5279e+00, var(R): 9.9935e-11, var(L*R): 4.1303e-09, WD: 4.1613e-05
[2025-08-03 07:59:17] - Epoch 294/500,it:119952, Train Loss: 1.4042e-01, Val Loss: 3.4097e-02, best model: 293, LR: 3.6352e-04, epoch time: 86.47, snr: 1.3203e+01, var(R): 1.2595e-10, var(L*R): 9.2829e-09, WD: 4.1714e-05
[2025-08-03 08:00:44] - Epoch 295/500,it:120360, Train Loss: 1.3891e-01, Val Loss: 2.2573e-02, best model: 293, LR: 3.6050e-04, epoch time: 86.53, snr: 1.8644e+01, var(R): 2.6969e-10, var(L*R): 9.8644e-09, WD: 4.1815e-05
[2025-08-03 08:02:10] - Epoch 296/500,it:120768, Train Loss: 1.4590e-01, Val Loss: 2.4413e-02, best model: 293, LR: 3.5749e-04, epoch time: 86.63, snr: 2.5325e+00, var(R): 1.5278e-10, var(L*R): 7.5950e-09, WD: 4.1930e-05
[2025-08-03 08:03:37] - Epoch 297/500,it:121176, Train Loss: 1.1432e-01, Val Loss: 2.0631e-02, best model: 297, LR: 3.5448e-04, epoch time: 86.67, snr: 1.6075e+01, var(R): 1.6839e-10, var(L*R): 1.0129e-08, WD: 4.2011e-05
[2025-08-03 08:05:03] - Epoch 298/500,it:121584, Train Loss: 1.2228e-01, Val Loss: 2.2717e-02, best model: 297, LR: 3.5148e-04, epoch time: 86.50, snr: 1.0703e+01, var(R): 1.3306e-10, var(L*R): 1.2466e-08, WD: 4.2036e-05
[2025-08-03 08:06:30] - Epoch 299/500,it:121992, Train Loss: 1.3818e-01, Val Loss: 2.4203e-02, best model: 297, LR: 3.4848e-04, epoch time: 86.51, snr: 1.5093e+01, var(R): 1.4495e-10, var(L*R): 1.1070e-08, WD: 4.2090e-05
[2025-08-03 08:07:56] - Epoch 300/500,it:122400, Train Loss: 1.3748e-01, Val Loss: 2.2389e-02, best model: 297, LR: 3.4549e-04, epoch time: 86.49, snr: 6.2147e+00, var(R): 1.1892e-10, var(L*R): 3.5751e-09, WD: 4.2177e-05
[2025-08-03 08:09:23] - Epoch 301/500,it:122808, Train Loss: 1.3550e-01, Val Loss: 2.2145e-02, best model: 297, LR: 3.4251e-04, epoch time: 86.50, snr: 8.2785e-01, var(R): 9.8523e-11, var(L*R): 6.8526e-09, WD: 4.2272e-05
[2025-08-03 08:10:49] - Epoch 302/500,it:123216, Train Loss: 1.1811e-01, Val Loss: 2.2731e-02, best model: 297, LR: 3.3953e-04, epoch time: 86.56, snr: 8.5048e+00, var(R): 1.5246e-10, var(L*R): 6.3171e-09, WD: 4.2360e-05
[2025-08-03 08:12:16] - Epoch 303/500,it:123624, Train Loss: 1.3626e-01, Val Loss: 2.8822e-02, best model: 297, LR: 3.3656e-04, epoch time: 86.52, snr: 1.1192e+00, var(R): 1.5034e-10, var(L*R): 4.7717e-09, WD: 4.2425e-05
[2025-08-03 08:13:42] - Epoch 304/500,it:124032, Train Loss: 1.3217e-01, Val Loss: 3.6542e-02, best model: 297, LR: 3.3359e-04, epoch time: 86.39, snr: 4.1231e+00, var(R): 1.4538e-10, var(L*R): 5.7288e-09, WD: 4.2476e-05
[2025-08-03 08:15:09] - Epoch 305/500,it:124440, Train Loss: 1.3991e-01, Val Loss: 2.0347e-02, best model: 305, LR: 3.3063e-04, epoch time: 86.58, snr: 2.5726e+00, var(R): 2.7067e-10, var(L*R): 1.5054e-08, WD: 4.2603e-05
[2025-08-03 08:16:35] - Epoch 306/500,it:124848, Train Loss: 1.0710e-01, Val Loss: 2.1753e-02, best model: 305, LR: 3.2768e-04, epoch time: 86.50, snr: 2.0865e+00, var(R): 1.3959e-10, var(L*R): 5.8578e-09, WD: 4.2671e-05
[2025-08-03 08:18:02] - Epoch 307/500,it:125256, Train Loss: 1.2567e-01, Val Loss: 2.1075e-02, best model: 305, LR: 3.2473e-04, epoch time: 86.42, snr: 6.5573e+00, var(R): 1.5013e-10, var(L*R): 9.0030e-09, WD: 4.2713e-05
[2025-08-03 08:19:28] - Epoch 308/500,it:125664, Train Loss: 1.1498e-01, Val Loss: 2.0622e-02, best model: 305, LR: 3.2179e-04, epoch time: 86.45, snr: 5.2623e+00, var(R): 1.4745e-10, var(L*R): 6.3643e-09, WD: 4.2809e-05
[2025-08-03 08:20:55] - Epoch 309/500,it:126072, Train Loss: 1.0727e-01, Val Loss: 2.3779e-02, best model: 305, LR: 3.1886e-04, epoch time: 86.43, snr: 1.1650e+01, var(R): 1.7381e-10, var(L*R): 1.0282e-08, WD: 4.2884e-05
[2025-08-03 08:22:21] - Epoch 310/500,it:126480, Train Loss: 1.0803e-01, Val Loss: 2.3568e-02, best model: 305, LR: 3.1594e-04, epoch time: 86.50, snr: 1.6182e+00, var(R): 1.5008e-10, var(L*R): 7.2138e-09, WD: 4.2917e-05
[2025-08-03 08:23:48] - Epoch 311/500,it:126888, Train Loss: 1.3915e-01, Val Loss: 2.1278e-02, best model: 305, LR: 3.1302e-04, epoch time: 86.47, snr: 2.3092e+00, var(R): 1.7136e-10, var(L*R): 6.3116e-09, WD: 4.2949e-05
[2025-08-03 08:25:14] - Epoch 312/500,it:127296, Train Loss: 1.2017e-01, Val Loss: 3.5758e-02, best model: 305, LR: 3.1011e-04, epoch time: 86.46, snr: 1.3523e+01, var(R): 1.7022e-10, var(L*R): 9.4127e-09, WD: 4.3022e-05
[2025-08-03 08:26:41] - Epoch 313/500,it:127704, Train Loss: 1.1121e-01, Val Loss: 1.9278e-02, best model: 313, LR: 3.0721e-04, epoch time: 86.75, snr: 1.7839e+01, var(R): 3.1031e-10, var(L*R): 2.3316e-08, WD: 4.3110e-05
[2025-08-03 08:28:08] - Epoch 314/500,it:128112, Train Loss: 1.1307e-01, Val Loss: 2.0103e-02, best model: 313, LR: 3.0431e-04, epoch time: 86.55, snr: 1.3984e+01, var(R): 1.6618e-10, var(L*R): 9.4544e-09, WD: 4.3164e-05
[2025-08-03 08:29:34] - Epoch 315/500,it:128520, Train Loss: 1.2020e-01, Val Loss: 2.3383e-02, best model: 313, LR: 3.0143e-04, epoch time: 86.39, snr: 3.8255e+00, var(R): 1.5563e-10, var(L*R): 4.5807e-09, WD: 4.3209e-05
[2025-08-03 08:31:01] - Epoch 316/500,it:128928, Train Loss: 1.2174e-01, Val Loss: 2.5418e-02, best model: 313, LR: 2.9855e-04, epoch time: 86.62, snr: 1.4827e+01, var(R): 1.8452e-10, var(L*R): 1.9496e-08, WD: 4.3273e-05
[2025-08-03 08:32:27] - Epoch 317/500,it:129336, Train Loss: 1.0695e-01, Val Loss: 1.9867e-02, best model: 313, LR: 2.9568e-04, epoch time: 86.61, snr: 2.2247e+00, var(R): 1.3133e-10, var(L*R): 7.6119e-09, WD: 4.3324e-05
[2025-08-03 08:33:54] - Epoch 318/500,it:129744, Train Loss: 1.0683e-01, Val Loss: 2.0319e-02, best model: 313, LR: 2.9281e-04, epoch time: 86.46, snr: 1.0703e+01, var(R): 1.2765e-10, var(L*R): 8.1993e-09, WD: 4.3400e-05
[2025-08-03 08:35:20] - Epoch 319/500,it:130152, Train Loss: 1.1381e-01, Val Loss: 2.1600e-02, best model: 313, LR: 2.8996e-04, epoch time: 86.55, snr: 1.3307e+01, var(R): 1.5623e-10, var(L*R): 1.1675e-08, WD: 4.3470e-05
[2025-08-03 08:36:47] - Epoch 320/500,it:130560, Train Loss: 9.7767e-02, Val Loss: 2.2288e-02, best model: 313, LR: 2.8711e-04, epoch time: 86.67, snr: 4.3829e+00, var(R): 1.3048e-10, var(L*R): 6.5564e-09, WD: 4.3527e-05
[2025-08-03 08:38:13] - Epoch 321/500,it:130968, Train Loss: 1.1031e-01, Val Loss: 2.1947e-02, best model: 313, LR: 2.8427e-04, epoch time: 86.61, snr: 2.2026e+00, var(R): 1.7048e-10, var(L*R): 8.1272e-09, WD: 4.3568e-05
[2025-08-03 08:39:40] - Epoch 322/500,it:131376, Train Loss: 1.4433e-01, Val Loss: 3.0121e-02, best model: 313, LR: 2.8144e-04, epoch time: 86.37, snr: 6.9293e+00, var(R): 1.5045e-10, var(L*R): 6.4430e-09, WD: 4.3627e-05
[2025-08-03 08:41:06] - Epoch 323/500,it:131784, Train Loss: 1.1188e-01, Val Loss: 1.7435e-02, best model: 323, LR: 2.7862e-04, epoch time: 86.60, snr: 1.7771e+00, var(R): 1.5867e-10, var(L*R): 7.8610e-09, WD: 4.3693e-05
[2025-08-03 08:42:33] - Epoch 324/500,it:132192, Train Loss: 1.0363e-01, Val Loss: 1.9039e-02, best model: 323, LR: 2.7581e-04, epoch time: 86.51, snr: 9.9716e+00, var(R): 1.5411e-10, var(L*R): 7.8786e-09, WD: 4.3758e-05
[2025-08-03 08:44:00] - Epoch 325/500,it:132600, Train Loss: 1.0200e-01, Val Loss: 1.7231e-02, best model: 325, LR: 2.7300e-04, epoch time: 86.65, snr: 1.4342e+01, var(R): 1.9192e-10, var(L*R): 1.3359e-08, WD: 4.3825e-05
[2025-08-03 08:45:26] - Epoch 326/500,it:133008, Train Loss: 9.9073e-02, Val Loss: 2.1504e-02, best model: 325, LR: 2.7021e-04, epoch time: 86.48, snr: 9.2524e+00, var(R): 1.5516e-10, var(L*R): 8.1239e-09, WD: 4.3883e-05
[2025-08-03 08:46:53] - Epoch 327/500,it:133416, Train Loss: 1.0359e-01, Val Loss: 1.8943e-02, best model: 325, LR: 2.6742e-04, epoch time: 86.47, snr: 2.9259e+00, var(R): 2.0668e-10, var(L*R): 1.2730e-08, WD: 4.3927e-05
[2025-08-03 08:48:19] - Epoch 328/500,it:133824, Train Loss: 1.0476e-01, Val Loss: 3.7040e-02, best model: 325, LR: 2.6465e-04, epoch time: 86.48, snr: 5.0608e+00, var(R): 1.7002e-10, var(L*R): 1.5403e-08, WD: 4.3976e-05
[2025-08-03 08:49:46] - Epoch 329/500,it:134232, Train Loss: 1.3121e-01, Val Loss: 3.9743e-02, best model: 325, LR: 2.6188e-04, epoch time: 86.51, snr: 7.5440e+00, var(R): 3.1216e-10, var(L*R): 4.8796e-08, WD: 4.4015e-05
[2025-08-03 08:51:12] - Epoch 330/500,it:134640, Train Loss: 1.3804e-01, Val Loss: 2.1211e-02, best model: 325, LR: 2.5912e-04, epoch time: 86.40, snr: 8.2521e+00, var(R): 2.9727e-10, var(L*R): 2.2345e-08, WD: 4.4084e-05
[2025-08-03 08:52:39] - Epoch 331/500,it:135048, Train Loss: 9.8921e-02, Val Loss: 1.9254e-02, best model: 325, LR: 2.5637e-04, epoch time: 86.70, snr: 2.4143e+00, var(R): 1.6985e-10, var(L*R): 8.4040e-09, WD: 4.4176e-05
[2025-08-03 08:54:05] - Epoch 332/500,it:135456, Train Loss: 1.1606e-01, Val Loss: 3.2368e-02, best model: 325, LR: 2.5364e-04, epoch time: 86.44, snr: 6.1997e+00, var(R): 1.6747e-10, var(L*R): 9.6688e-09, WD: 4.4209e-05
[2025-08-03 08:55:32] - Epoch 333/500,it:135864, Train Loss: 1.0792e-01, Val Loss: 2.6297e-02, best model: 325, LR: 2.5091e-04, epoch time: 86.50, snr: 1.9644e+01, var(R): 3.0191e-10, var(L*R): 3.8980e-08, WD: 4.4314e-05
[2025-08-03 08:56:58] - Epoch 334/500,it:136272, Train Loss: 1.1458e-01, Val Loss: 2.0199e-02, best model: 325, LR: 2.4819e-04, epoch time: 86.49, snr: 2.9633e+00, var(R): 1.7848e-10, var(L*R): 2.3504e-08, WD: 4.4339e-05
[2025-08-03 08:58:25] - Epoch 335/500,it:136680, Train Loss: 1.2205e-01, Val Loss: 2.2017e-02, best model: 325, LR: 2.4548e-04, epoch time: 86.48, snr: 2.9725e+00, var(R): 1.6601e-10, var(L*R): 1.5391e-08, WD: 4.4401e-05
[2025-08-03 08:59:51] - Epoch 336/500,it:137088, Train Loss: 9.5899e-02, Val Loss: 2.0737e-02, best model: 325, LR: 2.4278e-04, epoch time: 86.51, snr: 1.1096e+01, var(R): 2.2364e-10, var(L*R): 1.6020e-08, WD: 4.4483e-05
[2025-08-03 09:01:17] - Epoch 337/500,it:137496, Train Loss: 9.6707e-02, Val Loss: 1.7284e-02, best model: 325, LR: 2.4009e-04, epoch time: 86.38, snr: 2.1797e+00, var(R): 1.8013e-10, var(L*R): 9.4217e-09, WD: 4.4499e-05
[2025-08-03 09:02:44] - Epoch 338/500,it:137904, Train Loss: 1.1670e-01, Val Loss: 1.9321e-02, best model: 325, LR: 2.3741e-04, epoch time: 86.47, snr: 9.6933e+00, var(R): 2.1008e-10, var(L*R): 1.0791e-08, WD: 4.4575e-05
[2025-08-03 09:04:10] - Epoch 339/500,it:138312, Train Loss: 1.0830e-01, Val Loss: 1.9728e-02, best model: 325, LR: 2.3474e-04, epoch time: 86.47, snr: 5.0645e+00, var(R): 2.0371e-10, var(L*R): 1.2905e-08, WD: 4.4637e-05
[2025-08-03 09:05:37] - Epoch 340/500,it:138720, Train Loss: 1.1263e-01, Val Loss: 2.3070e-02, best model: 325, LR: 2.3209e-04, epoch time: 86.45, snr: 9.1538e+00, var(R): 2.2332e-10, var(L*R): 2.1076e-08, WD: 4.4687e-05
[2025-08-03 09:07:03] - Epoch 341/500,it:139128, Train Loss: 1.0656e-01, Val Loss: 1.6931e-02, best model: 341, LR: 2.2944e-04, epoch time: 86.43, snr: 1.5584e+01, var(R): 2.3264e-10, var(L*R): 3.3249e-08, WD: 4.4760e-05
[2025-08-03 09:08:30] - Epoch 342/500,it:139536, Train Loss: 9.0333e-02, Val Loss: 1.7095e-02, best model: 341, LR: 2.2680e-04, epoch time: 86.41, snr: 1.1705e+01, var(R): 1.7209e-10, var(L*R): 1.2473e-08, WD: 4.4783e-05
[2025-08-03 09:09:56] - Epoch 343/500,it:139944, Train Loss: 9.7709e-02, Val Loss: 1.8667e-02, best model: 341, LR: 2.2418e-04, epoch time: 86.55, snr: 9.5586e+00, var(R): 1.9352e-10, var(L*R): 1.2708e-08, WD: 4.4855e-05
[2025-08-03 09:11:23] - Epoch 344/500,it:140352, Train Loss: 1.2793e-01, Val Loss: 1.8029e-02, best model: 341, LR: 2.2156e-04, epoch time: 86.48, snr: 1.1739e+01, var(R): 1.7696e-10, var(L*R): 1.0242e-08, WD: 4.4882e-05
[2025-08-03 09:12:49] - Epoch 345/500,it:140760, Train Loss: 9.4648e-02, Val Loss: 1.6375e-02, best model: 345, LR: 2.1896e-04, epoch time: 86.36, snr: 6.5095e+00, var(R): 1.9361e-10, var(L*R): 1.3463e-08, WD: 4.4957e-05
[2025-08-03 09:14:16] - Epoch 346/500,it:141168, Train Loss: 1.0544e-01, Val Loss: 1.5621e-02, best model: 346, LR: 2.1637e-04, epoch time: 86.73, snr: 1.1877e+01, var(R): 2.2857e-10, var(L*R): 1.5305e-08, WD: 4.5003e-05
[2025-08-03 09:15:42] - Epoch 347/500,it:141576, Train Loss: 8.8590e-02, Val Loss: 1.6098e-02, best model: 346, LR: 2.1378e-04, epoch time: 86.52, snr: 7.7642e+00, var(R): 1.8384e-10, var(L*R): 9.4791e-09, WD: 4.5076e-05
[2025-08-03 09:17:09] - Epoch 348/500,it:141984, Train Loss: 1.0652e-01, Val Loss: 1.7779e-02, best model: 346, LR: 2.1121e-04, epoch time: 86.54, snr: 9.7351e+00, var(R): 2.0582e-10, var(L*R): 1.2464e-08, WD: 4.5079e-05
[2025-08-03 09:18:35] - Epoch 349/500,it:142392, Train Loss: 9.3351e-02, Val Loss: 1.7742e-02, best model: 346, LR: 2.0865e-04, epoch time: 86.33, snr: 1.1661e+01, var(R): 2.0722e-10, var(L*R): 1.3237e-08, WD: 4.5156e-05
[2025-08-03 09:20:02] - Epoch 350/500,it:142800, Train Loss: 9.7177e-02, Val Loss: 2.3329e-02, best model: 346, LR: 2.0611e-04, epoch time: 86.52, snr: 3.7088e+00, var(R): 1.7799e-10, var(L*R): 9.6799e-09, WD: 4.5194e-05
[2025-08-03 09:21:28] - Epoch 351/500,it:143208, Train Loss: 1.1685e-01, Val Loss: 2.1974e-02, best model: 346, LR: 2.0357e-04, epoch time: 86.41, snr: 1.2893e+01, var(R): 2.6205e-10, var(L*R): 2.3649e-08, WD: 4.5237e-05
[2025-08-03 09:22:54] - Epoch 352/500,it:143616, Train Loss: 1.0108e-01, Val Loss: 1.5752e-02, best model: 346, LR: 2.0105e-04, epoch time: 86.35, snr: 2.5821e+00, var(R): 1.8347e-10, var(L*R): 1.4846e-08, WD: 4.5320e-05
[2025-08-03 09:24:21] - Epoch 353/500,it:144024, Train Loss: 9.5111e-02, Val Loss: 1.7453e-02, best model: 346, LR: 1.9854e-04, epoch time: 86.59, snr: 6.4030e+00, var(R): 1.7735e-10, var(L*R): 1.1442e-08, WD: 4.5350e-05
[2025-08-03 09:25:48] - Epoch 354/500,it:144432, Train Loss: 8.5154e-02, Val Loss: 2.4558e-02, best model: 346, LR: 1.9603e-04, epoch time: 86.52, snr: 6.0905e+00, var(R): 1.8295e-10, var(L*R): 1.6389e-08, WD: 4.5375e-05
[2025-08-03 09:27:14] - Epoch 355/500,it:144840, Train Loss: 9.4873e-02, Val Loss: 1.6771e-02, best model: 346, LR: 1.9355e-04, epoch time: 86.47, snr: 1.3530e+01, var(R): 2.7901e-10, var(L*R): 1.5653e-08, WD: 4.5416e-05
[2025-08-03 09:28:40] - Epoch 356/500,it:145248, Train Loss: 9.8951e-02, Val Loss: 1.9833e-02, best model: 346, LR: 1.9107e-04, epoch time: 86.35, snr: 1.1853e+01, var(R): 2.3418e-10, var(L*R): 1.4686e-08, WD: 4.5478e-05
[2025-08-03 09:30:07] - Epoch 357/500,it:145656, Train Loss: 9.4455e-02, Val Loss: 1.6227e-02, best model: 346, LR: 1.8861e-04, epoch time: 86.48, snr: 1.4424e+01, var(R): 2.4828e-10, var(L*R): 3.1363e-08, WD: 4.5526e-05
[2025-08-03 09:31:33] - Epoch 358/500,it:146064, Train Loss: 9.2779e-02, Val Loss: 1.7181e-02, best model: 346, LR: 1.8615e-04, epoch time: 86.51, snr: 7.1661e+00, var(R): 2.0662e-10, var(L*R): 1.7396e-08, WD: 4.5574e-05
[2025-08-03 09:33:00] - Epoch 359/500,it:146472, Train Loss: 9.0833e-02, Val Loss: 1.6416e-02, best model: 346, LR: 1.8371e-04, epoch time: 86.49, snr: 8.4425e+00, var(R): 1.8438e-10, var(L*R): 9.9769e-09, WD: 4.5594e-05
[2025-08-03 09:34:26] - Epoch 360/500,it:146880, Train Loss: 8.7010e-02, Val Loss: 1.5688e-02, best model: 346, LR: 1.8129e-04, epoch time: 86.51, snr: 1.0113e+01, var(R): 2.1568e-10, var(L*R): 2.7187e-08, WD: 4.5672e-05
[2025-08-03 09:35:53] - Epoch 361/500,it:147288, Train Loss: 8.7877e-02, Val Loss: 1.4893e-02, best model: 361, LR: 1.7887e-04, epoch time: 86.70, snr: 9.8586e+00, var(R): 1.8892e-10, var(L*R): 1.5178e-08, WD: 4.5683e-05
[2025-08-03 09:37:20] - Epoch 362/500,it:147696, Train Loss: 9.9420e-02, Val Loss: 2.1232e-02, best model: 361, LR: 1.7647e-04, epoch time: 86.39, snr: 9.4611e+00, var(R): 2.1746e-10, var(L*R): 1.5679e-08, WD: 4.5726e-05
[2025-08-03 09:38:46] - Epoch 363/500,it:148104, Train Loss: 8.8720e-02, Val Loss: 1.5753e-02, best model: 361, LR: 1.7408e-04, epoch time: 86.51, snr: 1.4959e+01, var(R): 2.7520e-10, var(L*R): 2.9242e-08, WD: 4.5757e-05
[2025-08-03 09:40:12] - Epoch 364/500,it:148512, Train Loss: 8.2659e-02, Val Loss: 1.6023e-02, best model: 361, LR: 1.7171e-04, epoch time: 86.36, snr: 1.2719e+01, var(R): 2.3746e-10, var(L*R): 1.8505e-08, WD: 4.5796e-05
[2025-08-03 09:41:39] - Epoch 365/500,it:148920, Train Loss: 8.2815e-02, Val Loss: 1.4562e-02, best model: 365, LR: 1.6934e-04, epoch time: 86.59, snr: 1.1425e+01, var(R): 2.4001e-10, var(L*R): 2.0351e-08, WD: 4.5835e-05
[2025-08-03 09:43:05] - Epoch 366/500,it:149328, Train Loss: 8.8571e-02, Val Loss: 1.8571e-02, best model: 365, LR: 1.6699e-04, epoch time: 86.51, snr: 8.1401e+00, var(R): 2.1406e-10, var(L*R): 1.6981e-08, WD: 4.5859e-05
[2025-08-03 09:44:32] - Epoch 367/500,it:149736, Train Loss: 9.2253e-02, Val Loss: 1.7247e-02, best model: 365, LR: 1.6466e-04, epoch time: 86.40, snr: 1.3680e+01, var(R): 2.4359e-10, var(L*R): 2.1476e-08, WD: 4.5921e-05
[2025-08-03 09:45:58] - Epoch 368/500,it:150144, Train Loss: 9.5983e-02, Val Loss: 1.8168e-02, best model: 365, LR: 1.6233e-04, epoch time: 86.44, snr: 1.1424e+01, var(R): 2.3558e-10, var(L*R): 1.9276e-08, WD: 4.5961e-05
[2025-08-03 09:47:25] - Epoch 369/500,it:150552, Train Loss: 8.7191e-02, Val Loss: 2.1132e-02, best model: 365, LR: 1.6002e-04, epoch time: 86.49, snr: 5.8125e+00, var(R): 1.9013e-10, var(L*R): 2.4989e-08, WD: 4.6020e-05
[2025-08-03 09:48:51] - Epoch 370/500,it:150960, Train Loss: 8.4554e-02, Val Loss: 1.4390e-02, best model: 370, LR: 1.5773e-04, epoch time: 86.56, snr: 2.8847e+00, var(R): 2.6447e-10, var(L*R): 2.2976e-08, WD: 4.6056e-05
[2025-08-03 09:50:18] - Epoch 371/500,it:151368, Train Loss: 7.8161e-02, Val Loss: 1.5941e-02, best model: 370, LR: 1.5544e-04, epoch time: 86.35, snr: 9.4623e+00, var(R): 2.1070e-10, var(L*R): 1.3568e-08, WD: 4.6059e-05
[2025-08-03 09:51:44] - Epoch 372/500,it:151776, Train Loss: 8.4326e-02, Val Loss: 1.6114e-02, best model: 370, LR: 1.5317e-04, epoch time: 86.68, snr: 7.0721e+00, var(R): 2.3284e-10, var(L*R): 1.8527e-08, WD: 4.6106e-05
[2025-08-03 09:53:11] - Epoch 373/500,it:152184, Train Loss: 7.7195e-02, Val Loss: 1.7360e-02, best model: 370, LR: 1.5092e-04, epoch time: 86.61, snr: 1.1139e+01, var(R): 2.5777e-10, var(L*R): 2.0507e-08, WD: 4.6160e-05
[2025-08-03 09:54:38] - Epoch 374/500,it:152592, Train Loss: 8.0176e-02, Val Loss: 1.8916e-02, best model: 370, LR: 1.4868e-04, epoch time: 86.57, snr: 2.3339e+00, var(R): 2.0912e-10, var(L*R): 1.8457e-08, WD: 4.6149e-05
[2025-08-03 09:56:04] - Epoch 375/500,it:153000, Train Loss: 8.3175e-02, Val Loss: 1.4903e-02, best model: 370, LR: 1.4645e-04, epoch time: 86.37, snr: 1.3249e+01, var(R): 3.0588e-10, var(L*R): 2.8981e-08, WD: 4.6205e-05
[2025-08-03 09:57:30] - Epoch 376/500,it:153408, Train Loss: 8.1248e-02, Val Loss: 1.5261e-02, best model: 370, LR: 1.4423e-04, epoch time: 86.43, snr: 7.7959e+00, var(R): 2.0755e-10, var(L*R): 1.8377e-08, WD: 4.6241e-05
[2025-08-03 09:58:57] - Epoch 377/500,it:153816, Train Loss: 7.9685e-02, Val Loss: 1.5969e-02, best model: 370, LR: 1.4203e-04, epoch time: 86.50, snr: 6.6610e+00, var(R): 2.2381e-10, var(L*R): 2.9934e-08, WD: 4.6249e-05
[2025-08-03 10:00:23] - Epoch 378/500,it:154224, Train Loss: 8.0562e-02, Val Loss: 1.4127e-02, best model: 378, LR: 1.3985e-04, epoch time: 86.51, snr: 4.9812e+00, var(R): 2.1815e-10, var(L*R): 1.8785e-08, WD: 4.6307e-05
[2025-08-03 10:01:50] - Epoch 379/500,it:154632, Train Loss: 8.4547e-02, Val Loss: 1.6913e-02, best model: 378, LR: 1.3767e-04, epoch time: 86.54, snr: 1.0765e+01, var(R): 2.4902e-10, var(L*R): 1.8735e-08, WD: 4.6282e-05
[2025-08-03 10:03:17] - Epoch 380/500,it:155040, Train Loss: 7.9574e-02, Val Loss: 1.3711e-02, best model: 380, LR: 1.3552e-04, epoch time: 86.58, snr: 9.3975e+00, var(R): 2.8746e-10, var(L*R): 2.9951e-08, WD: 4.6332e-05
[2025-08-03 10:04:43] - Epoch 381/500,it:155448, Train Loss: 8.7889e-02, Val Loss: 1.5050e-02, best model: 380, LR: 1.3337e-04, epoch time: 86.63, snr: 8.8005e+00, var(R): 2.2531e-10, var(L*R): 1.9636e-08, WD: 4.6392e-05
[2025-08-03 10:06:10] - Epoch 382/500,it:155856, Train Loss: 7.4041e-02, Val Loss: 1.4250e-02, best model: 380, LR: 1.3124e-04, epoch time: 86.34, snr: 5.6215e+00, var(R): 2.4150e-10, var(L*R): 1.9725e-08, WD: 4.6422e-05
[2025-08-03 10:07:36] - Epoch 383/500,it:156264, Train Loss: 7.3252e-02, Val Loss: 1.3971e-02, best model: 380, LR: 1.2913e-04, epoch time: 86.56, snr: 8.2303e+00, var(R): 2.2507e-10, var(L*R): 1.6538e-08, WD: 4.6454e-05
[2025-08-03 10:09:03] - Epoch 384/500,it:156672, Train Loss: 7.6985e-02, Val Loss: 1.5435e-02, best model: 380, LR: 1.2703e-04, epoch time: 86.47, snr: 8.5883e+00, var(R): 2.4090e-10, var(L*R): 1.9437e-08, WD: 4.6465e-05
[2025-08-03 10:10:29] - Epoch 385/500,it:157080, Train Loss: 7.3723e-02, Val Loss: 1.3628e-02, best model: 385, LR: 1.2494e-04, epoch time: 86.53, snr: 6.5496e+00, var(R): 2.1917e-10, var(L*R): 1.5319e-08, WD: 4.6489e-05
[2025-08-03 10:11:56] - Epoch 386/500,it:157488, Train Loss: 7.3640e-02, Val Loss: 1.4576e-02, best model: 385, LR: 1.2287e-04, epoch time: 86.40, snr: 1.0103e+01, var(R): 2.3555e-10, var(L*R): 2.1479e-08, WD: 4.6497e-05
[2025-08-03 10:13:22] - Epoch 387/500,it:157896, Train Loss: 7.6994e-02, Val Loss: 1.3862e-02, best model: 385, LR: 1.2082e-04, epoch time: 86.47, snr: 7.0386e+00, var(R): 2.5688e-10, var(L*R): 1.9885e-08, WD: 4.6537e-05
[2025-08-03 10:14:49] - Epoch 388/500,it:158304, Train Loss: 8.2237e-02, Val Loss: 1.4414e-02, best model: 385, LR: 1.1878e-04, epoch time: 86.54, snr: 1.1418e+01, var(R): 2.6863e-10, var(L*R): 2.2011e-08, WD: 4.6544e-05
[2025-08-03 10:16:15] - Epoch 389/500,it:158712, Train Loss: 8.5127e-02, Val Loss: 1.7004e-02, best model: 385, LR: 1.1675e-04, epoch time: 86.48, snr: 7.9745e+00, var(R): 2.4561e-10, var(L*R): 2.2925e-08, WD: 4.6623e-05
[2025-08-03 10:17:41] - Epoch 390/500,it:159120, Train Loss: 7.1283e-02, Val Loss: 1.2882e-02, best model: 390, LR: 1.1474e-04, epoch time: 86.37, snr: 1.2678e+01, var(R): 2.8773e-10, var(L*R): 3.6217e-08, WD: 4.6645e-05
[2025-08-03 10:19:08] - Epoch 391/500,it:159528, Train Loss: 7.1417e-02, Val Loss: 1.4115e-02, best model: 390, LR: 1.1275e-04, epoch time: 86.56, snr: 9.9925e+00, var(R): 2.7242e-10, var(L*R): 2.3803e-08, WD: 4.6682e-05
[2025-08-03 10:20:34] - Epoch 392/500,it:159936, Train Loss: 7.7415e-02, Val Loss: 1.3940e-02, best model: 390, LR: 1.1077e-04, epoch time: 86.49, snr: 7.9559e+00, var(R): 2.5374e-10, var(L*R): 2.1776e-08, WD: 4.6680e-05
[2025-08-03 10:22:01] - Epoch 393/500,it:160344, Train Loss: 8.2184e-02, Val Loss: 1.5276e-02, best model: 390, LR: 1.0880e-04, epoch time: 86.49, snr: 1.1672e+01, var(R): 2.7701e-10, var(L*R): 2.8666e-08, WD: 4.6686e-05
[2025-08-03 10:23:27] - Epoch 394/500,it:160752, Train Loss: 6.9921e-02, Val Loss: 1.2261e-02, best model: 394, LR: 1.0686e-04, epoch time: 86.56, snr: 1.2498e+01, var(R): 2.8532e-10, var(L*R): 2.1015e-08, WD: 4.6740e-05
[2025-08-03 10:24:54] - Epoch 395/500,it:161160, Train Loss: 6.7616e-02, Val Loss: 1.3274e-02, best model: 394, LR: 1.0492e-04, epoch time: 86.51, snr: 1.0452e+01, var(R): 2.7886e-10, var(L*R): 2.4398e-08, WD: 4.6747e-05
[2025-08-03 10:26:20] - Epoch 396/500,it:161568, Train Loss: 7.3053e-02, Val Loss: 1.5226e-02, best model: 394, LR: 1.0300e-04, epoch time: 86.38, snr: 1.0186e+01, var(R): 2.7668e-10, var(L*R): 2.8547e-08, WD: 4.6777e-05
[2025-08-03 10:27:47] - Epoch 397/500,it:161976, Train Loss: 7.4017e-02, Val Loss: 1.2669e-02, best model: 394, LR: 1.0110e-04, epoch time: 86.40, snr: 6.7420e+00, var(R): 2.6206e-10, var(L*R): 2.4658e-08, WD: 4.6780e-05
[2025-08-03 10:29:13] - Epoch 398/500,it:162384, Train Loss: 7.7701e-02, Val Loss: 1.3839e-02, best model: 394, LR: 9.9217e-05, epoch time: 86.52, snr: 9.6076e+00, var(R): 2.5726e-10, var(L*R): 2.3249e-08, WD: 4.6815e-05
[2025-08-03 10:30:40] - Epoch 399/500,it:162792, Train Loss: 6.9095e-02, Val Loss: 1.2722e-02, best model: 394, LR: 9.7346e-05, epoch time: 86.45, snr: 1.0666e+01, var(R): 2.8568e-10, var(L*R): 2.4155e-08, WD: 4.6848e-05
[2025-08-03 10:32:06] - Epoch 400/500,it:163200, Train Loss: 7.3527e-02, Val Loss: 1.3975e-02, best model: 394, LR: 9.5492e-05, epoch time: 86.54, snr: 8.9834e+00, var(R): 2.7856e-10, var(L*R): 2.5163e-08, WD: 4.6844e-05
[2025-08-03 10:33:33] - Epoch 401/500,it:163608, Train Loss: 6.7687e-02, Val Loss: 1.3072e-02, best model: 394, LR: 9.3653e-05, epoch time: 86.38, snr: 7.4514e+00, var(R): 2.7528e-10, var(L*R): 2.3628e-08, WD: 4.6875e-05
[2025-08-03 10:34:59] - Epoch 402/500,it:164016, Train Loss: 7.4723e-02, Val Loss: 1.2119e-02, best model: 402, LR: 9.1830e-05, epoch time: 86.52, snr: 7.8000e+00, var(R): 2.6438e-10, var(L*R): 2.4688e-08, WD: 4.6917e-05
[2025-08-03 10:36:26] - Epoch 403/500,it:164424, Train Loss: 6.8333e-02, Val Loss: 1.2614e-02, best model: 402, LR: 9.0024e-05, epoch time: 86.53, snr: 9.4871e+00, var(R): 2.7707e-10, var(L*R): 2.8908e-08, WD: 4.6938e-05
[2025-08-03 10:37:52] - Epoch 404/500,it:164832, Train Loss: 7.5495e-02, Val Loss: 1.2487e-02, best model: 402, LR: 8.8234e-05, epoch time: 86.51, snr: 1.0024e+01, var(R): 2.7330e-10, var(L*R): 2.5909e-08, WD: 4.6953e-05
[2025-08-03 10:39:19] - Epoch 405/500,it:165240, Train Loss: 7.0840e-02, Val Loss: 1.2121e-02, best model: 402, LR: 8.6460e-05, epoch time: 86.36, snr: 1.0107e+01, var(R): 2.9036e-10, var(L*R): 2.9824e-08, WD: 4.6971e-05
[2025-08-03 10:40:45] - Epoch 406/500,it:165648, Train Loss: 7.4436e-02, Val Loss: 1.2888e-02, best model: 402, LR: 8.4702e-05, epoch time: 86.54, snr: 9.9631e+00, var(R): 2.8414e-10, var(L*R): 2.9984e-08, WD: 4.7015e-05
[2025-08-03 10:42:12] - Epoch 407/500,it:166056, Train Loss: 7.4218e-02, Val Loss: 1.2417e-02, best model: 402, LR: 8.2961e-05, epoch time: 86.43, snr: 9.0643e+00, var(R): 2.7002e-10, var(L*R): 2.8508e-08, WD: 4.7050e-05
[2025-08-03 10:43:38] - Epoch 408/500,it:166464, Train Loss: 7.0531e-02, Val Loss: 1.2016e-02, best model: 408, LR: 8.1236e-05, epoch time: 86.59, snr: 9.6281e+00, var(R): 3.0872e-10, var(L*R): 3.0435e-08, WD: 4.7053e-05
[2025-08-03 10:45:05] - Epoch 409/500,it:166872, Train Loss: 6.6551e-02, Val Loss: 1.2556e-02, best model: 408, LR: 7.9528e-05, epoch time: 86.47, snr: 1.0404e+01, var(R): 2.9748e-10, var(L*R): 3.3797e-08, WD: 4.7111e-05
[2025-08-03 10:46:31] - Epoch 410/500,it:167280, Train Loss: 6.6013e-02, Val Loss: 1.2257e-02, best model: 408, LR: 7.7836e-05, epoch time: 86.46, snr: 9.1023e+00, var(R): 2.8431e-10, var(L*R): 2.9798e-08, WD: 4.7134e-05
[2025-08-03 10:47:58] - Epoch 411/500,it:167688, Train Loss: 6.9639e-02, Val Loss: 1.2564e-02, best model: 408, LR: 7.6161e-05, epoch time: 86.45, snr: 1.1254e+01, var(R): 3.1093e-10, var(L*R): 3.4346e-08, WD: 4.7132e-05
[2025-08-03 10:49:24] - Epoch 412/500,it:168096, Train Loss: 6.8933e-02, Val Loss: 1.4016e-02, best model: 408, LR: 7.4503e-05, epoch time: 86.40, snr: 1.0254e+01, var(R): 3.1400e-10, var(L*R): 2.9472e-08, WD: 4.7156e-05
[2025-08-03 10:50:50] - Epoch 413/500,it:168504, Train Loss: 6.9961e-02, Val Loss: 1.2016e-02, best model: 408, LR: 7.2861e-05, epoch time: 86.57, snr: 1.2210e+01, var(R): 3.2297e-10, var(L*R): 3.9306e-08, WD: 4.7169e-05
[2025-08-03 10:52:17] - Epoch 414/500,it:168912, Train Loss: 6.7699e-02, Val Loss: 1.4327e-02, best model: 408, LR: 7.1237e-05, epoch time: 86.48, snr: 1.0448e+01, var(R): 3.1376e-10, var(L*R): 3.0451e-08, WD: 4.7193e-05
[2025-08-03 10:53:44] - Epoch 415/500,it:169320, Train Loss: 6.5240e-02, Val Loss: 1.2037e-02, best model: 408, LR: 6.9629e-05, epoch time: 86.54, snr: 1.2008e+01, var(R): 3.4467e-10, var(L*R): 3.5681e-08, WD: 4.7230e-05
[2025-08-03 10:55:10] - Epoch 416/500,it:169728, Train Loss: 6.5861e-02, Val Loss: 1.2207e-02, best model: 408, LR: 6.8038e-05, epoch time: 86.40, snr: 1.0140e+01, var(R): 3.0579e-10, var(L*R): 3.4745e-08, WD: 4.7222e-05
[2025-08-03 10:56:36] - Epoch 417/500,it:170136, Train Loss: 6.6542e-02, Val Loss: 1.2263e-02, best model: 408, LR: 6.6465e-05, epoch time: 86.55, snr: 1.0153e+01, var(R): 3.1281e-10, var(L*R): 3.0739e-08, WD: 4.7256e-05
[2025-08-03 10:58:03] - Epoch 418/500,it:170544, Train Loss: 6.6510e-02, Val Loss: 1.2328e-02, best model: 408, LR: 6.4908e-05, epoch time: 86.49, snr: 9.8284e+00, var(R): 2.9814e-10, var(L*R): 2.9439e-08, WD: 4.7246e-05
[2025-08-03 10:59:30] - Epoch 419/500,it:170952, Train Loss: 6.4793e-02, Val Loss: 1.2575e-02, best model: 408, LR: 6.3369e-05, epoch time: 86.61, snr: 9.2254e+00, var(R): 3.2583e-10, var(L*R): 2.9646e-08, WD: 4.7249e-05
[2025-08-03 11:00:56] - Epoch 420/500,it:171360, Train Loss: 6.5162e-02, Val Loss: 1.1604e-02, best model: 420, LR: 6.1847e-05, epoch time: 86.47, snr: 1.1177e+01, var(R): 3.5227e-10, var(L*R): 3.3220e-08, WD: 4.7306e-05
[2025-08-03 11:02:23] - Epoch 421/500,it:171768, Train Loss: 6.3350e-02, Val Loss: 1.1825e-02, best model: 420, LR: 6.0342e-05, epoch time: 86.53, snr: 1.1436e+01, var(R): 3.3832e-10, var(L*R): 3.8563e-08, WD: 4.7295e-05
[2025-08-03 11:03:49] - Epoch 422/500,it:172176, Train Loss: 6.3649e-02, Val Loss: 1.1815e-02, best model: 420, LR: 5.8854e-05, epoch time: 86.62, snr: 9.9899e+00, var(R): 3.3507e-10, var(L*R): 3.3484e-08, WD: 4.7300e-05
[2025-08-03 11:05:16] - Epoch 423/500,it:172584, Train Loss: 6.4547e-02, Val Loss: 1.2481e-02, best model: 420, LR: 5.7384e-05, epoch time: 86.43, snr: 9.8699e+00, var(R): 3.2430e-10, var(L*R): 3.1762e-08, WD: 4.7316e-05
[2025-08-03 11:06:42] - Epoch 424/500,it:172992, Train Loss: 6.2397e-02, Val Loss: 1.1336e-02, best model: 424, LR: 5.5932e-05, epoch time: 86.42, snr: 1.1999e+01, var(R): 3.6258e-10, var(L*R): 3.4214e-08, WD: 4.7336e-05
[2025-08-03 11:08:09] - Epoch 425/500,it:173400, Train Loss: 6.3912e-02, Val Loss: 1.1600e-02, best model: 424, LR: 5.4497e-05, epoch time: 86.64, snr: 1.1044e+01, var(R): 3.3630e-10, var(L*R): 3.4687e-08, WD: 4.7377e-05
[2025-08-03 11:09:35] - Epoch 426/500,it:173808, Train Loss: 6.1882e-02, Val Loss: 1.1854e-02, best model: 424, LR: 5.3079e-05, epoch time: 86.51, snr: 9.7728e+00, var(R): 3.3303e-10, var(L*R): 3.1340e-08, WD: 4.7375e-05
[2025-08-03 11:11:02] - Epoch 427/500,it:174216, Train Loss: 6.2895e-02, Val Loss: 1.1584e-02, best model: 424, LR: 5.1679e-05, epoch time: 86.48, snr: 1.0686e+01, var(R): 3.3703e-10, var(L*R): 3.0775e-08, WD: 4.7399e-05
[2025-08-03 11:12:28] - Epoch 428/500,it:174624, Train Loss: 6.1580e-02, Val Loss: 1.1257e-02, best model: 428, LR: 5.0297e-05, epoch time: 86.49, snr: 1.0664e+01, var(R): 3.3673e-10, var(L*R): 3.0736e-08, WD: 4.7384e-05
[2025-08-03 11:13:55] - Epoch 429/500,it:175032, Train Loss: 6.1584e-02, Val Loss: 1.1370e-02, best model: 428, LR: 4.8933e-05, epoch time: 86.46, snr: 1.0903e+01, var(R): 3.5528e-10, var(L*R): 3.4398e-08, WD: 4.7416e-05
[2025-08-03 11:15:21] - Epoch 430/500,it:175440, Train Loss: 6.2699e-02, Val Loss: 1.1917e-02, best model: 428, LR: 4.7586e-05, epoch time: 86.47, snr: 1.0673e+01, var(R): 3.6207e-10, var(L*R): 3.4127e-08, WD: 4.7385e-05
[2025-08-03 11:16:47] - Epoch 431/500,it:175848, Train Loss: 6.1274e-02, Val Loss: 1.1114e-02, best model: 431, LR: 4.6258e-05, epoch time: 86.36, snr: 9.9967e+00, var(R): 3.2512e-10, var(L*R): 3.3465e-08, WD: 4.7446e-05
[2025-08-03 11:18:14] - Epoch 432/500,it:176256, Train Loss: 6.1493e-02, Val Loss: 1.1523e-02, best model: 431, LR: 4.4947e-05, epoch time: 86.53, snr: 1.0716e+01, var(R): 3.6311e-10, var(L*R): 3.4259e-08, WD: 4.7440e-05
[2025-08-03 11:19:40] - Epoch 433/500,it:176664, Train Loss: 6.1801e-02, Val Loss: 1.1446e-02, best model: 431, LR: 4.3654e-05, epoch time: 86.42, snr: 1.0015e+01, var(R): 3.5429e-10, var(L*R): 3.6837e-08, WD: 4.7482e-05
[2025-08-03 11:21:07] - Epoch 434/500,it:177072, Train Loss: 6.1598e-02, Val Loss: 1.1083e-02, best model: 434, LR: 4.2379e-05, epoch time: 86.50, snr: 1.1123e+01, var(R): 3.6393e-10, var(L*R): 3.2161e-08, WD: 4.7449e-05
[2025-08-03 11:22:33] - Epoch 435/500,it:177480, Train Loss: 6.1243e-02, Val Loss: 1.1310e-02, best model: 434, LR: 4.1123e-05, epoch time: 86.37, snr: 1.0590e+01, var(R): 3.6204e-10, var(L*R): 3.4786e-08, WD: 4.7451e-05
[2025-08-03 11:24:00] - Epoch 436/500,it:177888, Train Loss: 6.1898e-02, Val Loss: 1.1103e-02, best model: 434, LR: 3.9884e-05, epoch time: 86.51, snr: 1.1365e+01, var(R): 3.8958e-10, var(L*R): 3.4684e-08, WD: 4.7453e-05
[2025-08-03 11:25:26] - Epoch 437/500,it:178296, Train Loss: 6.0888e-02, Val Loss: 1.1256e-02, best model: 434, LR: 3.8664e-05, epoch time: 86.58, snr: 1.0651e+01, var(R): 3.6136e-10, var(L*R): 3.5368e-08, WD: 4.7485e-05
[2025-08-03 11:26:53] - Epoch 438/500,it:178704, Train Loss: 6.1297e-02, Val Loss: 1.1042e-02, best model: 438, LR: 3.7461e-05, epoch time: 86.54, snr: 1.0746e+01, var(R): 3.8133e-10, var(L*R): 3.2390e-08, WD: 4.7495e-05
[2025-08-03 11:28:19] - Epoch 439/500,it:179112, Train Loss: 6.0781e-02, Val Loss: 1.0907e-02, best model: 439, LR: 3.6277e-05, epoch time: 86.39, snr: 1.0551e+01, var(R): 3.7844e-10, var(L*R): 3.5592e-08, WD: 4.7544e-05
[2025-08-03 11:29:46] - Epoch 440/500,it:179520, Train Loss: 6.0984e-02, Val Loss: 1.1867e-02, best model: 439, LR: 3.5112e-05, epoch time: 86.47, snr: 1.0911e+01, var(R): 3.7970e-10, var(L*R): 3.7624e-08, WD: 4.7557e-05
[2025-08-03 11:31:12] - Epoch 441/500,it:179928, Train Loss: 6.0336e-02, Val Loss: 1.1633e-02, best model: 439, LR: 3.3964e-05, epoch time: 86.46, snr: 9.6645e+00, var(R): 3.7364e-10, var(L*R): 3.7444e-08, WD: 4.7528e-05
[2025-08-03 11:32:39] - Epoch 442/500,it:180336, Train Loss: 6.0761e-02, Val Loss: 1.0896e-02, best model: 442, LR: 3.2836e-05, epoch time: 86.50, snr: 9.6504e+00, var(R): 3.7038e-10, var(L*R): 3.6462e-08, WD: 4.7548e-05
[2025-08-03 11:34:05] - Epoch 443/500,it:180744, Train Loss: 6.0363e-02, Val Loss: 1.1044e-02, best model: 442, LR: 3.1725e-05, epoch time: 86.49, snr: 1.1114e+01, var(R): 3.8918e-10, var(L*R): 3.8470e-08, WD: 4.7582e-05
[2025-08-03 11:35:32] - Epoch 444/500,it:181152, Train Loss: 5.9946e-02, Val Loss: 1.0847e-02, best model: 444, LR: 3.0633e-05, epoch time: 86.52, snr: 1.1566e+01, var(R): 3.9190e-10, var(L*R): 4.0811e-08, WD: 4.7596e-05
[2025-08-03 11:36:58] - Epoch 445/500,it:181560, Train Loss: 5.9897e-02, Val Loss: 1.0886e-02, best model: 444, LR: 2.9560e-05, epoch time: 86.46, snr: 1.1037e+01, var(R): 3.9219e-10, var(L*R): 3.7220e-08, WD: 4.7593e-05
[2025-08-03 11:38:25] - Epoch 446/500,it:181968, Train Loss: 6.0028e-02, Val Loss: 1.0722e-02, best model: 446, LR: 2.8505e-05, epoch time: 86.45, snr: 1.0446e+01, var(R): 3.7366e-10, var(L*R): 3.9182e-08, WD: 4.7614e-05
[2025-08-03 11:39:51] - Epoch 447/500,it:182376, Train Loss: 5.9537e-02, Val Loss: 1.0735e-02, best model: 446, LR: 2.7468e-05, epoch time: 86.48, snr: 1.0942e+01, var(R): 3.9416e-10, var(L*R): 3.9019e-08, WD: 4.7632e-05
[2025-08-03 11:41:18] - Epoch 448/500,it:182784, Train Loss: 5.9590e-02, Val Loss: 1.0734e-02, best model: 446, LR: 2.6451e-05, epoch time: 86.57, snr: 1.0444e+01, var(R): 3.9726e-10, var(L*R): 3.8495e-08, WD: 4.7630e-05
[2025-08-03 11:42:44] - Epoch 449/500,it:183192, Train Loss: 6.0048e-02, Val Loss: 1.0731e-02, best model: 446, LR: 2.5452e-05, epoch time: 86.50, snr: 1.0673e+01, var(R): 4.0007e-10, var(L*R): 3.8128e-08, WD: 4.7636e-05
[2025-08-03 11:44:11] - Epoch 450/500,it:183600, Train Loss: 5.9822e-02, Val Loss: 1.0716e-02, best model: 450, LR: 2.4472e-05, epoch time: 86.41, snr: 9.9649e+00, var(R): 3.9644e-10, var(L*R): 3.7173e-08, WD: 4.7659e-05
[2025-08-03 11:45:37] - Epoch 451/500,it:184008, Train Loss: 5.9579e-02, Val Loss: 1.0742e-02, best model: 450, LR: 2.3510e-05, epoch time: 86.47, snr: 1.0315e+01, var(R): 3.9975e-10, var(L*R): 3.6756e-08, WD: 4.7672e-05
[2025-08-03 11:47:04] - Epoch 452/500,it:184416, Train Loss: 5.9693e-02, Val Loss: 1.0605e-02, best model: 452, LR: 2.2568e-05, epoch time: 86.61, snr: 9.7366e+00, var(R): 3.9473e-10, var(L*R): 3.6523e-08, WD: 4.7697e-05
[2025-08-03 11:48:30] - Epoch 453/500,it:184824, Train Loss: 5.9313e-02, Val Loss: 1.0595e-02, best model: 453, LR: 2.1644e-05, epoch time: 86.54, snr: 1.0309e+01, var(R): 3.9816e-10, var(L*R): 3.6863e-08, WD: 4.7680e-05
[2025-08-03 11:49:57] - Epoch 454/500,it:185232, Train Loss: 6.0131e-02, Val Loss: 1.0725e-02, best model: 453, LR: 2.0739e-05, epoch time: 86.38, snr: 9.6734e+00, var(R): 3.8117e-10, var(L*R): 3.5465e-08, WD: 4.7676e-05
[2025-08-03 11:51:23] - Epoch 455/500,it:185640, Train Loss: 5.9652e-02, Val Loss: 1.0682e-02, best model: 453, LR: 1.9853e-05, epoch time: 86.70, snr: 9.0687e+00, var(R): 3.9163e-10, var(L*R): 3.7239e-08, WD: 4.7706e-05
[2025-08-03 11:52:50] - Epoch 456/500,it:186048, Train Loss: 5.9458e-02, Val Loss: 1.0495e-02, best model: 456, LR: 1.8986e-05, epoch time: 86.57, snr: 9.6503e+00, var(R): 3.9448e-10, var(L*R): 3.9631e-08, WD: 4.7736e-05
[2025-08-03 11:54:16] - Epoch 457/500,it:186456, Train Loss: 5.9521e-02, Val Loss: 1.0568e-02, best model: 456, LR: 1.8138e-05, epoch time: 86.49, snr: 9.6793e+00, var(R): 3.9815e-10, var(L*R): 3.7103e-08, WD: 4.7750e-05
[2025-08-03 11:55:43] - Epoch 458/500,it:186864, Train Loss: 5.9505e-02, Val Loss: 1.0532e-02, best model: 456, LR: 1.7309e-05, epoch time: 86.53, snr: 1.0606e+01, var(R): 4.0337e-10, var(L*R): 3.5775e-08, WD: 4.7766e-05
[2025-08-03 11:57:09] - Epoch 459/500,it:187272, Train Loss: 5.9345e-02, Val Loss: 1.0561e-02, best model: 456, LR: 1.6499e-05, epoch time: 86.53, snr: 9.8292e+00, var(R): 3.9732e-10, var(L*R): 3.6985e-08, WD: 4.7808e-05
[2025-08-03 11:58:36] - Epoch 460/500,it:187680, Train Loss: 5.9694e-02, Val Loss: 1.0390e-02, best model: 460, LR: 1.5708e-05, epoch time: 86.58, snr: 1.0352e+01, var(R): 4.1406e-10, var(L*R): 3.8688e-08, WD: 4.7764e-05
[2025-08-03 12:00:02] - Epoch 461/500,it:188088, Train Loss: 5.9366e-02, Val Loss: 1.0404e-02, best model: 460, LR: 1.4937e-05, epoch time: 86.43, snr: 9.6914e+00, var(R): 4.0393e-10, var(L*R): 3.4978e-08, WD: 4.7791e-05
[2025-08-03 12:01:29] - Epoch 462/500,it:188496, Train Loss: 5.9595e-02, Val Loss: 1.0420e-02, best model: 460, LR: 1.4184e-05, epoch time: 86.44, snr: 9.7916e+00, var(R): 4.0088e-10, var(L*R): 3.5014e-08, WD: 4.7820e-05
[2025-08-03 12:02:55] - Epoch 463/500,it:188904, Train Loss: 5.9249e-02, Val Loss: 1.0410e-02, best model: 460, LR: 1.3451e-05, epoch time: 86.52, snr: 9.2204e+00, var(R): 4.0649e-10, var(L*R): 3.4699e-08, WD: 4.7825e-05
[2025-08-03 12:04:22] - Epoch 464/500,it:189312, Train Loss: 5.9322e-02, Val Loss: 1.0731e-02, best model: 460, LR: 1.2737e-05, epoch time: 86.49, snr: 9.5604e+00, var(R): 4.0496e-10, var(L*R): 3.3874e-08, WD: 4.7852e-05
[2025-08-03 12:05:49] - Epoch 465/500,it:189720, Train Loss: 5.9638e-02, Val Loss: 1.0341e-02, best model: 465, LR: 1.2042e-05, epoch time: 86.58, snr: 8.7302e+00, var(R): 4.0293e-10, var(L*R): 3.4873e-08, WD: 4.7870e-05
[2025-08-03 12:07:15] - Epoch 466/500,it:190128, Train Loss: 5.9594e-02, Val Loss: 1.0321e-02, best model: 466, LR: 1.1366e-05, epoch time: 86.49, snr: 9.5944e+00, var(R): 4.0491e-10, var(L*R): 3.5205e-08, WD: 4.7893e-05
[2025-08-03 12:08:41] - Epoch 467/500,it:190536, Train Loss: 5.9848e-02, Val Loss: 1.0466e-02, best model: 466, LR: 1.0710e-05, epoch time: 86.45, snr: 9.6778e+00, var(R): 4.0004e-10, var(L*R): 3.6271e-08, WD: 4.7892e-05
[2025-08-03 12:10:08] - Epoch 468/500,it:190944, Train Loss: 5.9688e-02, Val Loss: 1.0298e-02, best model: 468, LR: 1.0072e-05, epoch time: 86.57, snr: 9.1831e+00, var(R): 4.1088e-10, var(L*R): 3.3853e-08, WD: 4.7900e-05
[2025-08-03 12:11:34] - Epoch 469/500,it:191352, Train Loss: 6.0015e-02, Val Loss: 1.0391e-02, best model: 468, LR: 9.4547e-06, epoch time: 86.45, snr: 9.8452e+00, var(R): 4.1687e-10, var(L*R): 3.6604e-08, WD: 4.7944e-05
[2025-08-03 12:13:01] - Epoch 470/500,it:191760, Train Loss: 5.9807e-02, Val Loss: 1.0278e-02, best model: 470, LR: 8.8564e-06, epoch time: 86.53, snr: 1.0102e+01, var(R): 4.1316e-10, var(L*R): 3.4089e-08, WD: 4.7972e-05
[2025-08-03 12:14:28] - Epoch 471/500,it:192168, Train Loss: 5.9798e-02, Val Loss: 1.0287e-02, best model: 470, LR: 8.2774e-06, epoch time: 86.61, snr: 9.8523e+00, var(R): 4.1951e-10, var(L*R): 3.6022e-08, WD: 4.7985e-05
[2025-08-03 12:15:54] - Epoch 472/500,it:192576, Train Loss: 6.0085e-02, Val Loss: 1.0249e-02, best model: 472, LR: 7.7178e-06, epoch time: 86.70, snr: 1.0073e+01, var(R): 4.2130e-10, var(L*R): 3.4807e-08, WD: 4.8002e-05
[2025-08-03 12:17:21] - Epoch 473/500,it:192984, Train Loss: 6.0018e-02, Val Loss: 1.0208e-02, best model: 473, LR: 7.1777e-06, epoch time: 86.40, snr: 9.9355e+00, var(R): 4.1997e-10, var(L*R): 3.5147e-08, WD: 4.8051e-05
[2025-08-03 12:18:47] - Epoch 474/500,it:193392, Train Loss: 6.0407e-02, Val Loss: 1.0276e-02, best model: 473, LR: 6.6570e-06, epoch time: 86.64, snr: 9.8243e+00, var(R): 4.1745e-10, var(L*R): 3.5337e-08, WD: 4.8026e-05
[2025-08-03 12:20:14] - Epoch 475/500,it:193800, Train Loss: 6.0108e-02, Val Loss: 1.0193e-02, best model: 475, LR: 6.1558e-06, epoch time: 86.51, snr: 9.6513e+00, var(R): 4.1701e-10, var(L*R): 3.6121e-08, WD: 4.8089e-05
[2025-08-03 12:21:40] - Epoch 476/500,it:194208, Train Loss: 6.0375e-02, Val Loss: 1.0184e-02, best model: 476, LR: 5.6741e-06, epoch time: 86.51, snr: 9.8904e+00, var(R): 4.2136e-10, var(L*R): 3.4356e-08, WD: 4.8096e-05
[2025-08-03 12:23:07] - Epoch 477/500,it:194616, Train Loss: 6.0483e-02, Val Loss: 1.0251e-02, best model: 476, LR: 5.2119e-06, epoch time: 86.50, snr: 9.8340e+00, var(R): 4.2386e-10, var(L*R): 3.6403e-08, WD: 4.8117e-05
[2025-08-03 12:24:34] - Epoch 478/500,it:195024, Train Loss: 6.0798e-02, Val Loss: 1.0316e-02, best model: 476, LR: 4.7693e-06, epoch time: 86.63, snr: 1.0092e+01, var(R): 4.2493e-10, var(L*R): 3.5994e-08, WD: 4.8128e-05
[2025-08-03 12:26:00] - Epoch 479/500,it:195432, Train Loss: 6.0396e-02, Val Loss: 1.0175e-02, best model: 479, LR: 4.3462e-06, epoch time: 86.77, snr: 1.0123e+01, var(R): 4.3066e-10, var(L*R): 3.6202e-08, WD: 4.8167e-05
[2025-08-03 12:27:27] - Epoch 480/500,it:195840, Train Loss: 6.0576e-02, Val Loss: 1.0145e-02, best model: 480, LR: 3.9426e-06, epoch time: 86.70, snr: 9.8777e+00, var(R): 4.2734e-10, var(L*R): 3.4747e-08, WD: 4.8170e-05
[2025-08-03 12:28:54] - Epoch 481/500,it:196248, Train Loss: 6.0500e-02, Val Loss: 1.0183e-02, best model: 480, LR: 3.5587e-06, epoch time: 86.49, snr: 9.6610e+00, var(R): 4.1973e-10, var(L*R): 3.3587e-08, WD: 4.8217e-05
[2025-08-03 12:30:20] - Epoch 482/500,it:196656, Train Loss: 6.0645e-02, Val Loss: 1.0172e-02, best model: 480, LR: 3.1943e-06, epoch time: 86.62, snr: 9.9943e+00, var(R): 4.2416e-10, var(L*R): 3.4067e-08, WD: 4.8247e-05
[2025-08-03 12:31:47] - Epoch 483/500,it:197064, Train Loss: 6.0557e-02, Val Loss: 1.0128e-02, best model: 483, LR: 2.8496e-06, epoch time: 86.56, snr: 9.4469e+00, var(R): 4.2033e-10, var(L*R): 3.4271e-08, WD: 4.8257e-05
[2025-08-03 12:33:13] - Epoch 484/500,it:197472, Train Loss: 6.0764e-02, Val Loss: 1.0112e-02, best model: 484, LR: 2.5245e-06, epoch time: 86.46, snr: 9.6886e+00, var(R): 4.2765e-10, var(L*R): 3.3248e-08, WD: 4.8308e-05
[2025-08-03 12:34:40] - Epoch 485/500,it:197880, Train Loss: 6.1028e-02, Val Loss: 1.0149e-02, best model: 484, LR: 2.2190e-06, epoch time: 86.56, snr: 9.8583e+00, var(R): 4.2679e-10, var(L*R): 3.3535e-08, WD: 4.8327e-05
[2025-08-03 12:36:06] - Epoch 486/500,it:198288, Train Loss: 6.1167e-02, Val Loss: 1.0111e-02, best model: 486, LR: 1.9332e-06, epoch time: 86.59, snr: 9.6203e+00, var(R): 4.2706e-10, var(L*R): 3.3605e-08, WD: 4.8325e-05
[2025-08-03 12:37:33] - Epoch 487/500,it:198696, Train Loss: 6.1359e-02, Val Loss: 1.0105e-02, best model: 487, LR: 1.6670e-06, epoch time: 86.65, snr: 9.7648e+00, var(R): 4.2607e-10, var(L*R): 3.3891e-08, WD: 4.8354e-05
[2025-08-03 12:39:00] - Epoch 488/500,it:199104, Train Loss: 6.1400e-02, Val Loss: 1.0094e-02, best model: 488, LR: 1.4205e-06, epoch time: 86.54, snr: 9.8713e+00, var(R): 4.2613e-10, var(L*R): 3.5010e-08, WD: 4.8368e-05
[2025-08-03 12:40:26] - Epoch 489/500,it:199512, Train Loss: 6.1475e-02, Val Loss: 1.0088e-02, best model: 489, LR: 1.1937e-06, epoch time: 86.69, snr: 9.7627e+00, var(R): 4.2694e-10, var(L*R): 3.4869e-08, WD: 4.8429e-05
[2025-08-03 12:41:53] - Epoch 490/500,it:199920, Train Loss: 6.1923e-02, Val Loss: 1.0082e-02, best model: 490, LR: 9.8664e-07, epoch time: 86.80, snr: 9.7370e+00, var(R): 4.2722e-10, var(L*R): 3.4022e-08, WD: 4.8437e-05
[2025-08-03 12:43:20] - Epoch 491/500,it:200328, Train Loss: 6.1578e-02, Val Loss: 1.0083e-02, best model: 490, LR: 7.9922e-07, epoch time: 86.48, snr: 9.5973e+00, var(R): 4.2644e-10, var(L*R): 3.4119e-08, WD: 4.8473e-05
[2025-08-03 12:44:46] - Epoch 492/500,it:200736, Train Loss: 6.1883e-02, Val Loss: 1.0074e-02, best model: 492, LR: 6.3152e-07, epoch time: 86.47, snr: 9.6690e+00, var(R): 4.2411e-10, var(L*R): 3.4432e-08, WD: 4.8507e-05
[2025-08-03 12:46:13] - Epoch 493/500,it:201144, Train Loss: 6.2077e-02, Val Loss: 1.0074e-02, best model: 492, LR: 4.8353e-07, epoch time: 86.59, snr: 9.7644e+00, var(R): 4.2609e-10, var(L*R): 3.4735e-08, WD: 4.8513e-05
[2025-08-03 12:47:39] - Epoch 494/500,it:201552, Train Loss: 6.2347e-02, Val Loss: 1.0065e-02, best model: 494, LR: 3.5526e-07, epoch time: 86.57, snr: 9.7093e+00, var(R): 4.2713e-10, var(L*R): 3.4743e-08, WD: 4.8551e-05
[2025-08-03 12:49:06] - Epoch 495/500,it:201960, Train Loss: 6.2190e-02, Val Loss: 1.0068e-02, best model: 494, LR: 2.4672e-07, epoch time: 86.50, snr: 9.7016e+00, var(R): 4.2732e-10, var(L*R): 3.4859e-08, WD: 4.8594e-05
[2025-08-03 12:50:32] - Epoch 496/500,it:202368, Train Loss: 6.2376e-02, Val Loss: 1.0052e-02, best model: 496, LR: 1.5791e-07, epoch time: 86.55, snr: 9.5787e+00, var(R): 4.2769e-10, var(L*R): 3.4662e-08, WD: 4.8629e-05
[2025-08-03 12:51:59] - Epoch 497/500,it:202776, Train Loss: 6.2495e-02, Val Loss: 1.0053e-02, best model: 496, LR: 8.8824e-08, epoch time: 86.50, snr: 9.6616e+00, var(R): 4.2735e-10, var(L*R): 3.4677e-08, WD: 4.8666e-05
[2025-08-03 12:53:25] - Epoch 498/500,it:203184, Train Loss: 6.2753e-02, Val Loss: 1.0063e-02, best model: 496, LR: 3.9478e-08, epoch time: 86.64, snr: 9.6371e+00, var(R): 4.2833e-10, var(L*R): 3.4485e-08, WD: 4.8673e-05
[2025-08-03 12:54:52] - Epoch 499/500,it:203592, Train Loss: 6.2556e-02, Val Loss: 1.0054e-02, best model: 496, LR: 9.8696e-09, epoch time: 86.49, snr: 9.6459e+00, var(R): 4.2637e-10, var(L*R): 3.4236e-08, WD: 4.8736e-05
[2025-08-03 12:56:18] - Epoch 500/500,it:204000, Train Loss: 6.3003e-02, Val Loss: 1.0053e-02, best model: 496, LR: 0.0000e+00, epoch time: 86.56, snr: 9.6733e+00, var(R): 4.2623e-10, var(L*R): 3.4251e-08, WD: 4.8751e-05
Training finished.
Test Loss: 1.0149e-02
