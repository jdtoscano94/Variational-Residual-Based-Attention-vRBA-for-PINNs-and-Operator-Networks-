## SLURM PROLOG ###############################################################
##    Job ID : 12241788
##  Job Name : vrba_sample
##  Nodelist : gpu2108
##      CPUs : 1
##  Mem/Node : 65536 MB
## Directory : /oscar/data/gk/jdtoscan
##   Job Started : Sun Aug  3 00:52:42 EDT 2025
###############################################################################
Sun Aug  3 00:52:42 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:81:00.0 Off |                  N/A |
| 30%   29C    P8              29W / 350W |     42MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     45822      G   /usr/libexec/Xorg                            33MiB |
+---------------------------------------------------------------------------------------+
Using device: cuda

Train Dataset
x:  (40800, 1, 64, 64)
y:  (40800, 1, 64, 64)
t:  (40800,)


Validation Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)


Test Dataset
x:  (5100, 1, 64, 64)
y:  (5100, 1, 64, 64)
t:  (5100,)

Lambda:  (40800, 1, 64, 64)
Par: 
 {'nx': 64, 'ny': 64, 'nf': 1, 'd_emb': 128, 'lb': 1, 'lf': 51, 'num_epochs': 500, 'inp_shift': np.float64(0.007669870189599345), 'inp_scale': np.float64(0.061450183570653995), 'out_shift': np.float64(-0.001635048307912137), 'out_scale': np.float64(0.03807830166415873), 't_shift': np.float64(0.0), 't_scale': np.float64(1.0), 'eta': 0.1, 'gamma': 0.99, 'do_rba': True, 'get_snr': True, 'Lambda_max': 9.999999999999991}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
Unet2D                                                  [1, 1, 64, 64]            --
├─Conv2d: 1-1                                           [1, 16, 64, 64]           2,368
├─Sequential: 1-2                                       [1, 64]                   --
│    └─SinusoidalPosEmb: 2-1                            [1, 16]                   --
│    └─Linear: 2-2                                      [1, 64]                   1,088
│    └─GELU: 2-3                                        [1, 64]                   --
│    └─Linear: 2-4                                      [1, 64]                   4,160
├─ModuleList: 1-3                                       --                        --
│    └─ModuleList: 2-5                                  --                        --
│    │    └─ResnetBlock: 3-1                            [1, 16, 64, 64]           6,784
│    │    └─ResnetBlock: 3-2                            [1, 16, 64, 64]           6,784
│    │    └─Residual: 3-3                               [1, 16, 64, 64]           8,240
│    │    └─Sequential: 3-4                             [1, 16, 32, 32]           1,040
│    └─ModuleList: 2-6                                  --                        --
│    │    └─ResnetBlock: 3-5                            [1, 16, 32, 32]           6,784
│    │    └─ResnetBlock: 3-6                            [1, 16, 32, 32]           6,784
│    │    └─Residual: 3-7                               [1, 16, 32, 32]           8,240
│    │    └─Sequential: 3-8                             [1, 32, 16, 16]           2,080
│    └─ModuleList: 2-7                                  --                        --
│    │    └─ResnetBlock: 3-9                            [1, 32, 16, 16]           22,784
│    │    └─ResnetBlock: 3-10                           [1, 32, 16, 16]           22,784
│    │    └─Residual: 3-11                              [1, 32, 16, 16]           16,480
│    │    └─Sequential: 3-12                            [1, 64, 8, 8]             8,256
│    └─ModuleList: 2-8                                  --                        --
│    │    └─ResnetBlock: 3-13                           [1, 64, 8, 8]             82,432
│    │    └─ResnetBlock: 3-14                           [1, 64, 8, 8]             82,432
│    │    └─Residual: 3-15                              [1, 64, 8, 8]             32,960
│    │    └─Conv2d: 3-16                                [1, 128, 8, 8]            73,856
├─ResnetBlock: 1-4                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-9                                  [1, 256]                  --
│    │    └─SiLU: 3-17                                  [1, 64]                   --
│    │    └─Linear: 3-18                                [1, 256]                  16,640
│    └─Block: 2-10                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-19                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-20                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-21                                  [1, 128, 8, 8]            --
│    └─Block: 2-11                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-22                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-23                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-24                                  [1, 128, 8, 8]            --
│    └─Identity: 2-12                                   [1, 128, 8, 8]            --
├─Residual: 1-5                                         [1, 128, 8, 8]            --
│    └─PreNorm: 2-13                                    [1, 128, 8, 8]            --
│    │    └─LayerNorm: 3-25                             [1, 128, 8, 8]            128
│    │    └─Attention: 3-26                             [1, 128, 8, 8]            65,664
├─ResnetBlock: 1-6                                      [1, 128, 8, 8]            --
│    └─Sequential: 2-14                                 [1, 256]                  --
│    │    └─SiLU: 3-27                                  [1, 64]                   --
│    │    └─Linear: 3-28                                [1, 256]                  16,640
│    └─Block: 2-15                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-29                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-30                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-31                                  [1, 128, 8, 8]            --
│    └─Block: 2-16                                      [1, 128, 8, 8]            --
│    │    └─Conv2d: 3-32                                [1, 128, 8, 8]            147,584
│    │    └─GroupNorm: 3-33                             [1, 128, 8, 8]            256
│    │    └─SiLU: 3-34                                  [1, 128, 8, 8]            --
│    └─Identity: 2-17                                   [1, 128, 8, 8]            --
├─ModuleList: 1-7                                       --                        --
│    └─ModuleList: 2-18                                 --                        --
│    │    └─ResnetBlock: 3-35                           [1, 128, 8, 8]            410,752
│    │    └─ResnetBlock: 3-36                           [1, 128, 8, 8]            410,752
│    │    └─Residual: 3-37                              [1, 128, 8, 8]            65,920
│    │    └─Sequential: 3-38                            [1, 64, 16, 16]           73,792
│    └─ModuleList: 2-19                                 --                        --
│    │    └─ResnetBlock: 3-39                           [1, 64, 16, 16]           107,072
│    │    └─ResnetBlock: 3-40                           [1, 64, 16, 16]           107,072
│    │    └─Residual: 3-41                              [1, 64, 16, 16]           32,960
│    │    └─Sequential: 3-42                            [1, 32, 32, 32]           18,464
│    └─ModuleList: 2-20                                 --                        --
│    │    └─ResnetBlock: 3-43                           [1, 32, 32, 32]           28,960
│    │    └─ResnetBlock: 3-44                           [1, 32, 32, 32]           28,960
│    │    └─Residual: 3-45                              [1, 32, 32, 32]           16,480
│    │    └─Sequential: 3-46                            [1, 16, 64, 64]           4,624
│    └─ModuleList: 2-21                                 --                        --
│    │    └─ResnetBlock: 3-47                           [1, 16, 64, 64]           9,616
│    │    └─ResnetBlock: 3-48                           [1, 16, 64, 64]           9,616
│    │    └─Residual: 3-49                              [1, 16, 64, 64]           8,240
│    │    └─Conv2d: 3-50                                [1, 16, 64, 64]           2,320
├─ResnetBlock: 1-8                                      [1, 16, 64, 64]           --
│    └─Sequential: 2-22                                 [1, 32]                   --
│    │    └─SiLU: 3-51                                  [1, 64]                   --
│    │    └─Linear: 3-52                                [1, 32]                   2,080
│    └─Block: 2-23                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-53                                [1, 16, 64, 64]           4,624
│    │    └─GroupNorm: 3-54                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-55                                  [1, 16, 64, 64]           --
│    └─Block: 2-24                                      [1, 16, 64, 64]           --
│    │    └─Conv2d: 3-56                                [1, 16, 64, 64]           2,320
│    │    └─GroupNorm: 3-57                             [1, 16, 64, 64]           32
│    │    └─SiLU: 3-58                                  [1, 16, 64, 64]           --
│    └─Conv2d: 2-25                                     [1, 16, 64, 64]           528
├─Conv2d: 1-9                                           [1, 1, 64, 64]            17
=========================================================================================================
Total params: 2,432,001
Trainable params: 2,432,001
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 545.94
=========================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 60.28
Params size (MB): 9.73
Estimated Total Size (MB): 70.02
=========================================================================================================
[2025-08-03 00:54:17] - Epoch 1/500,it:408, Train Loss: 4.3913e+00, Val Loss: 7.8113e-01, best model: 1, LR: 9.9999e-04, epoch time: 84.66, snr: 4.5539e+00, var(R): 5.9177e-05, var(L*R): 5.9177e-05, WD: 0.0000e+00
[2025-08-03 00:55:41] - Epoch 2/500,it:816, Train Loss: 2.9437e+00, Val Loss: 3.6962e-01, best model: 2, LR: 9.9996e-04, epoch time: 84.16, snr: 8.6586e-01, var(R): 4.4553e-06, var(L*R): 4.5328e-06, WD: 3.3816e-07
[2025-08-03 00:57:05] - Epoch 3/500,it:1224, Train Loss: 1.5828e+00, Val Loss: 2.3264e-01, best model: 3, LR: 9.9991e-04, epoch time: 84.32, snr: 2.2357e+00, var(R): 4.8976e-07, var(L*R): 5.0166e-07, WD: 4.9499e-07
[2025-08-03 00:58:29] - Epoch 4/500,it:1632, Train Loss: 1.0836e+00, Val Loss: 1.6676e-01, best model: 4, LR: 9.9984e-04, epoch time: 84.34, snr: 5.7938e+00, var(R): 8.0104e-08, var(L*R): 8.2674e-08, WD: 6.0706e-07
[2025-08-03 00:59:54] - Epoch 5/500,it:2040, Train Loss: 9.4242e-01, Val Loss: 1.8442e-01, best model: 4, LR: 9.9975e-04, epoch time: 84.34, snr: 1.5543e+00, var(R): 2.2269e-08, var(L*R): 2.3102e-08, WD: 6.9994e-07
[2025-08-03 01:01:18] - Epoch 6/500,it:2448, Train Loss: 8.1437e-01, Val Loss: 1.3285e-01, best model: 6, LR: 9.9964e-04, epoch time: 84.43, snr: 3.0396e+00, var(R): 2.7113e-08, var(L*R): 2.7767e-08, WD: 7.7453e-07
[2025-08-03 01:02:42] - Epoch 7/500,it:2856, Train Loss: 7.3753e-01, Val Loss: 1.6698e-01, best model: 6, LR: 9.9952e-04, epoch time: 84.24, snr: 4.4820e+00, var(R): 8.2861e-09, var(L*R): 8.6176e-09, WD: 8.3860e-07
[2025-08-03 01:04:07] - Epoch 8/500,it:3264, Train Loss: 6.9783e-01, Val Loss: 1.4483e-01, best model: 6, LR: 9.9937e-04, epoch time: 84.39, snr: 2.7056e+00, var(R): 3.3782e-08, var(L*R): 3.5768e-08, WD: 8.9638e-07
[2025-08-03 01:05:31] - Epoch 9/500,it:3672, Train Loss: 7.2265e-01, Val Loss: 1.4978e-01, best model: 6, LR: 9.9920e-04, epoch time: 84.41, snr: 1.2522e+01, var(R): 1.4338e-08, var(L*R): 1.5523e-08, WD: 9.4709e-07
[2025-08-03 01:06:56] - Epoch 10/500,it:4080, Train Loss: 6.1490e-01, Val Loss: 1.2691e-01, best model: 10, LR: 9.9901e-04, epoch time: 84.50, snr: 1.2711e+01, var(R): 4.0287e-08, var(L*R): 4.6634e-08, WD: 9.8624e-07
[2025-08-03 01:08:20] - Epoch 11/500,it:4488, Train Loss: 6.5673e-01, Val Loss: 1.9142e-01, best model: 10, LR: 9.9881e-04, epoch time: 84.31, snr: 9.4411e+00, var(R): 5.6880e-09, var(L*R): 5.9673e-09, WD: 1.0261e-06
[2025-08-03 01:09:44] - Epoch 12/500,it:4896, Train Loss: 6.9500e-01, Val Loss: 1.5337e-01, best model: 10, LR: 9.9858e-04, epoch time: 84.49, snr: 1.2806e+01, var(R): 3.4578e-08, var(L*R): 3.5816e-08, WD: 1.0589e-06
[2025-08-03 01:11:09] - Epoch 13/500,it:5304, Train Loss: 5.4831e-01, Val Loss: 1.4264e-01, best model: 10, LR: 9.9833e-04, epoch time: 84.44, snr: 1.5069e+01, var(R): 1.2793e-08, var(L*R): 1.3727e-08, WD: 1.0919e-06
[2025-08-03 01:12:33] - Epoch 14/500,it:5712, Train Loss: 5.6128e-01, Val Loss: 1.2387e-01, best model: 14, LR: 9.9807e-04, epoch time: 84.33, snr: 1.4514e+01, var(R): 2.1214e-08, var(L*R): 2.4802e-08, WD: 1.1229e-06
[2025-08-03 01:13:58] - Epoch 15/500,it:6120, Train Loss: 5.9959e-01, Val Loss: 8.3303e-02, best model: 15, LR: 9.9778e-04, epoch time: 84.33, snr: 1.2840e+01, var(R): 5.8736e-09, var(L*R): 6.1150e-09, WD: 1.1469e-06
[2025-08-03 01:15:22] - Epoch 16/500,it:6528, Train Loss: 6.2184e-01, Val Loss: 1.1461e-01, best model: 15, LR: 9.9748e-04, epoch time: 84.37, snr: 7.6683e-01, var(R): 1.2720e-09, var(L*R): 1.4023e-09, WD: 1.1701e-06
[2025-08-03 01:16:46] - Epoch 17/500,it:6936, Train Loss: 5.7399e-01, Val Loss: 8.7580e-02, best model: 15, LR: 9.9715e-04, epoch time: 84.36, snr: 1.1201e+01, var(R): 5.1313e-09, var(L*R): 5.5357e-09, WD: 1.1910e-06
[2025-08-03 01:18:11] - Epoch 18/500,it:7344, Train Loss: 5.4806e-01, Val Loss: 1.0157e-01, best model: 15, LR: 9.9681e-04, epoch time: 84.28, snr: 1.5384e+01, var(R): 1.5785e-09, var(L*R): 1.8175e-09, WD: 1.2101e-06
[2025-08-03 01:19:35] - Epoch 19/500,it:7752, Train Loss: 4.6315e-01, Val Loss: 8.1472e-02, best model: 19, LR: 9.9644e-04, epoch time: 84.35, snr: 1.3093e+01, var(R): 4.2545e-09, var(L*R): 5.1320e-09, WD: 1.2299e-06
[2025-08-03 01:20:59] - Epoch 20/500,it:8160, Train Loss: 4.6564e-01, Val Loss: 1.5301e-01, best model: 19, LR: 9.9606e-04, epoch time: 84.31, snr: 3.3840e+00, var(R): 1.0426e-09, var(L*R): 1.1405e-09, WD: 1.2464e-06
[2025-08-03 01:22:24] - Epoch 21/500,it:8568, Train Loss: 5.7855e-01, Val Loss: 1.5658e-01, best model: 19, LR: 9.9565e-04, epoch time: 84.49, snr: 1.6163e+01, var(R): 1.2660e-08, var(L*R): 1.4303e-08, WD: 1.2617e-06
[2025-08-03 01:23:48] - Epoch 22/500,it:8976, Train Loss: 4.5688e-01, Val Loss: 6.8962e-02, best model: 22, LR: 9.9523e-04, epoch time: 84.16, snr: 1.6565e+01, var(R): 1.5278e-08, var(L*R): 1.7176e-08, WD: 1.2763e-06
[2025-08-03 01:25:12] - Epoch 23/500,it:9384, Train Loss: 5.5200e-01, Val Loss: 8.4046e-02, best model: 22, LR: 9.9479e-04, epoch time: 84.46, snr: 7.5190e+00, var(R): 6.2672e-10, var(L*R): 7.1953e-10, WD: 1.2880e-06
[2025-08-03 01:26:37] - Epoch 24/500,it:9792, Train Loss: 4.4505e-01, Val Loss: 8.6762e-02, best model: 22, LR: 9.9433e-04, epoch time: 84.53, snr: 1.2623e+01, var(R): 1.3931e-09, var(L*R): 1.5363e-09, WD: 1.3026e-06
[2025-08-03 01:28:01] - Epoch 25/500,it:10200, Train Loss: 4.7473e-01, Val Loss: 8.6946e-02, best model: 22, LR: 9.9384e-04, epoch time: 84.37, snr: 1.2809e+00, var(R): 3.1734e-09, var(L*R): 4.4194e-09, WD: 1.3144e-06
[2025-08-03 01:29:26] - Epoch 26/500,it:10608, Train Loss: 4.4313e-01, Val Loss: 1.7020e-01, best model: 22, LR: 9.9334e-04, epoch time: 84.36, snr: 3.7529e+00, var(R): 1.7505e-09, var(L*R): 2.0075e-09, WD: 1.3230e-06
[2025-08-03 01:30:50] - Epoch 27/500,it:11016, Train Loss: 5.1085e-01, Val Loss: 1.1903e-01, best model: 22, LR: 9.9282e-04, epoch time: 84.45, snr: 2.0193e+01, var(R): 4.3168e-08, var(L*R): 6.2771e-08, WD: 1.3383e-06
[2025-08-03 01:32:14] - Epoch 28/500,it:11424, Train Loss: 3.9854e-01, Val Loss: 6.4157e-02, best model: 28, LR: 9.9228e-04, epoch time: 84.27, snr: 1.7381e+01, var(R): 5.8742e-09, var(L*R): 7.2076e-09, WD: 1.3462e-06
[2025-08-03 01:33:39] - Epoch 29/500,it:11832, Train Loss: 5.4003e-01, Val Loss: 6.7202e-02, best model: 28, LR: 9.9172e-04, epoch time: 84.28, snr: 9.1084e+00, var(R): 5.3759e-10, var(L*R): 6.8755e-10, WD: 1.3547e-06
[2025-08-03 01:35:03] - Epoch 30/500,it:12240, Train Loss: 4.0370e-01, Val Loss: 8.8245e-02, best model: 28, LR: 9.9114e-04, epoch time: 84.38, snr: 1.3651e+01, var(R): 4.7198e-10, var(L*R): 5.6649e-10, WD: 1.3637e-06
[2025-08-03 01:36:27] - Epoch 31/500,it:12648, Train Loss: 4.1794e-01, Val Loss: 6.6828e-02, best model: 28, LR: 9.9055e-04, epoch time: 84.22, snr: 1.5949e+01, var(R): 3.4777e-09, var(L*R): 4.6621e-09, WD: 1.3725e-06
[2025-08-03 01:37:51] - Epoch 32/500,it:13056, Train Loss: 4.2714e-01, Val Loss: 1.4733e-01, best model: 28, LR: 9.8993e-04, epoch time: 84.25, snr: 1.2202e+01, var(R): 7.3481e-10, var(L*R): 9.8708e-10, WD: 1.3784e-06
[2025-08-03 01:39:16] - Epoch 33/500,it:13464, Train Loss: 4.4631e-01, Val Loss: 7.2451e-02, best model: 28, LR: 9.8929e-04, epoch time: 84.54, snr: 1.6319e+01, var(R): 1.2906e-08, var(L*R): 1.6245e-08, WD: 1.3823e-06
[2025-08-03 01:40:40] - Epoch 34/500,it:13872, Train Loss: 3.6252e-01, Val Loss: 6.7971e-02, best model: 28, LR: 9.8863e-04, epoch time: 84.27, snr: 1.9441e+00, var(R): 7.7409e-10, var(L*R): 8.7079e-10, WD: 1.3865e-06
[2025-08-03 01:42:05] - Epoch 35/500,it:14280, Train Loss: 4.4461e-01, Val Loss: 1.4293e-01, best model: 28, LR: 9.8796e-04, epoch time: 84.38, snr: 9.8087e+00, var(R): 5.2108e-10, var(L*R): 6.1352e-10, WD: 1.3935e-06
[2025-08-03 01:43:29] - Epoch 36/500,it:14688, Train Loss: 4.5790e-01, Val Loss: 7.0983e-02, best model: 28, LR: 9.8726e-04, epoch time: 84.51, snr: 1.8352e+01, var(R): 7.5810e-09, var(L*R): 8.7504e-09, WD: 1.3968e-06
[2025-08-03 01:44:53] - Epoch 37/500,it:15096, Train Loss: 3.4247e-01, Val Loss: 1.7443e-01, best model: 28, LR: 9.8655e-04, epoch time: 84.09, snr: 1.1477e+01, var(R): 6.5711e-10, var(L*R): 7.4853e-10, WD: 1.4049e-06
[2025-08-03 01:46:17] - Epoch 38/500,it:15504, Train Loss: 4.0534e-01, Val Loss: 7.0469e-02, best model: 28, LR: 9.8582e-04, epoch time: 84.16, snr: 2.1659e+01, var(R): 2.1415e-08, var(L*R): 2.7625e-08, WD: 1.4092e-06
[2025-08-03 01:47:42] - Epoch 39/500,it:15912, Train Loss: 3.4360e-01, Val Loss: 7.5838e-02, best model: 28, LR: 9.8506e-04, epoch time: 84.35, snr: 7.7915e+00, var(R): 7.3784e-10, var(L*R): 9.1935e-10, WD: 1.4150e-06
[2025-08-03 01:49:06] - Epoch 40/500,it:16320, Train Loss: 4.5125e-01, Val Loss: 1.1591e-01, best model: 28, LR: 9.8429e-04, epoch time: 84.41, snr: 1.5006e+01, var(R): 8.9148e-10, var(L*R): 1.1847e-09, WD: 1.4174e-06
[2025-08-03 01:50:30] - Epoch 41/500,it:16728, Train Loss: 3.1233e-01, Val Loss: 9.2298e-02, best model: 28, LR: 9.8350e-04, epoch time: 84.16, snr: 1.6158e+01, var(R): 4.2030e-09, var(L*R): 5.0573e-09, WD: 1.4229e-06
[2025-08-03 01:51:55] - Epoch 42/500,it:17136, Train Loss: 3.5307e-01, Val Loss: 1.0711e-01, best model: 28, LR: 9.8269e-04, epoch time: 84.34, snr: 1.8384e+01, var(R): 1.6434e-09, var(L*R): 1.8882e-09, WD: 1.4260e-06
[2025-08-03 01:53:19] - Epoch 43/500,it:17544, Train Loss: 3.6100e-01, Val Loss: 7.1470e-02, best model: 28, LR: 9.8186e-04, epoch time: 84.27, snr: 2.0805e+01, var(R): 3.1042e-09, var(L*R): 4.0458e-09, WD: 1.4261e-06
[2025-08-03 01:54:44] - Epoch 44/500,it:17952, Train Loss: 3.4400e-01, Val Loss: 6.7253e-02, best model: 28, LR: 9.8101e-04, epoch time: 84.56, snr: 1.4717e+01, var(R): 9.5315e-10, var(L*R): 1.4075e-09, WD: 1.4306e-06
[2025-08-03 01:56:08] - Epoch 45/500,it:18360, Train Loss: 3.8006e-01, Val Loss: 6.0517e-02, best model: 45, LR: 9.8015e-04, epoch time: 84.26, snr: 8.4891e-01, var(R): 4.8233e-10, var(L*R): 5.7555e-10, WD: 1.4321e-06
[2025-08-03 01:57:32] - Epoch 46/500,it:18768, Train Loss: 4.0965e-01, Val Loss: 7.1835e-02, best model: 45, LR: 9.7926e-04, epoch time: 84.26, snr: 2.1922e+00, var(R): 4.6465e-10, var(L*R): 6.1584e-10, WD: 1.4354e-06
[2025-08-03 01:58:56] - Epoch 47/500,it:19176, Train Loss: 4.3308e-01, Val Loss: 1.1555e-01, best model: 45, LR: 9.7836e-04, epoch time: 84.25, snr: 3.7015e+00, var(R): 8.3009e-10, var(L*R): 1.1157e-09, WD: 1.4405e-06
[2025-08-03 02:00:21] - Epoch 48/500,it:19584, Train Loss: 3.4508e-01, Val Loss: 6.8586e-02, best model: 45, LR: 9.7743e-04, epoch time: 84.22, snr: 1.8800e+01, var(R): 3.4054e-09, var(L*R): 4.3300e-09, WD: 1.4425e-06
[2025-08-03 02:01:45] - Epoch 49/500,it:19992, Train Loss: 3.0271e-01, Val Loss: 6.5251e-02, best model: 45, LR: 9.7649e-04, epoch time: 84.22, snr: 8.5508e-01, var(R): 7.0787e-10, var(L*R): 9.8064e-10, WD: 1.4475e-06
[2025-08-03 02:03:09] - Epoch 50/500,it:20400, Train Loss: 2.9686e-01, Val Loss: 6.8312e-02, best model: 45, LR: 9.7553e-04, epoch time: 84.16, snr: 3.6836e+00, var(R): 5.8638e-10, var(L*R): 7.1560e-10, WD: 1.4474e-06
[2025-08-03 02:04:33] - Epoch 51/500,it:20808, Train Loss: 3.1518e-01, Val Loss: 6.0049e-02, best model: 51, LR: 9.7455e-04, epoch time: 84.20, snr: 1.8661e+01, var(R): 5.2062e-10, var(L*R): 6.3215e-10, WD: 1.4442e-06
[2025-08-03 02:05:57] - Epoch 52/500,it:21216, Train Loss: 3.7703e-01, Val Loss: 7.6183e-02, best model: 51, LR: 9.7355e-04, epoch time: 84.21, snr: 1.0358e+01, var(R): 3.5134e-10, var(L*R): 4.2710e-10, WD: 1.4409e-06
[2025-08-03 02:07:22] - Epoch 53/500,it:21624, Train Loss: 3.5497e-01, Val Loss: 7.0589e-02, best model: 51, LR: 9.7253e-04, epoch time: 84.21, snr: 3.2570e+00, var(R): 9.5464e-10, var(L*R): 1.1981e-09, WD: 1.4390e-06
[2025-08-03 02:08:46] - Epoch 54/500,it:22032, Train Loss: 2.7234e-01, Val Loss: 5.1482e-02, best model: 54, LR: 9.7150e-04, epoch time: 84.24, snr: 1.6634e+01, var(R): 6.3844e-10, var(L*R): 7.9950e-10, WD: 1.4372e-06
[2025-08-03 02:10:10] - Epoch 55/500,it:22440, Train Loss: 3.1147e-01, Val Loss: 7.6748e-02, best model: 54, LR: 9.7044e-04, epoch time: 84.24, snr: 8.8637e-01, var(R): 2.6597e-10, var(L*R): 3.9280e-10, WD: 1.4352e-06
[2025-08-03 02:11:34] - Epoch 56/500,it:22848, Train Loss: 3.4279e-01, Val Loss: 1.0682e-01, best model: 54, LR: 9.6937e-04, epoch time: 84.01, snr: 2.2011e+00, var(R): 8.9170e-10, var(L*R): 1.0440e-09, WD: 1.4352e-06
[2025-08-03 02:12:58] - Epoch 57/500,it:23256, Train Loss: 3.2630e-01, Val Loss: 6.1445e-02, best model: 54, LR: 9.6827e-04, epoch time: 84.13, snr: 1.4962e+01, var(R): 3.9872e-09, var(L*R): 5.0151e-09, WD: 1.4327e-06
[2025-08-03 02:14:22] - Epoch 58/500,it:23664, Train Loss: 3.1011e-01, Val Loss: 8.2093e-02, best model: 54, LR: 9.6716e-04, epoch time: 84.21, snr: 1.6088e+00, var(R): 4.6905e-10, var(L*R): 5.8678e-10, WD: 1.4319e-06
[2025-08-03 02:15:47] - Epoch 59/500,it:24072, Train Loss: 3.2521e-01, Val Loss: 7.4528e-02, best model: 54, LR: 9.6604e-04, epoch time: 84.21, snr: 1.8238e+01, var(R): 1.3459e-09, var(L*R): 1.6906e-09, WD: 1.4319e-06
[2025-08-03 02:17:11] - Epoch 60/500,it:24480, Train Loss: 2.9363e-01, Val Loss: 8.8753e-02, best model: 54, LR: 9.6489e-04, epoch time: 84.12, snr: 6.0291e+00, var(R): 8.7686e-10, var(L*R): 1.2216e-09, WD: 1.4294e-06
[2025-08-03 02:18:35] - Epoch 61/500,it:24888, Train Loss: 3.3783e-01, Val Loss: 7.1350e-02, best model: 54, LR: 9.6372e-04, epoch time: 84.29, snr: 1.6028e+01, var(R): 1.6551e-09, var(L*R): 2.0678e-09, WD: 1.4268e-06
[2025-08-03 02:19:59] - Epoch 62/500,it:25296, Train Loss: 3.4793e-01, Val Loss: 6.5112e-02, best model: 54, LR: 9.6254e-04, epoch time: 84.10, snr: 2.8899e+00, var(R): 7.8548e-10, var(L*R): 1.1098e-09, WD: 1.4291e-06
[2025-08-03 02:21:23] - Epoch 63/500,it:25704, Train Loss: 2.6590e-01, Val Loss: 8.0277e-02, best model: 54, LR: 9.6134e-04, epoch time: 84.13, snr: 1.5814e+01, var(R): 5.4927e-10, var(L*R): 6.6544e-10, WD: 1.4262e-06
[2025-08-03 02:22:47] - Epoch 64/500,it:26112, Train Loss: 3.1435e-01, Val Loss: 4.7183e-02, best model: 64, LR: 9.6012e-04, epoch time: 84.22, snr: 1.4745e+01, var(R): 9.8479e-10, var(L*R): 1.4510e-09, WD: 1.4265e-06
[2025-08-03 02:24:12] - Epoch 65/500,it:26520, Train Loss: 3.5313e-01, Val Loss: 1.3663e-01, best model: 64, LR: 9.5888e-04, epoch time: 84.18, snr: 5.3450e+00, var(R): 1.4865e-10, var(L*R): 1.8524e-10, WD: 1.4266e-06
[2025-08-03 02:25:36] - Epoch 66/500,it:26928, Train Loss: 2.5578e-01, Val Loss: 5.1394e-02, best model: 64, LR: 9.5762e-04, epoch time: 84.22, snr: 2.1303e+01, var(R): 8.3925e-09, var(L*R): 1.2978e-08, WD: 1.4279e-06
[2025-08-03 02:27:00] - Epoch 67/500,it:27336, Train Loss: 3.5312e-01, Val Loss: 5.8688e-02, best model: 64, LR: 9.5635e-04, epoch time: 84.17, snr: 3.8738e+00, var(R): 1.9472e-10, var(L*R): 2.4893e-10, WD: 1.4268e-06
[2025-08-03 02:28:24] - Epoch 68/500,it:27744, Train Loss: 2.4583e-01, Val Loss: 6.6068e-02, best model: 64, LR: 9.5505e-04, epoch time: 84.19, snr: 1.4635e+00, var(R): 3.2088e-10, var(L*R): 4.3533e-10, WD: 1.4275e-06
[2025-08-03 02:29:48] - Epoch 69/500,it:28152, Train Loss: 2.3927e-01, Val Loss: 5.9088e-02, best model: 64, LR: 9.5374e-04, epoch time: 84.10, snr: 1.7631e+01, var(R): 3.7075e-10, var(L*R): 4.7914e-10, WD: 1.4252e-06
[2025-08-03 02:31:13] - Epoch 70/500,it:28560, Train Loss: 2.6732e-01, Val Loss: 5.4837e-02, best model: 64, LR: 9.5241e-04, epoch time: 84.22, snr: 1.0070e+00, var(R): 3.6645e-10, var(L*R): 4.6958e-10, WD: 1.4261e-06
[2025-08-03 02:32:37] - Epoch 71/500,it:28968, Train Loss: 2.6027e-01, Val Loss: 5.8228e-02, best model: 64, LR: 9.5107e-04, epoch time: 84.09, snr: 2.0907e+00, var(R): 2.6902e-10, var(L*R): 3.6261e-10, WD: 1.4250e-06
[2025-08-03 02:34:01] - Epoch 72/500,it:29376, Train Loss: 2.8665e-01, Val Loss: 5.1091e-02, best model: 64, LR: 9.4970e-04, epoch time: 84.14, snr: 1.1045e+01, var(R): 3.7396e-10, var(L*R): 5.7824e-10, WD: 1.4272e-06
[2025-08-03 02:35:25] - Epoch 73/500,it:29784, Train Loss: 3.2069e-01, Val Loss: 9.7232e-02, best model: 64, LR: 9.4832e-04, epoch time: 84.28, snr: 5.1143e-01, var(R): 2.1017e-10, var(L*R): 2.8600e-10, WD: 1.4268e-06
[2025-08-03 02:36:49] - Epoch 74/500,it:30192, Train Loss: 2.4734e-01, Val Loss: 6.3318e-02, best model: 64, LR: 9.4692e-04, epoch time: 84.28, snr: 1.2815e+01, var(R): 2.9660e-09, var(L*R): 3.8533e-09, WD: 1.4333e-06
[2025-08-03 02:38:14] - Epoch 75/500,it:30600, Train Loss: 2.5532e-01, Val Loss: 5.3113e-02, best model: 64, LR: 9.4550e-04, epoch time: 84.17, snr: 8.1058e+00, var(R): 5.2805e-10, var(L*R): 6.8796e-10, WD: 1.4303e-06
[2025-08-03 02:39:38] - Epoch 76/500,it:31008, Train Loss: 2.7199e-01, Val Loss: 7.4331e-02, best model: 64, LR: 9.4407e-04, epoch time: 84.27, snr: 3.3667e+00, var(R): 2.8497e-10, var(L*R): 3.7853e-10, WD: 1.4320e-06
[2025-08-03 02:41:02] - Epoch 77/500,it:31416, Train Loss: 2.6733e-01, Val Loss: 1.0850e-01, best model: 64, LR: 9.4262e-04, epoch time: 84.20, snr: 1.3175e+01, var(R): 7.2383e-10, var(L*R): 9.3137e-10, WD: 1.4314e-06
[2025-08-03 02:42:26] - Epoch 78/500,it:31824, Train Loss: 2.3209e-01, Val Loss: 6.1827e-02, best model: 64, LR: 9.4115e-04, epoch time: 84.07, snr: 1.9967e+01, var(R): 3.8688e-09, var(L*R): 6.5869e-09, WD: 1.4307e-06
[2025-08-03 02:43:50] - Epoch 79/500,it:32232, Train Loss: 2.6461e-01, Val Loss: 1.2596e-01, best model: 64, LR: 9.3966e-04, epoch time: 84.10, snr: 1.4679e+01, var(R): 6.5649e-10, var(L*R): 1.0798e-09, WD: 1.4307e-06
[2025-08-03 02:45:14] - Epoch 80/500,it:32640, Train Loss: 2.6966e-01, Val Loss: 4.9430e-02, best model: 64, LR: 9.3815e-04, epoch time: 84.18, snr: 2.0033e+01, var(R): 5.7763e-09, var(L*R): 8.2962e-09, WD: 1.4310e-06
[2025-08-03 02:46:39] - Epoch 81/500,it:33048, Train Loss: 2.5530e-01, Val Loss: 5.8040e-02, best model: 64, LR: 9.3663e-04, epoch time: 84.23, snr: 1.2364e+00, var(R): 2.1169e-10, var(L*R): 3.0689e-10, WD: 1.4348e-06
[2025-08-03 02:48:03] - Epoch 82/500,it:33456, Train Loss: 2.2902e-01, Val Loss: 6.3364e-02, best model: 64, LR: 9.3509e-04, epoch time: 84.13, snr: 1.6505e+01, var(R): 3.5662e-10, var(L*R): 5.9281e-10, WD: 1.4351e-06
[2025-08-03 02:49:27] - Epoch 83/500,it:33864, Train Loss: 2.7335e-01, Val Loss: 1.1265e-01, best model: 64, LR: 9.3354e-04, epoch time: 84.16, snr: 1.0633e+01, var(R): 5.1209e-10, var(L*R): 9.6158e-10, WD: 1.4330e-06
[2025-08-03 02:50:51] - Epoch 84/500,it:34272, Train Loss: 2.6894e-01, Val Loss: 1.2985e-01, best model: 64, LR: 9.3196e-04, epoch time: 84.08, snr: 2.2114e+01, var(R): 3.6932e-09, var(L*R): 5.6030e-09, WD: 1.4376e-06
[2025-08-03 02:52:15] - Epoch 85/500,it:34680, Train Loss: 3.0623e-01, Val Loss: 5.1425e-02, best model: 64, LR: 9.3037e-04, epoch time: 84.28, snr: 2.2962e+01, var(R): 5.6785e-09, var(L*R): 8.1528e-09, WD: 1.4372e-06
[2025-08-03 02:53:39] - Epoch 86/500,it:35088, Train Loss: 2.1765e-01, Val Loss: 5.2368e-02, best model: 64, LR: 9.2876e-04, epoch time: 84.12, snr: 1.4906e+01, var(R): 1.8362e-10, var(L*R): 2.4422e-10, WD: 1.4379e-06
[2025-08-03 02:55:04] - Epoch 87/500,it:35496, Train Loss: 2.4221e-01, Val Loss: 6.2916e-02, best model: 64, LR: 9.2714e-04, epoch time: 84.23, snr: 7.2356e+00, var(R): 2.4278e-10, var(L*R): 3.9131e-10, WD: 1.4400e-06
[2025-08-03 02:56:28] - Epoch 88/500,it:35904, Train Loss: 2.7688e-01, Val Loss: 7.6637e-02, best model: 64, LR: 9.2550e-04, epoch time: 84.50, snr: 1.6284e+01, var(R): 4.9807e-10, var(L*R): 6.4649e-10, WD: 1.4386e-06
[2025-08-03 02:57:52] - Epoch 89/500,it:36312, Train Loss: 2.4510e-01, Val Loss: 5.0761e-02, best model: 64, LR: 9.2384e-04, epoch time: 84.25, snr: 2.1118e+01, var(R): 9.1855e-10, var(L*R): 1.4864e-09, WD: 1.4363e-06
[2025-08-03 02:59:16] - Epoch 90/500,it:36720, Train Loss: 2.1015e-01, Val Loss: 5.7679e-02, best model: 64, LR: 9.2216e-04, epoch time: 84.08, snr: 9.0436e+00, var(R): 2.6305e-10, var(L*R): 4.7813e-10, WD: 1.4383e-06
[2025-08-03 03:00:41] - Epoch 91/500,it:37128, Train Loss: 2.3877e-01, Val Loss: 4.9702e-02, best model: 64, LR: 9.2047e-04, epoch time: 84.41, snr: 1.5327e+01, var(R): 3.5003e-10, var(L*R): 5.3886e-10, WD: 1.4416e-06
[2025-08-03 03:02:05] - Epoch 92/500,it:37536, Train Loss: 2.3899e-01, Val Loss: 1.0663e-01, best model: 64, LR: 9.1876e-04, epoch time: 84.29, snr: 6.7592e-01, var(R): 2.0962e-10, var(L*R): 2.8289e-10, WD: 1.4408e-06
[2025-08-03 03:03:29] - Epoch 93/500,it:37944, Train Loss: 2.5884e-01, Val Loss: 5.1242e-02, best model: 64, LR: 9.1704e-04, epoch time: 84.21, snr: 2.2731e+01, var(R): 3.9315e-09, var(L*R): 6.8535e-09, WD: 1.4369e-06
[2025-08-03 03:04:54] - Epoch 94/500,it:38352, Train Loss: 2.6836e-01, Val Loss: 7.7139e-02, best model: 64, LR: 9.1530e-04, epoch time: 84.23, snr: 1.5776e+01, var(R): 4.2964e-10, var(L*R): 6.8541e-10, WD: 1.4399e-06
[2025-08-03 03:06:18] - Epoch 95/500,it:38760, Train Loss: 2.3318e-01, Val Loss: 1.1640e-01, best model: 64, LR: 9.1354e-04, epoch time: 84.17, snr: 1.6193e+01, var(R): 1.2259e-09, var(L*R): 2.4833e-09, WD: 1.4466e-06
[2025-08-03 03:07:42] - Epoch 96/500,it:39168, Train Loss: 2.0847e-01, Val Loss: 4.3358e-02, best model: 96, LR: 9.1177e-04, epoch time: 84.19, snr: 2.3586e+01, var(R): 5.3951e-09, var(L*R): 1.0112e-08, WD: 1.4477e-06
[2025-08-03 03:09:06] - Epoch 97/500,it:39576, Train Loss: 2.0050e-01, Val Loss: 5.3718e-02, best model: 96, LR: 9.0998e-04, epoch time: 84.02, snr: 9.2929e-01, var(R): 1.3123e-10, var(L*R): 2.0707e-10, WD: 1.4466e-06
[2025-08-03 03:10:30] - Epoch 98/500,it:39984, Train Loss: 2.2275e-01, Val Loss: 6.0046e-02, best model: 96, LR: 9.0817e-04, epoch time: 84.27, snr: 1.4994e+01, var(R): 2.8465e-10, var(L*R): 4.3955e-10, WD: 1.4501e-06
[2025-08-03 03:11:54] - Epoch 99/500,it:40392, Train Loss: 2.6914e-01, Val Loss: 6.2064e-02, best model: 96, LR: 9.0635e-04, epoch time: 84.25, snr: 1.3163e+01, var(R): 5.9346e-10, var(L*R): 9.1221e-10, WD: 1.4507e-06
[2025-08-03 03:13:19] - Epoch 100/500,it:40800, Train Loss: 2.0682e-01, Val Loss: 4.2247e-02, best model: 100, LR: 9.0451e-04, epoch time: 84.35, snr: 6.0012e+00, var(R): 3.8257e-10, var(L*R): 5.3750e-10, WD: 1.4502e-06
[2025-08-03 03:14:43] - Epoch 101/500,it:41208, Train Loss: 1.9447e-01, Val Loss: 5.8520e-02, best model: 100, LR: 9.0265e-04, epoch time: 84.21, snr: 1.2714e+00, var(R): 1.9878e-10, var(L*R): 2.9460e-10, WD: 1.4490e-06
[2025-08-03 03:16:07] - Epoch 102/500,it:41616, Train Loss: 2.5734e-01, Val Loss: 5.1409e-02, best model: 100, LR: 9.0078e-04, epoch time: 84.26, snr: 8.3943e+00, var(R): 4.6889e-10, var(L*R): 7.7263e-10, WD: 1.4426e-06
[2025-08-03 03:17:31] - Epoch 103/500,it:42024, Train Loss: 2.2955e-01, Val Loss: 4.3252e-02, best model: 100, LR: 8.9890e-04, epoch time: 84.17, snr: 7.9624e-01, var(R): 2.9831e-10, var(L*R): 4.4084e-10, WD: 1.4455e-06
[2025-08-03 03:18:56] - Epoch 104/500,it:42432, Train Loss: 2.2113e-01, Val Loss: 8.0126e-02, best model: 100, LR: 8.9700e-04, epoch time: 84.26, snr: 1.1435e+01, var(R): 1.6413e-10, var(L*R): 2.3649e-10, WD: 1.4446e-06
[2025-08-03 03:20:20] - Epoch 105/500,it:42840, Train Loss: 2.2245e-01, Val Loss: 8.8042e-02, best model: 100, LR: 8.9508e-04, epoch time: 84.11, snr: 1.6284e+01, var(R): 1.2936e-09, var(L*R): 2.0730e-09, WD: 1.4404e-06
[2025-08-03 03:21:44] - Epoch 106/500,it:43248, Train Loss: 2.2593e-01, Val Loss: 4.9647e-02, best model: 100, LR: 8.9314e-04, epoch time: 84.22, snr: 1.9557e+01, var(R): 1.9035e-09, var(L*R): 3.4393e-09, WD: 1.4429e-06
[2025-08-03 03:23:08] - Epoch 107/500,it:43656, Train Loss: 2.2304e-01, Val Loss: 7.5540e-02, best model: 100, LR: 8.9120e-04, epoch time: 84.28, snr: 1.4172e+01, var(R): 2.4470e-10, var(L*R): 4.0096e-10, WD: 1.4437e-06
[2025-08-03 03:24:32] - Epoch 108/500,it:44064, Train Loss: 2.1450e-01, Val Loss: 4.4599e-02, best model: 100, LR: 8.8923e-04, epoch time: 84.09, snr: 1.8674e+01, var(R): 9.8015e-10, var(L*R): 1.4301e-09, WD: 1.4441e-06
[2025-08-03 03:25:56] - Epoch 109/500,it:44472, Train Loss: 2.2713e-01, Val Loss: 4.7804e-02, best model: 100, LR: 8.8725e-04, epoch time: 83.99, snr: 8.0362e-01, var(R): 2.7026e-10, var(L*R): 3.8932e-10, WD: 1.4448e-06
[2025-08-03 03:27:21] - Epoch 110/500,it:44880, Train Loss: 1.9345e-01, Val Loss: 7.9442e-02, best model: 100, LR: 8.8526e-04, epoch time: 84.31, snr: 7.9308e+00, var(R): 2.4743e-10, var(L*R): 4.0351e-10, WD: 1.4410e-06
[2025-08-03 03:28:45] - Epoch 111/500,it:45288, Train Loss: 2.0203e-01, Val Loss: 4.7141e-02, best model: 100, LR: 8.8325e-04, epoch time: 84.43, snr: 1.5651e+01, var(R): 1.2031e-09, var(L*R): 2.0369e-09, WD: 1.4359e-06
[2025-08-03 03:30:10] - Epoch 112/500,it:45696, Train Loss: 2.0269e-01, Val Loss: 8.7838e-02, best model: 100, LR: 8.8122e-04, epoch time: 84.39, snr: 2.4961e+00, var(R): 2.5125e-10, var(L*R): 4.0255e-10, WD: 1.4388e-06
[2025-08-03 03:31:34] - Epoch 113/500,it:46104, Train Loss: 2.2697e-01, Val Loss: 6.0832e-02, best model: 100, LR: 8.7918e-04, epoch time: 84.56, snr: 1.9995e+01, var(R): 1.6161e-09, var(L*R): 2.9803e-09, WD: 1.4363e-06
[2025-08-03 03:32:59] - Epoch 114/500,it:46512, Train Loss: 2.1735e-01, Val Loss: 1.0983e-01, best model: 100, LR: 8.7713e-04, epoch time: 84.41, snr: 1.4921e+01, var(R): 4.8722e-10, var(L*R): 8.6434e-10, WD: 1.4339e-06
[2025-08-03 03:34:23] - Epoch 115/500,it:46920, Train Loss: 1.8178e-01, Val Loss: 5.8081e-02, best model: 100, LR: 8.7506e-04, epoch time: 84.40, snr: 2.2893e+01, var(R): 5.0429e-09, var(L*R): 1.0759e-08, WD: 1.4393e-06
[2025-08-03 03:35:47] - Epoch 116/500,it:47328, Train Loss: 2.5155e-01, Val Loss: 5.0146e-02, best model: 100, LR: 8.7297e-04, epoch time: 84.31, snr: 1.3105e+00, var(R): 4.1158e-10, var(L*R): 6.2934e-10, WD: 1.4408e-06
[2025-08-03 03:37:12] - Epoch 117/500,it:47736, Train Loss: 1.9539e-01, Val Loss: 5.8484e-02, best model: 100, LR: 8.7087e-04, epoch time: 84.27, snr: 1.4759e+00, var(R): 3.0027e-10, var(L*R): 4.5393e-10, WD: 1.4437e-06
[2025-08-03 03:38:36] - Epoch 118/500,it:48144, Train Loss: 1.9017e-01, Val Loss: 4.5626e-02, best model: 100, LR: 8.6876e-04, epoch time: 84.15, snr: 6.2992e+00, var(R): 4.9398e-10, var(L*R): 8.9576e-10, WD: 1.4442e-06
[2025-08-03 03:40:00] - Epoch 119/500,it:48552, Train Loss: 1.8429e-01, Val Loss: 5.2950e-02, best model: 100, LR: 8.6663e-04, epoch time: 84.26, snr: 8.8094e+00, var(R): 2.8655e-10, var(L*R): 7.3524e-10, WD: 1.4414e-06
[2025-08-03 03:41:24] - Epoch 120/500,it:48960, Train Loss: 1.7349e-01, Val Loss: 4.3080e-02, best model: 100, LR: 8.6448e-04, epoch time: 84.09, snr: 2.7312e+00, var(R): 4.3134e-10, var(L*R): 6.1801e-10, WD: 1.4423e-06
[2025-08-03 03:42:48] - Epoch 121/500,it:49368, Train Loss: 1.7408e-01, Val Loss: 5.5575e-02, best model: 100, LR: 8.6233e-04, epoch time: 84.20, snr: 4.8073e+00, var(R): 2.4194e-10, var(L*R): 4.1234e-10, WD: 1.4426e-06
[2025-08-03 03:44:13] - Epoch 122/500,it:49776, Train Loss: 2.0896e-01, Val Loss: 5.0008e-02, best model: 100, LR: 8.6015e-04, epoch time: 84.29, snr: 1.8666e+01, var(R): 3.6094e-10, var(L*R): 6.6375e-10, WD: 1.4409e-06
[2025-08-03 03:45:37] - Epoch 123/500,it:50184, Train Loss: 2.2354e-01, Val Loss: 6.2103e-02, best model: 100, LR: 8.5797e-04, epoch time: 84.14, snr: 8.0445e+00, var(R): 3.8173e-10, var(L*R): 6.3480e-10, WD: 1.4433e-06
[2025-08-03 03:47:01] - Epoch 124/500,it:50592, Train Loss: 1.9502e-01, Val Loss: 4.1621e-02, best model: 124, LR: 8.5577e-04, epoch time: 84.10, snr: 1.9290e+01, var(R): 6.3444e-10, var(L*R): 9.7496e-10, WD: 1.4442e-06
[2025-08-03 03:48:25] - Epoch 125/500,it:51000, Train Loss: 1.9359e-01, Val Loss: 6.5237e-02, best model: 124, LR: 8.5355e-04, epoch time: 84.21, snr: 1.1942e+01, var(R): 1.8774e-10, var(L*R): 3.1921e-10, WD: 1.4485e-06
[2025-08-03 03:49:49] - Epoch 126/500,it:51408, Train Loss: 2.1405e-01, Val Loss: 1.0163e-01, best model: 124, LR: 8.5132e-04, epoch time: 84.13, snr: 1.7181e+01, var(R): 9.0746e-10, var(L*R): 1.9692e-09, WD: 1.4494e-06
[2025-08-03 03:51:14] - Epoch 127/500,it:51816, Train Loss: 1.7744e-01, Val Loss: 3.9566e-02, best model: 127, LR: 8.4908e-04, epoch time: 84.45, snr: 2.2113e+01, var(R): 2.3024e-09, var(L*R): 4.1247e-09, WD: 1.4502e-06
[2025-08-03 03:52:38] - Epoch 128/500,it:52224, Train Loss: 1.7645e-01, Val Loss: 4.6623e-02, best model: 127, LR: 8.4683e-04, epoch time: 84.25, snr: 8.3065e+00, var(R): 2.0546e-10, var(L*R): 3.1398e-10, WD: 1.4493e-06
[2025-08-03 03:54:02] - Epoch 129/500,it:52632, Train Loss: 1.8580e-01, Val Loss: 6.2082e-02, best model: 127, LR: 8.4456e-04, epoch time: 84.23, snr: 1.6772e+01, var(R): 2.8606e-10, var(L*R): 4.8705e-10, WD: 1.4483e-06
[2025-08-03 03:55:26] - Epoch 130/500,it:53040, Train Loss: 1.6810e-01, Val Loss: 4.1683e-02, best model: 127, LR: 8.4227e-04, epoch time: 84.33, snr: 1.9963e+01, var(R): 6.3654e-10, var(L*R): 1.1680e-09, WD: 1.4509e-06
[2025-08-03 03:56:51] - Epoch 131/500,it:53448, Train Loss: 2.0524e-01, Val Loss: 7.2730e-02, best model: 127, LR: 8.3998e-04, epoch time: 84.36, snr: 3.0383e+00, var(R): 1.8986e-10, var(L*R): 2.8995e-10, WD: 1.4505e-06
[2025-08-03 03:58:15] - Epoch 132/500,it:53856, Train Loss: 2.0322e-01, Val Loss: 5.1675e-02, best model: 127, LR: 8.3767e-04, epoch time: 84.50, snr: 2.0319e+01, var(R): 8.1530e-10, var(L*R): 1.6204e-09, WD: 1.4515e-06
[2025-08-03 03:59:40] - Epoch 133/500,it:54264, Train Loss: 1.7669e-01, Val Loss: 1.0240e-01, best model: 127, LR: 8.3534e-04, epoch time: 84.53, snr: 1.1221e+00, var(R): 3.2211e-10, var(L*R): 4.7258e-10, WD: 1.4504e-06
[2025-08-03 04:01:04] - Epoch 134/500,it:54672, Train Loss: 1.9407e-01, Val Loss: 4.2732e-02, best model: 127, LR: 8.3301e-04, epoch time: 84.19, snr: 2.1253e+01, var(R): 3.3363e-09, var(L*R): 7.2347e-09, WD: 1.4579e-06
[2025-08-03 04:02:28] - Epoch 135/500,it:55080, Train Loss: 1.6461e-01, Val Loss: 3.5535e-02, best model: 135, LR: 8.3066e-04, epoch time: 84.16, snr: 1.7658e+01, var(R): 2.2864e-10, var(L*R): 4.0291e-10, WD: 1.4580e-06
[2025-08-03 04:03:52] - Epoch 136/500,it:55488, Train Loss: 2.0651e-01, Val Loss: 7.8698e-02, best model: 135, LR: 8.2829e-04, epoch time: 84.19, snr: 1.0512e+00, var(R): 1.7011e-10, var(L*R): 2.7059e-10, WD: 1.4605e-06
[2025-08-03 04:05:17] - Epoch 137/500,it:55896, Train Loss: 1.9081e-01, Val Loss: 7.3459e-02, best model: 135, LR: 8.2592e-04, epoch time: 84.33, snr: 1.6486e+01, var(R): 1.1038e-09, var(L*R): 2.2173e-09, WD: 1.4617e-06
[2025-08-03 04:06:41] - Epoch 138/500,it:56304, Train Loss: 1.8484e-01, Val Loss: 3.8808e-02, best model: 135, LR: 8.2353e-04, epoch time: 84.18, snr: 1.9185e+01, var(R): 1.4704e-09, var(L*R): 3.8215e-09, WD: 1.4619e-06
[2025-08-03 04:08:05] - Epoch 139/500,it:56712, Train Loss: 1.5503e-01, Val Loss: 4.4532e-02, best model: 135, LR: 8.2113e-04, epoch time: 83.95, snr: 2.5125e+00, var(R): 1.7669e-10, var(L*R): 2.9476e-10, WD: 1.4654e-06
[2025-08-03 04:09:29] - Epoch 140/500,it:57120, Train Loss: 1.6678e-01, Val Loss: 3.7765e-02, best model: 135, LR: 8.1871e-04, epoch time: 84.30, snr: 1.7963e+01, var(R): 2.6819e-10, var(L*R): 4.4795e-10, WD: 1.4672e-06
[2025-08-03 04:10:53] - Epoch 141/500,it:57528, Train Loss: 1.9210e-01, Val Loss: 5.5021e-02, best model: 135, LR: 8.1629e-04, epoch time: 84.19, snr: 1.1983e+00, var(R): 2.5150e-10, var(L*R): 4.2318e-10, WD: 1.4674e-06
[2025-08-03 04:12:17] - Epoch 142/500,it:57936, Train Loss: 1.9919e-01, Val Loss: 7.8097e-02, best model: 135, LR: 8.1385e-04, epoch time: 84.09, snr: 1.9824e+01, var(R): 4.1219e-10, var(L*R): 8.6250e-10, WD: 1.4684e-06
[2025-08-03 04:13:42] - Epoch 143/500,it:58344, Train Loss: 1.6063e-01, Val Loss: 4.9727e-02, best model: 135, LR: 8.1139e-04, epoch time: 84.44, snr: 1.7986e+01, var(R): 1.2533e-09, var(L*R): 2.4836e-09, WD: 1.4724e-06
[2025-08-03 04:15:06] - Epoch 144/500,it:58752, Train Loss: 1.9041e-01, Val Loss: 4.3533e-02, best model: 135, LR: 8.0893e-04, epoch time: 84.18, snr: 1.6396e+01, var(R): 4.3572e-10, var(L*R): 8.6728e-10, WD: 1.4739e-06
[2025-08-03 04:16:30] - Epoch 145/500,it:59160, Train Loss: 1.5071e-01, Val Loss: 6.9687e-02, best model: 135, LR: 8.0645e-04, epoch time: 84.05, snr: 1.8073e+00, var(R): 3.4488e-10, var(L*R): 5.7550e-10, WD: 1.4758e-06
[2025-08-03 04:17:54] - Epoch 146/500,it:59568, Train Loss: 1.7226e-01, Val Loss: 4.5039e-02, best model: 135, LR: 8.0397e-04, epoch time: 84.09, snr: 5.0915e+00, var(R): 1.2529e-09, var(L*R): 2.0679e-09, WD: 1.4754e-06
[2025-08-03 04:19:18] - Epoch 147/500,it:59976, Train Loss: 1.6296e-01, Val Loss: 4.0662e-02, best model: 135, LR: 8.0146e-04, epoch time: 84.20, snr: 1.3240e+01, var(R): 3.8190e-10, var(L*R): 6.9459e-10, WD: 1.4808e-06
[2025-08-03 04:20:42] - Epoch 148/500,it:60384, Train Loss: 1.8306e-01, Val Loss: 6.7096e-02, best model: 135, LR: 7.9895e-04, epoch time: 84.12, snr: 7.0316e+00, var(R): 2.0072e-10, var(L*R): 3.4320e-10, WD: 1.4850e-06
[2025-08-03 04:22:07] - Epoch 149/500,it:60792, Train Loss: 1.5877e-01, Val Loss: 6.6107e-02, best model: 135, LR: 7.9643e-04, epoch time: 84.24, snr: 2.2650e+00, var(R): 1.0217e-09, var(L*R): 1.5570e-09, WD: 1.4814e-06
[2025-08-03 04:23:31] - Epoch 150/500,it:61200, Train Loss: 1.8556e-01, Val Loss: 7.0078e-02, best model: 135, LR: 7.9389e-04, epoch time: 84.13, snr: 1.5363e+01, var(R): 8.6788e-10, var(L*R): 1.4318e-09, WD: 1.4795e-06
[2025-08-03 04:24:55] - Epoch 151/500,it:61608, Train Loss: 2.0773e-01, Val Loss: 5.1137e-02, best model: 135, LR: 7.9135e-04, epoch time: 84.09, snr: 1.7176e+01, var(R): 8.4528e-10, var(L*R): 1.5347e-09, WD: 1.4828e-06
[2025-08-03 04:26:19] - Epoch 152/500,it:62016, Train Loss: 1.4040e-01, Val Loss: 5.2342e-02, best model: 135, LR: 7.8879e-04, epoch time: 84.01, snr: 1.7434e+01, var(R): 2.8661e-10, var(L*R): 5.2007e-10, WD: 1.4777e-06
[2025-08-03 04:27:43] - Epoch 153/500,it:62424, Train Loss: 1.4814e-01, Val Loss: 9.4800e-02, best model: 135, LR: 7.8622e-04, epoch time: 84.16, snr: 1.5503e+01, var(R): 5.1604e-10, var(L*R): 9.1499e-10, WD: 1.4800e-06
[2025-08-03 04:29:07] - Epoch 154/500,it:62832, Train Loss: 1.6332e-01, Val Loss: 7.1717e-02, best model: 135, LR: 7.8363e-04, epoch time: 83.98, snr: 1.9132e+01, var(R): 2.5287e-09, var(L*R): 6.2211e-09, WD: 1.4815e-06
[2025-08-03 04:30:31] - Epoch 155/500,it:63240, Train Loss: 1.4954e-01, Val Loss: 4.4015e-02, best model: 135, LR: 7.8104e-04, epoch time: 84.14, snr: 1.2852e+01, var(R): 9.4230e-10, var(L*R): 2.1072e-09, WD: 1.4803e-06
[2025-08-03 04:31:56] - Epoch 156/500,it:63648, Train Loss: 1.4887e-01, Val Loss: 5.1213e-02, best model: 135, LR: 7.7844e-04, epoch time: 84.27, snr: 2.4057e+00, var(R): 2.9612e-10, var(L*R): 4.5951e-10, WD: 1.4766e-06
[2025-08-03 04:33:19] - Epoch 157/500,it:64056, Train Loss: 1.6910e-01, Val Loss: 4.5716e-02, best model: 135, LR: 7.7582e-04, epoch time: 83.95, snr: 1.6201e+01, var(R): 5.2516e-10, var(L*R): 1.0629e-09, WD: 1.4767e-06
[2025-08-03 04:34:43] - Epoch 158/500,it:64464, Train Loss: 1.6965e-01, Val Loss: 4.1184e-02, best model: 135, LR: 7.7320e-04, epoch time: 83.99, snr: 1.5279e+01, var(R): 3.4919e-10, var(L*R): 6.8388e-10, WD: 1.4772e-06
[2025-08-03 04:36:08] - Epoch 159/500,it:64872, Train Loss: 1.8223e-01, Val Loss: 4.0881e-02, best model: 135, LR: 7.7056e-04, epoch time: 84.15, snr: 8.8003e-01, var(R): 3.8320e-10, var(L*R): 1.1684e-09, WD: 1.4790e-06
[2025-08-03 04:37:32] - Epoch 160/500,it:65280, Train Loss: 1.3673e-01, Val Loss: 6.6623e-02, best model: 135, LR: 7.6791e-04, epoch time: 84.10, snr: 1.0410e+01, var(R): 2.8483e-10, var(L*R): 4.9511e-10, WD: 1.4773e-06
[2025-08-03 04:38:56] - Epoch 161/500,it:65688, Train Loss: 1.4355e-01, Val Loss: 5.4054e-02, best model: 135, LR: 7.6526e-04, epoch time: 84.00, snr: 1.9999e+01, var(R): 8.7446e-10, var(L*R): 1.8108e-09, WD: 1.4791e-06
[2025-08-03 04:40:20] - Epoch 162/500,it:66096, Train Loss: 1.8887e-01, Val Loss: 4.4040e-02, best model: 135, LR: 7.6259e-04, epoch time: 84.21, snr: 1.9178e+01, var(R): 4.3133e-10, var(L*R): 7.5251e-10, WD: 1.4822e-06
[2025-08-03 04:41:44] - Epoch 163/500,it:66504, Train Loss: 1.6975e-01, Val Loss: 8.0269e-02, best model: 135, LR: 7.5991e-04, epoch time: 84.05, snr: 6.9013e+00, var(R): 3.9359e-10, var(L*R): 7.1981e-10, WD: 1.4819e-06
[2025-08-03 04:43:08] - Epoch 164/500,it:66912, Train Loss: 1.4729e-01, Val Loss: 4.4131e-02, best model: 135, LR: 7.5722e-04, epoch time: 84.02, snr: 1.8170e+01, var(R): 1.1520e-09, var(L*R): 1.9962e-09, WD: 1.4785e-06
[2025-08-03 04:44:32] - Epoch 165/500,it:67320, Train Loss: 1.4228e-01, Val Loss: 4.6299e-02, best model: 135, LR: 7.5452e-04, epoch time: 84.22, snr: 1.5620e+01, var(R): 3.9008e-10, var(L*R): 7.0413e-10, WD: 1.4819e-06
[2025-08-03 04:45:57] - Epoch 166/500,it:67728, Train Loss: 1.3827e-01, Val Loss: 3.5565e-02, best model: 135, LR: 7.5181e-04, epoch time: 84.28, snr: 6.5551e+00, var(R): 5.2926e-10, var(L*R): 9.8492e-10, WD: 1.4807e-06
[2025-08-03 04:47:21] - Epoch 167/500,it:68136, Train Loss: 1.7997e-01, Val Loss: 4.9243e-02, best model: 135, LR: 7.4909e-04, epoch time: 84.17, snr: 5.0311e+00, var(R): 2.8467e-10, var(L*R): 5.2057e-10, WD: 1.4844e-06
[2025-08-03 04:48:45] - Epoch 168/500,it:68544, Train Loss: 1.2523e-01, Val Loss: 4.0765e-02, best model: 135, LR: 7.4636e-04, epoch time: 84.21, snr: 1.5669e+01, var(R): 4.3838e-10, var(L*R): 7.8237e-10, WD: 1.4880e-06
[2025-08-03 04:50:09] - Epoch 169/500,it:68952, Train Loss: 1.4329e-01, Val Loss: 6.1995e-02, best model: 135, LR: 7.4363e-04, epoch time: 84.02, snr: 1.2223e+01, var(R): 4.3492e-10, var(L*R): 8.3693e-10, WD: 1.4855e-06
[2025-08-03 04:51:33] - Epoch 170/500,it:69360, Train Loss: 1.6968e-01, Val Loss: 6.3575e-02, best model: 135, LR: 7.4088e-04, epoch time: 84.07, snr: 1.7966e+01, var(R): 7.0548e-10, var(L*R): 1.4960e-09, WD: 1.4893e-06
[2025-08-03 04:52:57] - Epoch 171/500,it:69768, Train Loss: 1.4141e-01, Val Loss: 8.9762e-02, best model: 135, LR: 7.3812e-04, epoch time: 84.20, snr: 2.0442e+01, var(R): 7.1602e-10, var(L*R): 1.2283e-09, WD: 1.4916e-06
[2025-08-03 04:54:21] - Epoch 172/500,it:70176, Train Loss: 1.7654e-01, Val Loss: 4.4877e-02, best model: 135, LR: 7.3535e-04, epoch time: 84.01, snr: 2.0183e+01, var(R): 2.3549e-09, var(L*R): 4.2972e-09, WD: 1.4877e-06
[2025-08-03 04:55:45] - Epoch 173/500,it:70584, Train Loss: 1.3302e-01, Val Loss: 3.3897e-02, best model: 173, LR: 7.3258e-04, epoch time: 84.19, snr: 9.4263e+00, var(R): 4.2875e-10, var(L*R): 7.3553e-10, WD: 1.4941e-06
[2025-08-03 04:57:09] - Epoch 174/500,it:70992, Train Loss: 1.4365e-01, Val Loss: 4.8851e-02, best model: 173, LR: 7.2979e-04, epoch time: 84.01, snr: 8.7009e-01, var(R): 2.0159e-10, var(L*R): 3.3167e-10, WD: 1.4950e-06
[2025-08-03 04:58:33] - Epoch 175/500,it:71400, Train Loss: 1.6337e-01, Val Loss: 3.8895e-02, best model: 173, LR: 7.2700e-04, epoch time: 84.03, snr: 3.5015e+00, var(R): 4.0371e-10, var(L*R): 6.6319e-10, WD: 1.4933e-06
[2025-08-03 04:59:57] - Epoch 176/500,it:71808, Train Loss: 1.5327e-01, Val Loss: 6.7081e-02, best model: 173, LR: 7.2419e-04, epoch time: 83.84, snr: 9.2652e+00, var(R): 4.2472e-10, var(L*R): 8.0351e-10, WD: 1.4975e-06
[2025-08-03 05:01:21] - Epoch 177/500,it:72216, Train Loss: 1.3287e-01, Val Loss: 3.5962e-02, best model: 173, LR: 7.2138e-04, epoch time: 84.07, snr: 1.5180e+01, var(R): 7.7866e-10, var(L*R): 1.5102e-09, WD: 1.4984e-06
[2025-08-03 05:02:45] - Epoch 178/500,it:72624, Train Loss: 1.4775e-01, Val Loss: 7.4590e-02, best model: 173, LR: 7.1856e-04, epoch time: 83.97, snr: 1.9573e+00, var(R): 4.3829e-10, var(L*R): 7.2037e-10, WD: 1.4957e-06
[2025-08-03 05:04:09] - Epoch 179/500,it:73032, Train Loss: 1.4307e-01, Val Loss: 6.9101e-02, best model: 173, LR: 7.1573e-04, epoch time: 83.88, snr: 1.4824e+01, var(R): 1.5621e-09, var(L*R): 2.9260e-09, WD: 1.4989e-06
[2025-08-03 05:05:33] - Epoch 180/500,it:73440, Train Loss: 1.2762e-01, Val Loss: 5.1916e-02, best model: 173, LR: 7.1289e-04, epoch time: 83.96, snr: 1.7833e+01, var(R): 9.9965e-10, var(L*R): 1.7727e-09, WD: 1.4916e-06
[2025-08-03 05:06:57] - Epoch 181/500,it:73848, Train Loss: 1.5279e-01, Val Loss: 4.2001e-02, best model: 173, LR: 7.1004e-04, epoch time: 83.94, snr: 1.3547e+01, var(R): 6.8520e-10, var(L*R): 1.1571e-09, WD: 1.5046e-06
[2025-08-03 05:08:21] - Epoch 182/500,it:74256, Train Loss: 1.1983e-01, Val Loss: 4.6500e-02, best model: 173, LR: 7.0719e-04, epoch time: 83.82, snr: 1.6963e+01, var(R): 4.8330e-10, var(L*R): 9.8062e-10, WD: 1.5057e-06
[2025-08-03 05:09:45] - Epoch 183/500,it:74664, Train Loss: 1.3501e-01, Val Loss: 4.0760e-02, best model: 173, LR: 7.0432e-04, epoch time: 83.81, snr: 1.7086e+01, var(R): 4.4853e-10, var(L*R): 7.2948e-10, WD: 1.5034e-06
[2025-08-03 05:11:09] - Epoch 184/500,it:75072, Train Loss: 1.5072e-01, Val Loss: 3.7660e-02, best model: 173, LR: 7.0145e-04, epoch time: 83.73, snr: 6.8642e+00, var(R): 3.3977e-10, var(L*R): 6.2091e-10, WD: 1.5087e-06
[2025-08-03 05:12:32] - Epoch 185/500,it:75480, Train Loss: 1.5979e-01, Val Loss: 3.9906e-02, best model: 173, LR: 6.9857e-04, epoch time: 83.77, snr: 4.1812e+00, var(R): 4.0286e-10, var(L*R): 7.9228e-10, WD: 1.5110e-06
[2025-08-03 05:13:56] - Epoch 186/500,it:75888, Train Loss: 1.6933e-01, Val Loss: 4.3488e-02, best model: 173, LR: 6.9569e-04, epoch time: 83.87, snr: 3.0145e+00, var(R): 4.6514e-10, var(L*R): 9.0007e-10, WD: 1.5141e-06
[2025-08-03 05:15:20] - Epoch 187/500,it:76296, Train Loss: 1.3371e-01, Val Loss: 5.1093e-02, best model: 173, LR: 6.9279e-04, epoch time: 83.77, snr: 1.0892e+01, var(R): 4.4919e-10, var(L*R): 7.0667e-10, WD: 1.5137e-06
[2025-08-03 05:16:44] - Epoch 188/500,it:76704, Train Loss: 1.3848e-01, Val Loss: 6.1933e-02, best model: 173, LR: 6.8989e-04, epoch time: 83.73, snr: 1.4607e+01, var(R): 6.0381e-10, var(L*R): 1.1728e-09, WD: 1.5123e-06
[2025-08-03 05:18:07] - Epoch 189/500,it:77112, Train Loss: 1.3941e-01, Val Loss: 3.3579e-02, best model: 189, LR: 6.8698e-04, epoch time: 83.75, snr: 1.7276e+01, var(R): 6.3446e-10, var(L*R): 1.4337e-09, WD: 1.5186e-06
[2025-08-03 05:19:30] - Epoch 190/500,it:77520, Train Loss: 1.2741e-01, Val Loss: 3.6919e-02, best model: 189, LR: 6.8406e-04, epoch time: 82.72, snr: 3.6975e+00, var(R): 4.1221e-10, var(L*R): 7.4676e-10, WD: 1.5143e-06
[2025-08-03 05:20:52] - Epoch 191/500,it:77928, Train Loss: 1.5134e-01, Val Loss: 6.7305e-02, best model: 189, LR: 6.8114e-04, epoch time: 82.34, snr: 1.0069e+01, var(R): 5.6168e-10, var(L*R): 1.1087e-09, WD: 1.5228e-06
[2025-08-03 05:22:15] - Epoch 192/500,it:78336, Train Loss: 1.4819e-01, Val Loss: 4.0740e-02, best model: 189, LR: 6.7821e-04, epoch time: 82.47, snr: 1.6770e+01, var(R): 1.1300e-09, var(L*R): 2.0917e-09, WD: 1.5205e-06
[2025-08-03 05:23:37] - Epoch 193/500,it:78744, Train Loss: 1.2859e-01, Val Loss: 7.7681e-02, best model: 189, LR: 6.7527e-04, epoch time: 82.41, snr: 1.0156e+00, var(R): 4.9967e-10, var(L*R): 8.2486e-10, WD: 1.5268e-06
[2025-08-03 05:25:00] - Epoch 194/500,it:79152, Train Loss: 1.4115e-01, Val Loss: 3.9018e-02, best model: 189, LR: 6.7232e-04, epoch time: 82.33, snr: 1.8176e+01, var(R): 1.8411e-09, var(L*R): 4.4852e-09, WD: 1.5214e-06
[2025-08-03 05:26:22] - Epoch 195/500,it:79560, Train Loss: 1.2709e-01, Val Loss: 5.2843e-02, best model: 189, LR: 6.6937e-04, epoch time: 82.24, snr: 4.3385e+00, var(R): 3.2116e-10, var(L*R): 6.5619e-10, WD: 1.5266e-06
[2025-08-03 05:27:44] - Epoch 196/500,it:79968, Train Loss: 1.2946e-01, Val Loss: 4.6092e-02, best model: 189, LR: 6.6641e-04, epoch time: 82.28, snr: 8.1972e+00, var(R): 6.9285e-10, var(L*R): 1.9719e-09, WD: 1.5244e-06
[2025-08-03 05:29:06] - Epoch 197/500,it:80376, Train Loss: 1.3837e-01, Val Loss: 6.0997e-02, best model: 189, LR: 6.6344e-04, epoch time: 82.25, snr: 1.1862e+01, var(R): 7.2220e-10, var(L*R): 1.3265e-09, WD: 1.5283e-06
[2025-08-03 05:30:29] - Epoch 198/500,it:80784, Train Loss: 1.1796e-01, Val Loss: 3.7501e-02, best model: 189, LR: 6.6047e-04, epoch time: 82.22, snr: 1.7971e+01, var(R): 7.6788e-10, var(L*R): 1.3740e-09, WD: 1.5278e-06
[2025-08-03 05:31:51] - Epoch 199/500,it:81192, Train Loss: 1.1150e-01, Val Loss: 5.4323e-02, best model: 189, LR: 6.5749e-04, epoch time: 82.04, snr: 1.4884e+00, var(R): 4.0237e-10, var(L*R): 6.5947e-10, WD: 1.5237e-06
[2025-08-03 05:33:13] - Epoch 200/500,it:81600, Train Loss: 1.2404e-01, Val Loss: 3.1998e-02, best model: 200, LR: 6.5451e-04, epoch time: 82.27, snr: 1.6132e+01, var(R): 8.6230e-10, var(L*R): 2.1282e-09, WD: 1.5280e-06
[2025-08-03 05:34:35] - Epoch 201/500,it:82008, Train Loss: 1.2622e-01, Val Loss: 4.0045e-02, best model: 200, LR: 6.5152e-04, epoch time: 82.21, snr: 9.4758e-01, var(R): 3.6552e-10, var(L*R): 6.0963e-10, WD: 1.5282e-06
[2025-08-03 05:35:57] - Epoch 202/500,it:82416, Train Loss: 1.2883e-01, Val Loss: 4.0824e-02, best model: 200, LR: 6.4852e-04, epoch time: 82.11, snr: 7.6274e+00, var(R): 5.6635e-10, var(L*R): 9.2285e-10, WD: 1.5327e-06
[2025-08-03 05:37:20] - Epoch 203/500,it:82824, Train Loss: 1.2792e-01, Val Loss: 3.6115e-02, best model: 200, LR: 6.4552e-04, epoch time: 82.15, snr: 7.6733e+00, var(R): 5.2215e-10, var(L*R): 9.5683e-10, WD: 1.5281e-06
[2025-08-03 05:38:42] - Epoch 204/500,it:83232, Train Loss: 1.0657e-01, Val Loss: 3.4895e-02, best model: 200, LR: 6.4251e-04, epoch time: 82.15, snr: 7.6107e-01, var(R): 5.0814e-10, var(L*R): 8.9134e-10, WD: 1.5300e-06
[2025-08-03 05:40:04] - Epoch 205/500,it:83640, Train Loss: 1.1675e-01, Val Loss: 4.3727e-02, best model: 200, LR: 6.3950e-04, epoch time: 82.16, snr: 1.2108e+00, var(R): 6.0169e-10, var(L*R): 1.1543e-09, WD: 1.5306e-06
[2025-08-03 05:41:26] - Epoch 206/500,it:84048, Train Loss: 1.1951e-01, Val Loss: 7.5232e-02, best model: 200, LR: 6.3648e-04, epoch time: 82.01, snr: 1.4171e+01, var(R): 5.8577e-10, var(L*R): 1.1980e-09, WD: 1.5360e-06
[2025-08-03 05:42:48] - Epoch 207/500,it:84456, Train Loss: 1.3430e-01, Val Loss: 3.1058e-02, best model: 207, LR: 6.3345e-04, epoch time: 82.08, snr: 1.6769e+01, var(R): 1.4398e-09, var(L*R): 2.6843e-09, WD: 1.5358e-06
[2025-08-03 05:44:10] - Epoch 208/500,it:84864, Train Loss: 1.3595e-01, Val Loss: 3.1102e-02, best model: 207, LR: 6.3042e-04, epoch time: 82.09, snr: 1.4890e+00, var(R): 4.4338e-10, var(L*R): 7.4351e-10, WD: 1.5331e-06
[2025-08-03 05:45:32] - Epoch 209/500,it:85272, Train Loss: 1.2140e-01, Val Loss: 2.8747e-02, best model: 209, LR: 6.2739e-04, epoch time: 82.16, snr: 1.7570e+00, var(R): 4.9111e-10, var(L*R): 8.0541e-10, WD: 1.5366e-06
[2025-08-03 05:46:54] - Epoch 210/500,it:85680, Train Loss: 1.1476e-01, Val Loss: 4.2145e-02, best model: 209, LR: 6.2434e-04, epoch time: 82.03, snr: 1.1226e+00, var(R): 3.8048e-10, var(L*R): 6.9472e-10, WD: 1.5392e-06
[2025-08-03 05:48:16] - Epoch 211/500,it:86088, Train Loss: 1.3056e-01, Val Loss: 3.6390e-02, best model: 209, LR: 6.2130e-04, epoch time: 81.95, snr: 7.3460e+00, var(R): 5.7603e-10, var(L*R): 9.1910e-10, WD: 1.5400e-06
[2025-08-03 05:49:38] - Epoch 212/500,it:86496, Train Loss: 1.0908e-01, Val Loss: 2.8965e-02, best model: 209, LR: 6.1825e-04, epoch time: 82.07, snr: 6.8102e+00, var(R): 6.4812e-10, var(L*R): 1.1841e-09, WD: 1.5415e-06
[2025-08-03 05:51:00] - Epoch 213/500,it:86904, Train Loss: 1.2120e-01, Val Loss: 3.6071e-02, best model: 209, LR: 6.1519e-04, epoch time: 82.01, snr: 2.0376e+00, var(R): 4.5572e-10, var(L*R): 8.3605e-10, WD: 1.5384e-06
[2025-08-03 05:52:22] - Epoch 214/500,it:87312, Train Loss: 1.2657e-01, Val Loss: 3.2977e-02, best model: 209, LR: 6.1214e-04, epoch time: 81.93, snr: 2.5795e+00, var(R): 7.0411e-10, var(L*R): 1.1933e-09, WD: 1.5425e-06
[2025-08-03 05:53:44] - Epoch 215/500,it:87720, Train Loss: 1.2490e-01, Val Loss: 3.4848e-02, best model: 209, LR: 6.0907e-04, epoch time: 81.90, snr: 2.0811e+00, var(R): 6.4180e-10, var(L*R): 1.2702e-09, WD: 1.5517e-06
[2025-08-03 05:55:06] - Epoch 216/500,it:88128, Train Loss: 1.0131e-01, Val Loss: 3.8820e-02, best model: 209, LR: 6.0600e-04, epoch time: 82.07, snr: 9.6888e+00, var(R): 6.2865e-10, var(L*R): 1.0256e-09, WD: 1.5431e-06
[2025-08-03 05:56:28] - Epoch 217/500,it:88536, Train Loss: 1.1970e-01, Val Loss: 3.0019e-02, best model: 209, LR: 6.0293e-04, epoch time: 81.89, snr: 1.1651e+01, var(R): 6.3442e-10, var(L*R): 1.3745e-09, WD: 1.5408e-06
[2025-08-03 05:57:50] - Epoch 218/500,it:88944, Train Loss: 1.1308e-01, Val Loss: 3.8197e-02, best model: 209, LR: 5.9985e-04, epoch time: 81.99, snr: 4.2863e+00, var(R): 4.2934e-10, var(L*R): 7.8801e-10, WD: 1.5457e-06
[2025-08-03 05:59:12] - Epoch 219/500,it:89352, Train Loss: 1.1940e-01, Val Loss: 4.7273e-02, best model: 209, LR: 5.9677e-04, epoch time: 81.95, snr: 1.2179e+01, var(R): 6.6694e-10, var(L*R): 1.6084e-09, WD: 1.5447e-06
[2025-08-03 06:00:34] - Epoch 220/500,it:89760, Train Loss: 1.0912e-01, Val Loss: 5.3277e-02, best model: 209, LR: 5.9369e-04, epoch time: 82.15, snr: 1.2855e+01, var(R): 1.3114e-09, var(L*R): 2.7820e-09, WD: 1.5491e-06
[2025-08-03 06:01:56] - Epoch 221/500,it:90168, Train Loss: 9.9681e-02, Val Loss: 3.0197e-02, best model: 209, LR: 5.9060e-04, epoch time: 81.87, snr: 1.3922e+01, var(R): 1.2611e-09, var(L*R): 2.6470e-09, WD: 1.5507e-06
[2025-08-03 06:03:18] - Epoch 222/500,it:90576, Train Loss: 1.2456e-01, Val Loss: 3.4204e-02, best model: 209, LR: 5.8751e-04, epoch time: 82.03, snr: 1.7533e+00, var(R): 5.4767e-10, var(L*R): 1.0214e-09, WD: 1.5508e-06
[2025-08-03 06:04:40] - Epoch 223/500,it:90984, Train Loss: 1.0632e-01, Val Loss: 3.1163e-02, best model: 209, LR: 5.8442e-04, epoch time: 81.97, snr: 8.1042e+00, var(R): 6.1136e-10, var(L*R): 9.2181e-10, WD: 1.5501e-06
[2025-08-03 06:06:02] - Epoch 224/500,it:91392, Train Loss: 1.3095e-01, Val Loss: 5.0358e-02, best model: 209, LR: 5.8132e-04, epoch time: 82.02, snr: 1.5533e+00, var(R): 6.3378e-10, var(L*R): 1.1585e-09, WD: 1.5526e-06
[2025-08-03 06:07:24] - Epoch 225/500,it:91800, Train Loss: 1.0119e-01, Val Loss: 2.9546e-02, best model: 209, LR: 5.7822e-04, epoch time: 81.95, snr: 1.4661e+01, var(R): 1.0482e-09, var(L*R): 1.9846e-09, WD: 1.5582e-06
[2025-08-03 06:08:46] - Epoch 226/500,it:92208, Train Loss: 1.2904e-01, Val Loss: 3.3151e-02, best model: 209, LR: 5.7511e-04, epoch time: 82.00, snr: 3.3381e+00, var(R): 5.1579e-10, var(L*R): 1.0225e-09, WD: 1.5567e-06
[2025-08-03 06:10:08] - Epoch 227/500,it:92616, Train Loss: 9.7334e-02, Val Loss: 4.2657e-02, best model: 209, LR: 5.7201e-04, epoch time: 82.02, snr: 3.4706e+00, var(R): 8.1364e-10, var(L*R): 1.3975e-09, WD: 1.5638e-06
[2025-08-03 06:11:30] - Epoch 228/500,it:93024, Train Loss: 1.1866e-01, Val Loss: 3.0099e-02, best model: 209, LR: 5.6890e-04, epoch time: 82.08, snr: 1.3241e+01, var(R): 9.0212e-10, var(L*R): 1.9750e-09, WD: 1.5653e-06
[2025-08-03 06:12:52] - Epoch 229/500,it:93432, Train Loss: 1.0520e-01, Val Loss: 3.9221e-02, best model: 209, LR: 5.6578e-04, epoch time: 81.94, snr: 7.4467e+00, var(R): 6.2050e-10, var(L*R): 1.1165e-09, WD: 1.5644e-06
[2025-08-03 06:14:14] - Epoch 230/500,it:93840, Train Loss: 1.1042e-01, Val Loss: 5.3517e-02, best model: 209, LR: 5.6267e-04, epoch time: 81.90, snr: 1.8405e+00, var(R): 7.9886e-10, var(L*R): 1.4957e-09, WD: 1.5689e-06
[2025-08-03 06:15:36] - Epoch 231/500,it:94248, Train Loss: 1.0150e-01, Val Loss: 5.1799e-02, best model: 209, LR: 5.5955e-04, epoch time: 82.08, snr: 1.6304e+01, var(R): 8.8624e-10, var(L*R): 1.5334e-09, WD: 1.5676e-06
[2025-08-03 06:16:58] - Epoch 232/500,it:94656, Train Loss: 1.0973e-01, Val Loss: 3.1870e-02, best model: 209, LR: 5.5643e-04, epoch time: 81.91, snr: 1.3915e+01, var(R): 1.1174e-09, var(L*R): 2.7067e-09, WD: 1.5693e-06
[2025-08-03 06:18:20] - Epoch 233/500,it:95064, Train Loss: 1.0599e-01, Val Loss: 3.7974e-02, best model: 209, LR: 5.5331e-04, epoch time: 82.09, snr: 2.3095e+00, var(R): 6.6555e-10, var(L*R): 1.0716e-09, WD: 1.5736e-06
[2025-08-03 06:19:42] - Epoch 234/500,it:95472, Train Loss: 9.1304e-02, Val Loss: 2.7307e-02, best model: 234, LR: 5.5018e-04, epoch time: 82.01, snr: 7.4411e+00, var(R): 6.6378e-10, var(L*R): 1.1656e-09, WD: 1.5747e-06
[2025-08-03 06:21:04] - Epoch 235/500,it:95880, Train Loss: 1.0364e-01, Val Loss: 3.8242e-02, best model: 234, LR: 5.4705e-04, epoch time: 82.16, snr: 1.4681e+00, var(R): 6.4693e-10, var(L*R): 1.1915e-09, WD: 1.5743e-06
[2025-08-03 06:22:26] - Epoch 236/500,it:96288, Train Loss: 1.0570e-01, Val Loss: 3.1590e-02, best model: 234, LR: 5.4393e-04, epoch time: 82.00, snr: 1.0996e+01, var(R): 6.0553e-10, var(L*R): 9.5124e-10, WD: 1.5792e-06
[2025-08-03 06:23:48] - Epoch 237/500,it:96696, Train Loss: 1.0057e-01, Val Loss: 2.6040e-02, best model: 237, LR: 5.4080e-04, epoch time: 82.13, snr: 7.6960e+00, var(R): 6.7600e-10, var(L*R): 1.2356e-09, WD: 1.5779e-06
[2025-08-03 06:25:10] - Epoch 238/500,it:97104, Train Loss: 1.2190e-01, Val Loss: 6.2973e-02, best model: 237, LR: 5.3766e-04, epoch time: 81.95, snr: 5.3100e+00, var(R): 5.8066e-10, var(L*R): 1.0941e-09, WD: 1.5801e-06
[2025-08-03 06:26:32] - Epoch 239/500,it:97512, Train Loss: 1.0571e-01, Val Loss: 3.2508e-02, best model: 237, LR: 5.3453e-04, epoch time: 82.09, snr: 1.8132e+01, var(R): 1.1429e-09, var(L*R): 2.0293e-09, WD: 1.5832e-06
[2025-08-03 06:27:54] - Epoch 240/500,it:97920, Train Loss: 1.0175e-01, Val Loss: 3.0565e-02, best model: 237, LR: 5.3140e-04, epoch time: 81.92, snr: 8.7670e+00, var(R): 7.2911e-10, var(L*R): 1.4079e-09, WD: 1.5807e-06
[2025-08-03 06:29:16] - Epoch 241/500,it:98328, Train Loss: 9.0498e-02, Val Loss: 2.7692e-02, best model: 237, LR: 5.2826e-04, epoch time: 82.06, snr: 1.1877e+00, var(R): 6.3104e-10, var(L*R): 1.1429e-09, WD: 1.5866e-06
[2025-08-03 06:30:38] - Epoch 242/500,it:98736, Train Loss: 1.0436e-01, Val Loss: 2.7466e-02, best model: 237, LR: 5.2512e-04, epoch time: 81.99, snr: 3.5065e+00, var(R): 6.9544e-10, var(L*R): 1.2827e-09, WD: 1.5857e-06
[2025-08-03 06:32:01] - Epoch 243/500,it:99144, Train Loss: 8.9062e-02, Val Loss: 2.5200e-02, best model: 243, LR: 5.2198e-04, epoch time: 82.24, snr: 1.1843e+00, var(R): 7.2384e-10, var(L*R): 1.2526e-09, WD: 1.5864e-06
[2025-08-03 06:33:23] - Epoch 244/500,it:99552, Train Loss: 1.0314e-01, Val Loss: 4.4391e-02, best model: 243, LR: 5.1885e-04, epoch time: 81.94, snr: 1.7313e+00, var(R): 8.1582e-10, var(L*R): 1.9571e-09, WD: 1.5893e-06
[2025-08-03 06:34:45] - Epoch 245/500,it:99960, Train Loss: 9.9173e-02, Val Loss: 3.1447e-02, best model: 243, LR: 5.1571e-04, epoch time: 81.99, snr: 1.4864e+01, var(R): 9.9754e-10, var(L*R): 1.7927e-09, WD: 1.5907e-06
[2025-08-03 06:36:07] - Epoch 246/500,it:100368, Train Loss: 8.9420e-02, Val Loss: 4.3155e-02, best model: 243, LR: 5.1257e-04, epoch time: 82.13, snr: 1.0104e+01, var(R): 8.2347e-10, var(L*R): 1.4073e-09, WD: 1.5933e-06
[2025-08-03 06:37:29] - Epoch 247/500,it:100776, Train Loss: 9.8198e-02, Val Loss: 3.1240e-02, best model: 243, LR: 5.0942e-04, epoch time: 81.98, snr: 1.0532e+01, var(R): 1.1703e-09, var(L*R): 2.3453e-09, WD: 1.5911e-06
[2025-08-03 06:38:51] - Epoch 248/500,it:101184, Train Loss: 9.7128e-02, Val Loss: 4.6852e-02, best model: 243, LR: 5.0628e-04, epoch time: 82.02, snr: 6.1469e+00, var(R): 8.5225e-10, var(L*R): 1.6028e-09, WD: 1.5917e-06
[2025-08-03 06:40:13] - Epoch 249/500,it:101592, Train Loss: 1.0927e-01, Val Loss: 4.1343e-02, best model: 243, LR: 5.0314e-04, epoch time: 82.00, snr: 1.1217e+01, var(R): 8.8141e-10, var(L*R): 1.5740e-09, WD: 1.5874e-06
[2025-08-03 06:41:35] - Epoch 250/500,it:102000, Train Loss: 8.8799e-02, Val Loss: 4.1161e-02, best model: 243, LR: 5.0000e-04, epoch time: 82.04, snr: 1.2166e+01, var(R): 9.7114e-10, var(L*R): 1.9835e-09, WD: 1.6009e-06
[2025-08-03 06:42:57] - Epoch 251/500,it:102408, Train Loss: 8.5943e-02, Val Loss: 2.6676e-02, best model: 243, LR: 4.9686e-04, epoch time: 81.96, snr: 1.5240e+01, var(R): 8.2168e-10, var(L*R): 1.6454e-09, WD: 1.6000e-06
[2025-08-03 06:44:19] - Epoch 252/500,it:102816, Train Loss: 1.0158e-01, Val Loss: 2.6326e-02, best model: 243, LR: 4.9372e-04, epoch time: 82.02, snr: 2.3071e+00, var(R): 7.0389e-10, var(L*R): 1.2771e-09, WD: 1.6001e-06
[2025-08-03 06:45:41] - Epoch 253/500,it:103224, Train Loss: 9.1428e-02, Val Loss: 3.8228e-02, best model: 243, LR: 4.9058e-04, epoch time: 82.03, snr: 3.7295e+00, var(R): 1.0046e-09, var(L*R): 1.8781e-09, WD: 1.5941e-06
[2025-08-03 06:47:03] - Epoch 254/500,it:103632, Train Loss: 8.1980e-02, Val Loss: 3.0210e-02, best model: 243, LR: 4.8743e-04, epoch time: 82.08, snr: 1.2824e+01, var(R): 1.0755e-09, var(L*R): 2.0401e-09, WD: 1.5987e-06
[2025-08-03 06:48:25] - Epoch 255/500,it:104040, Train Loss: 1.0645e-01, Val Loss: 3.9199e-02, best model: 243, LR: 4.8429e-04, epoch time: 81.99, snr: 7.3249e+00, var(R): 7.8047e-10, var(L*R): 1.5664e-09, WD: 1.5920e-06
[2025-08-03 06:49:47] - Epoch 256/500,it:104448, Train Loss: 8.7034e-02, Val Loss: 2.9559e-02, best model: 243, LR: 4.8115e-04, epoch time: 82.03, snr: 1.0424e+01, var(R): 8.0072e-10, var(L*R): 1.2996e-09, WD: 1.6036e-06
[2025-08-03 06:51:09] - Epoch 257/500,it:104856, Train Loss: 1.0364e-01, Val Loss: 3.4316e-02, best model: 243, LR: 4.7802e-04, epoch time: 82.04, snr: 2.6256e+00, var(R): 1.0729e-09, var(L*R): 2.0099e-09, WD: 1.6022e-06
[2025-08-03 06:52:31] - Epoch 258/500,it:105264, Train Loss: 9.2128e-02, Val Loss: 2.8577e-02, best model: 243, LR: 4.7488e-04, epoch time: 81.98, snr: 5.7185e+00, var(R): 9.1511e-10, var(L*R): 1.8002e-09, WD: 1.6054e-06
[2025-08-03 06:53:53] - Epoch 259/500,it:105672, Train Loss: 9.5486e-02, Val Loss: 3.1951e-02, best model: 243, LR: 4.7174e-04, epoch time: 82.02, snr: 6.6883e+00, var(R): 8.5009e-10, var(L*R): 1.6517e-09, WD: 1.6008e-06
[2025-08-03 06:55:15] - Epoch 260/500,it:106080, Train Loss: 8.1713e-02, Val Loss: 3.6873e-02, best model: 243, LR: 4.6860e-04, epoch time: 82.03, snr: 1.1044e+01, var(R): 8.9065e-10, var(L*R): 1.5088e-09, WD: 1.5991e-06
[2025-08-03 06:56:37] - Epoch 261/500,it:106488, Train Loss: 9.9459e-02, Val Loss: 3.7360e-02, best model: 243, LR: 4.6547e-04, epoch time: 82.07, snr: 1.3732e+01, var(R): 1.0502e-09, var(L*R): 1.9009e-09, WD: 1.6120e-06
[2025-08-03 06:57:59] - Epoch 262/500,it:106896, Train Loss: 7.7366e-02, Val Loss: 3.8578e-02, best model: 243, LR: 4.6234e-04, epoch time: 81.90, snr: 8.6599e+00, var(R): 9.2043e-10, var(L*R): 1.7946e-09, WD: 1.6040e-06
[2025-08-03 06:59:21] - Epoch 263/500,it:107304, Train Loss: 8.1617e-02, Val Loss: 2.6965e-02, best model: 243, LR: 4.5920e-04, epoch time: 82.11, snr: 1.2536e+01, var(R): 1.1817e-09, var(L*R): 2.4677e-09, WD: 1.6005e-06
[2025-08-03 07:00:43] - Epoch 264/500,it:107712, Train Loss: 9.6756e-02, Val Loss: 3.0977e-02, best model: 243, LR: 4.5607e-04, epoch time: 82.08, snr: 3.1612e+00, var(R): 9.7472e-10, var(L*R): 1.8875e-09, WD: 1.6081e-06
[2025-08-03 07:02:05] - Epoch 265/500,it:108120, Train Loss: 8.3464e-02, Val Loss: 2.5610e-02, best model: 243, LR: 4.5295e-04, epoch time: 82.07, snr: 4.6521e+00, var(R): 1.0057e-09, var(L*R): 1.9604e-09, WD: 1.6090e-06
[2025-08-03 07:03:27] - Epoch 266/500,it:108528, Train Loss: 8.6090e-02, Val Loss: 3.1957e-02, best model: 243, LR: 4.4982e-04, epoch time: 81.91, snr: 5.4468e+00, var(R): 8.1619e-10, var(L*R): 1.5069e-09, WD: 1.6075e-06
[2025-08-03 07:04:49] - Epoch 267/500,it:108936, Train Loss: 8.5341e-02, Val Loss: 3.4595e-02, best model: 243, LR: 4.4669e-04, epoch time: 82.09, snr: 7.2946e+00, var(R): 9.3705e-10, var(L*R): 1.6436e-09, WD: 1.6090e-06
[2025-08-03 07:06:11] - Epoch 268/500,it:109344, Train Loss: 8.0942e-02, Val Loss: 2.9636e-02, best model: 243, LR: 4.4357e-04, epoch time: 82.03, snr: 1.1018e+01, var(R): 1.3434e-09, var(L*R): 2.7568e-09, WD: 1.6115e-06
[2025-08-03 07:07:33] - Epoch 269/500,it:109752, Train Loss: 8.3300e-02, Val Loss: 2.4184e-02, best model: 269, LR: 4.4045e-04, epoch time: 82.11, snr: 2.7669e+00, var(R): 1.1254e-09, var(L*R): 2.1239e-09, WD: 1.6126e-06
[2025-08-03 07:08:55] - Epoch 270/500,it:110160, Train Loss: 9.8012e-02, Val Loss: 3.7011e-02, best model: 269, LR: 4.3733e-04, epoch time: 81.89, snr: 1.5489e+00, var(R): 1.0712e-09, var(L*R): 1.9903e-09, WD: 1.6131e-06
[2025-08-03 07:10:17] - Epoch 271/500,it:110568, Train Loss: 9.0047e-02, Val Loss: 4.0299e-02, best model: 269, LR: 4.3422e-04, epoch time: 82.08, snr: 1.1814e+01, var(R): 1.2822e-09, var(L*R): 2.1193e-09, WD: 1.6216e-06
[2025-08-03 07:11:40] - Epoch 272/500,it:110976, Train Loss: 8.5523e-02, Val Loss: 3.1208e-02, best model: 269, LR: 4.3110e-04, epoch time: 82.10, snr: 1.1210e+01, var(R): 1.0923e-09, var(L*R): 2.3643e-09, WD: 1.6219e-06
[2025-08-03 07:13:02] - Epoch 273/500,it:111384, Train Loss: 9.3682e-02, Val Loss: 3.0585e-02, best model: 269, LR: 4.2799e-04, epoch time: 81.97, snr: 5.6460e+00, var(R): 1.1269e-09, var(L*R): 2.1034e-09, WD: 1.6149e-06
[2025-08-03 07:14:23] - Epoch 274/500,it:111792, Train Loss: 7.0194e-02, Val Loss: 2.5757e-02, best model: 269, LR: 4.2489e-04, epoch time: 81.97, snr: 5.1096e+00, var(R): 1.2312e-09, var(L*R): 2.5422e-09, WD: 1.6194e-06
[2025-08-03 07:15:46] - Epoch 275/500,it:112200, Train Loss: 9.0180e-02, Val Loss: 4.4637e-02, best model: 269, LR: 4.2178e-04, epoch time: 82.03, snr: 1.3330e+00, var(R): 1.0831e-09, var(L*R): 2.3070e-09, WD: 1.6199e-06
[2025-08-03 07:17:08] - Epoch 276/500,it:112608, Train Loss: 8.1551e-02, Val Loss: 2.9193e-02, best model: 269, LR: 4.1868e-04, epoch time: 82.11, snr: 1.3232e+01, var(R): 1.6584e-09, var(L*R): 3.3749e-09, WD: 1.6237e-06
[2025-08-03 07:18:30] - Epoch 277/500,it:113016, Train Loss: 9.5184e-02, Val Loss: 3.9574e-02, best model: 269, LR: 4.1558e-04, epoch time: 81.94, snr: 4.5932e+00, var(R): 1.0744e-09, var(L*R): 2.4132e-09, WD: 1.6223e-06
[2025-08-03 07:19:52] - Epoch 278/500,it:113424, Train Loss: 8.1433e-02, Val Loss: 2.6562e-02, best model: 269, LR: 4.1249e-04, epoch time: 81.98, snr: 8.3934e+00, var(R): 1.3010e-09, var(L*R): 3.2775e-09, WD: 1.6272e-06
[2025-08-03 07:21:14] - Epoch 279/500,it:113832, Train Loss: 8.4026e-02, Val Loss: 2.5240e-02, best model: 269, LR: 4.0940e-04, epoch time: 82.07, snr: 7.3276e+00, var(R): 9.8158e-10, var(L*R): 1.8827e-09, WD: 1.6288e-06
[2025-08-03 07:22:36] - Epoch 280/500,it:114240, Train Loss: 7.1364e-02, Val Loss: 4.0347e-02, best model: 269, LR: 4.0631e-04, epoch time: 82.10, snr: 2.7129e+00, var(R): 1.1944e-09, var(L*R): 2.2731e-09, WD: 1.6332e-06
[2025-08-03 07:23:58] - Epoch 281/500,it:114648, Train Loss: 8.5119e-02, Val Loss: 2.2689e-02, best model: 281, LR: 4.0323e-04, epoch time: 82.05, snr: 8.5244e+00, var(R): 1.7758e-09, var(L*R): 4.1805e-09, WD: 1.6278e-06
[2025-08-03 07:25:20] - Epoch 282/500,it:115056, Train Loss: 7.2523e-02, Val Loss: 2.6162e-02, best model: 281, LR: 4.0015e-04, epoch time: 81.99, snr: 1.9764e+00, var(R): 1.1693e-09, var(L*R): 2.2080e-09, WD: 1.6343e-06
[2025-08-03 07:26:42] - Epoch 283/500,it:115464, Train Loss: 9.3084e-02, Val Loss: 2.9860e-02, best model: 281, LR: 3.9707e-04, epoch time: 82.10, snr: 7.1108e+00, var(R): 1.1439e-09, var(L*R): 2.2577e-09, WD: 1.6302e-06
[2025-08-03 07:28:04] - Epoch 284/500,it:115872, Train Loss: 7.4492e-02, Val Loss: 3.6288e-02, best model: 281, LR: 3.9400e-04, epoch time: 82.05, snr: 5.7740e+00, var(R): 1.3080e-09, var(L*R): 2.5438e-09, WD: 1.6362e-06
[2025-08-03 07:29:26] - Epoch 285/500,it:116280, Train Loss: 8.1368e-02, Val Loss: 5.3832e-02, best model: 281, LR: 3.9093e-04, epoch time: 81.81, snr: 7.3475e+00, var(R): 1.4443e-09, var(L*R): 3.0387e-09, WD: 1.6283e-06
[2025-08-03 07:30:48] - Epoch 286/500,it:116688, Train Loss: 7.7538e-02, Val Loss: 2.2515e-02, best model: 286, LR: 3.8786e-04, epoch time: 82.16, snr: 1.5925e+01, var(R): 1.6287e-09, var(L*R): 3.4097e-09, WD: 1.6313e-06
[2025-08-03 07:32:10] - Epoch 287/500,it:117096, Train Loss: 7.1309e-02, Val Loss: 2.7474e-02, best model: 286, LR: 3.8481e-04, epoch time: 82.05, snr: 2.1217e+00, var(R): 1.2380e-09, var(L*R): 2.4504e-09, WD: 1.6409e-06
[2025-08-03 07:33:32] - Epoch 288/500,it:117504, Train Loss: 8.1732e-02, Val Loss: 2.8351e-02, best model: 286, LR: 3.8175e-04, epoch time: 81.96, snr: 6.8167e+00, var(R): 1.3430e-09, var(L*R): 2.3058e-09, WD: 1.6468e-06
[2025-08-03 07:34:54] - Epoch 289/500,it:117912, Train Loss: 7.4110e-02, Val Loss: 2.7576e-02, best model: 286, LR: 3.7870e-04, epoch time: 81.91, snr: 7.4404e+00, var(R): 1.1274e-09, var(L*R): 2.0288e-09, WD: 1.6386e-06
[2025-08-03 07:36:16] - Epoch 290/500,it:118320, Train Loss: 7.5557e-02, Val Loss: 4.2402e-02, best model: 286, LR: 3.7566e-04, epoch time: 82.01, snr: 4.4713e+00, var(R): 1.6452e-09, var(L*R): 3.1791e-09, WD: 1.6400e-06
[2025-08-03 07:37:38] - Epoch 291/500,it:118728, Train Loss: 8.0567e-02, Val Loss: 2.3697e-02, best model: 286, LR: 3.7261e-04, epoch time: 81.98, snr: 1.0380e+01, var(R): 1.7766e-09, var(L*R): 4.3828e-09, WD: 1.6498e-06
[2025-08-03 07:39:00] - Epoch 292/500,it:119136, Train Loss: 8.4414e-02, Val Loss: 2.8111e-02, best model: 286, LR: 3.6958e-04, epoch time: 81.90, snr: 2.1701e+00, var(R): 1.3778e-09, var(L*R): 2.7134e-09, WD: 1.6445e-06
[2025-08-03 07:40:22] - Epoch 293/500,it:119544, Train Loss: 9.7541e-02, Val Loss: 4.2633e-02, best model: 286, LR: 3.6655e-04, epoch time: 82.06, snr: 3.2239e+00, var(R): 1.3601e-09, var(L*R): 2.5985e-09, WD: 1.6359e-06
[2025-08-03 07:41:44] - Epoch 294/500,it:119952, Train Loss: 6.6200e-02, Val Loss: 2.4438e-02, best model: 286, LR: 3.6352e-04, epoch time: 82.05, snr: 1.1090e+01, var(R): 1.6452e-09, var(L*R): 3.3001e-09, WD: 1.6460e-06
[2025-08-03 07:43:06] - Epoch 295/500,it:120360, Train Loss: 7.2908e-02, Val Loss: 2.2350e-02, best model: 295, LR: 3.6050e-04, epoch time: 81.97, snr: 2.4406e+00, var(R): 1.5892e-09, var(L*R): 2.9230e-09, WD: 1.6467e-06
[2025-08-03 07:44:28] - Epoch 296/500,it:120768, Train Loss: 7.7211e-02, Val Loss: 2.8230e-02, best model: 295, LR: 3.5749e-04, epoch time: 81.97, snr: 3.7237e+00, var(R): 1.5170e-09, var(L*R): 3.3744e-09, WD: 1.6567e-06
[2025-08-03 07:45:50] - Epoch 297/500,it:121176, Train Loss: 6.4441e-02, Val Loss: 2.1698e-02, best model: 297, LR: 3.5448e-04, epoch time: 82.05, snr: 4.1365e+00, var(R): 1.4956e-09, var(L*R): 2.9800e-09, WD: 1.6558e-06
[2025-08-03 07:47:12] - Epoch 298/500,it:121584, Train Loss: 7.2911e-02, Val Loss: 2.3081e-02, best model: 297, LR: 3.5148e-04, epoch time: 81.90, snr: 4.3514e+00, var(R): 1.4372e-09, var(L*R): 2.9209e-09, WD: 1.6498e-06
[2025-08-03 07:48:34] - Epoch 299/500,it:121992, Train Loss: 6.6637e-02, Val Loss: 2.0456e-02, best model: 299, LR: 3.4848e-04, epoch time: 82.11, snr: 6.3979e+00, var(R): 1.4432e-09, var(L*R): 2.7920e-09, WD: 1.6448e-06
[2025-08-03 07:49:56] - Epoch 300/500,it:122400, Train Loss: 7.7354e-02, Val Loss: 2.1492e-02, best model: 299, LR: 3.4549e-04, epoch time: 81.86, snr: 2.8476e+00, var(R): 1.3060e-09, var(L*R): 2.5437e-09, WD: 1.6480e-06
[2025-08-03 07:51:18] - Epoch 301/500,it:122808, Train Loss: 6.8070e-02, Val Loss: 2.6593e-02, best model: 299, LR: 3.4251e-04, epoch time: 81.91, snr: 2.8668e+00, var(R): 1.3928e-09, var(L*R): 3.1510e-09, WD: 1.6540e-06
[2025-08-03 07:52:40] - Epoch 302/500,it:123216, Train Loss: 7.4902e-02, Val Loss: 3.9362e-02, best model: 299, LR: 3.3953e-04, epoch time: 82.09, snr: 3.0045e+00, var(R): 1.6630e-09, var(L*R): 3.6914e-09, WD: 1.6543e-06
[2025-08-03 07:54:02] - Epoch 303/500,it:123624, Train Loss: 6.4787e-02, Val Loss: 2.5327e-02, best model: 299, LR: 3.3656e-04, epoch time: 82.01, snr: 6.4285e+00, var(R): 2.3428e-09, var(L*R): 5.0993e-09, WD: 1.6581e-06
[2025-08-03 07:55:24] - Epoch 304/500,it:124032, Train Loss: 7.3126e-02, Val Loss: 3.5271e-02, best model: 299, LR: 3.3359e-04, epoch time: 81.87, snr: 3.8476e+00, var(R): 1.5113e-09, var(L*R): 3.2543e-09, WD: 1.6560e-06
[2025-08-03 07:56:46] - Epoch 305/500,it:124440, Train Loss: 7.1064e-02, Val Loss: 2.5470e-02, best model: 299, LR: 3.3063e-04, epoch time: 82.01, snr: 8.3555e+00, var(R): 1.8426e-09, var(L*R): 3.8623e-09, WD: 1.6652e-06
[2025-08-03 07:58:08] - Epoch 306/500,it:124848, Train Loss: 7.1782e-02, Val Loss: 2.1838e-02, best model: 299, LR: 3.2768e-04, epoch time: 81.99, snr: 3.9651e+00, var(R): 1.7165e-09, var(L*R): 3.5598e-09, WD: 1.6555e-06
[2025-08-03 07:59:30] - Epoch 307/500,it:125256, Train Loss: 6.9092e-02, Val Loss: 3.3053e-02, best model: 299, LR: 3.2473e-04, epoch time: 81.88, snr: 1.6199e+00, var(R): 1.6407e-09, var(L*R): 3.2522e-09, WD: 1.6531e-06
[2025-08-03 08:00:52] - Epoch 308/500,it:125664, Train Loss: 7.6227e-02, Val Loss: 2.2649e-02, best model: 299, LR: 3.2179e-04, epoch time: 82.00, snr: 9.7311e+00, var(R): 1.6661e-09, var(L*R): 3.7283e-09, WD: 1.6639e-06
[2025-08-03 08:02:14] - Epoch 309/500,it:126072, Train Loss: 6.8447e-02, Val Loss: 2.4855e-02, best model: 299, LR: 3.1886e-04, epoch time: 82.04, snr: 6.1478e+00, var(R): 1.7134e-09, var(L*R): 3.1847e-09, WD: 1.6697e-06
[2025-08-03 08:03:36] - Epoch 310/500,it:126480, Train Loss: 5.6813e-02, Val Loss: 1.9504e-02, best model: 310, LR: 3.1594e-04, epoch time: 82.03, snr: 1.6202e+00, var(R): 1.6647e-09, var(L*R): 3.2375e-09, WD: 1.6704e-06
[2025-08-03 08:04:58] - Epoch 311/500,it:126888, Train Loss: 6.4138e-02, Val Loss: 2.1737e-02, best model: 310, LR: 3.1302e-04, epoch time: 81.85, snr: 4.1164e+00, var(R): 1.7101e-09, var(L*R): 3.5297e-09, WD: 1.6606e-06
[2025-08-03 08:06:20] - Epoch 312/500,it:127296, Train Loss: 6.8712e-02, Val Loss: 2.0757e-02, best model: 310, LR: 3.1011e-04, epoch time: 82.01, snr: 3.8823e+00, var(R): 1.6385e-09, var(L*R): 3.3310e-09, WD: 1.6582e-06
[2025-08-03 08:07:42] - Epoch 313/500,it:127704, Train Loss: 5.5481e-02, Val Loss: 2.4353e-02, best model: 310, LR: 3.0721e-04, epoch time: 82.02, snr: 2.6115e+00, var(R): 1.7609e-09, var(L*R): 3.5503e-09, WD: 1.6610e-06
[2025-08-03 08:09:03] - Epoch 314/500,it:128112, Train Loss: 7.9237e-02, Val Loss: 2.1944e-02, best model: 310, LR: 3.0431e-04, epoch time: 81.94, snr: 7.0423e+00, var(R): 1.8923e-09, var(L*R): 3.7883e-09, WD: 1.6631e-06
[2025-08-03 08:10:25] - Epoch 315/500,it:128520, Train Loss: 7.5889e-02, Val Loss: 2.6287e-02, best model: 310, LR: 3.0143e-04, epoch time: 81.94, snr: 4.8224e+00, var(R): 1.7776e-09, var(L*R): 3.7315e-09, WD: 1.6634e-06
[2025-08-03 08:11:47] - Epoch 316/500,it:128928, Train Loss: 6.7962e-02, Val Loss: 3.2523e-02, best model: 310, LR: 2.9855e-04, epoch time: 81.96, snr: 2.0126e+00, var(R): 1.7814e-09, var(L*R): 3.4156e-09, WD: 1.6672e-06
[2025-08-03 08:13:09] - Epoch 317/500,it:129336, Train Loss: 6.3520e-02, Val Loss: 3.4474e-02, best model: 310, LR: 2.9568e-04, epoch time: 81.89, snr: 5.7598e+00, var(R): 2.0686e-09, var(L*R): 4.5010e-09, WD: 1.6650e-06
[2025-08-03 08:14:31] - Epoch 318/500,it:129744, Train Loss: 6.2338e-02, Val Loss: 2.3106e-02, best model: 310, LR: 2.9281e-04, epoch time: 82.06, snr: 3.9014e+00, var(R): 2.4389e-09, var(L*R): 4.8083e-09, WD: 1.6691e-06
[2025-08-03 08:15:53] - Epoch 319/500,it:130152, Train Loss: 5.7256e-02, Val Loss: 2.1640e-02, best model: 310, LR: 2.8996e-04, epoch time: 81.92, snr: 5.7206e+00, var(R): 2.1057e-09, var(L*R): 4.0602e-09, WD: 1.6750e-06
[2025-08-03 08:17:15] - Epoch 320/500,it:130560, Train Loss: 6.5746e-02, Val Loss: 2.8348e-02, best model: 310, LR: 2.8711e-04, epoch time: 81.91, snr: 3.2373e+00, var(R): 2.1130e-09, var(L*R): 4.3915e-09, WD: 1.6701e-06
[2025-08-03 08:18:37] - Epoch 321/500,it:130968, Train Loss: 6.3398e-02, Val Loss: 3.6447e-02, best model: 310, LR: 2.8427e-04, epoch time: 82.04, snr: 9.9944e+00, var(R): 1.9214e-09, var(L*R): 3.5495e-09, WD: 1.6725e-06
[2025-08-03 08:19:59] - Epoch 322/500,it:131376, Train Loss: 6.2873e-02, Val Loss: 2.1122e-02, best model: 310, LR: 2.8144e-04, epoch time: 81.86, snr: 1.0661e+01, var(R): 2.0408e-09, var(L*R): 3.5323e-09, WD: 1.6736e-06
[2025-08-03 08:21:21] - Epoch 323/500,it:131784, Train Loss: 6.5306e-02, Val Loss: 2.0198e-02, best model: 310, LR: 2.7862e-04, epoch time: 81.94, snr: 4.2245e+00, var(R): 2.0225e-09, var(L*R): 4.2895e-09, WD: 1.6675e-06
[2025-08-03 08:22:43] - Epoch 324/500,it:132192, Train Loss: 5.6804e-02, Val Loss: 2.9909e-02, best model: 310, LR: 2.7581e-04, epoch time: 82.08, snr: 1.8819e+00, var(R): 2.1905e-09, var(L*R): 4.4967e-09, WD: 1.6763e-06
[2025-08-03 08:24:05] - Epoch 325/500,it:132600, Train Loss: 6.0212e-02, Val Loss: 2.4619e-02, best model: 310, LR: 2.7300e-04, epoch time: 81.99, snr: 6.8421e+00, var(R): 1.9638e-09, var(L*R): 3.8689e-09, WD: 1.6752e-06
[2025-08-03 08:25:27] - Epoch 326/500,it:133008, Train Loss: 5.8975e-02, Val Loss: 2.0180e-02, best model: 310, LR: 2.7021e-04, epoch time: 81.87, snr: 7.4029e+00, var(R): 2.1424e-09, var(L*R): 4.0903e-09, WD: 1.6784e-06
[2025-08-03 08:26:49] - Epoch 327/500,it:133416, Train Loss: 6.2625e-02, Val Loss: 1.8191e-02, best model: 327, LR: 2.6742e-04, epoch time: 82.07, snr: 1.4435e+00, var(R): 2.1778e-09, var(L*R): 4.4874e-09, WD: 1.6770e-06
[2025-08-03 08:28:11] - Epoch 328/500,it:133824, Train Loss: 5.7742e-02, Val Loss: 2.3700e-02, best model: 327, LR: 2.6465e-04, epoch time: 82.01, snr: 2.5543e+00, var(R): 2.2037e-09, var(L*R): 4.4634e-09, WD: 1.6745e-06
[2025-08-03 08:29:33] - Epoch 329/500,it:134232, Train Loss: 5.9879e-02, Val Loss: 2.0987e-02, best model: 327, LR: 2.6188e-04, epoch time: 81.96, snr: 2.2280e+00, var(R): 2.2819e-09, var(L*R): 4.6755e-09, WD: 1.6724e-06
[2025-08-03 08:30:55] - Epoch 330/500,it:134640, Train Loss: 6.0082e-02, Val Loss: 3.3852e-02, best model: 327, LR: 2.5912e-04, epoch time: 81.94, snr: 6.2507e+00, var(R): 2.2599e-09, var(L*R): 4.3907e-09, WD: 1.6715e-06
[2025-08-03 08:32:17] - Epoch 331/500,it:135048, Train Loss: 6.8404e-02, Val Loss: 2.0412e-02, best model: 327, LR: 2.5637e-04, epoch time: 82.00, snr: 1.0569e+01, var(R): 2.1489e-09, var(L*R): 4.3517e-09, WD: 1.6780e-06
[2025-08-03 08:33:39] - Epoch 332/500,it:135456, Train Loss: 5.3056e-02, Val Loss: 2.3877e-02, best model: 327, LR: 2.5364e-04, epoch time: 81.98, snr: 1.6747e+00, var(R): 2.2518e-09, var(L*R): 4.9056e-09, WD: 1.6819e-06
[2025-08-03 08:35:01] - Epoch 333/500,it:135864, Train Loss: 5.3447e-02, Val Loss: 1.7869e-02, best model: 333, LR: 2.5091e-04, epoch time: 82.03, snr: 8.2069e+00, var(R): 2.3749e-09, var(L*R): 4.4938e-09, WD: 1.6842e-06
[2025-08-03 08:36:23] - Epoch 334/500,it:136272, Train Loss: 6.5167e-02, Val Loss: 1.9684e-02, best model: 333, LR: 2.4819e-04, epoch time: 81.92, snr: 1.6867e+00, var(R): 2.2892e-09, var(L*R): 5.0161e-09, WD: 1.6819e-06
[2025-08-03 08:37:45] - Epoch 335/500,it:136680, Train Loss: 5.9200e-02, Val Loss: 2.0300e-02, best model: 333, LR: 2.4548e-04, epoch time: 81.98, snr: 1.9028e+00, var(R): 2.3801e-09, var(L*R): 5.0220e-09, WD: 1.6856e-06
[2025-08-03 08:39:07] - Epoch 336/500,it:137088, Train Loss: 5.3530e-02, Val Loss: 2.4504e-02, best model: 333, LR: 2.4278e-04, epoch time: 81.93, snr: 4.6284e+00, var(R): 2.1751e-09, var(L*R): 4.4815e-09, WD: 1.6854e-06
[2025-08-03 08:40:29] - Epoch 337/500,it:137496, Train Loss: 5.4123e-02, Val Loss: 2.7599e-02, best model: 333, LR: 2.4009e-04, epoch time: 81.96, snr: 1.5308e+00, var(R): 2.6395e-09, var(L*R): 5.2230e-09, WD: 1.6830e-06
[2025-08-03 08:41:51] - Epoch 338/500,it:137904, Train Loss: 6.0512e-02, Val Loss: 2.1849e-02, best model: 333, LR: 2.3741e-04, epoch time: 81.97, snr: 3.9670e+00, var(R): 2.6763e-09, var(L*R): 5.7629e-09, WD: 1.6844e-06
[2025-08-03 08:43:13] - Epoch 339/500,it:138312, Train Loss: 5.2905e-02, Val Loss: 1.9175e-02, best model: 333, LR: 2.3474e-04, epoch time: 81.91, snr: 4.1644e+00, var(R): 2.4483e-09, var(L*R): 5.9237e-09, WD: 1.6895e-06
[2025-08-03 08:44:35] - Epoch 340/500,it:138720, Train Loss: 4.8129e-02, Val Loss: 1.7158e-02, best model: 340, LR: 2.3209e-04, epoch time: 82.07, snr: 2.5977e+00, var(R): 2.3469e-09, var(L*R): 5.1232e-09, WD: 1.6838e-06
[2025-08-03 08:45:57] - Epoch 341/500,it:139128, Train Loss: 5.5972e-02, Val Loss: 2.9823e-02, best model: 340, LR: 2.2944e-04, epoch time: 81.91, snr: 1.9880e+00, var(R): 2.6125e-09, var(L*R): 5.5235e-09, WD: 1.6943e-06
[2025-08-03 08:47:19] - Epoch 342/500,it:139536, Train Loss: 5.7254e-02, Val Loss: 2.8603e-02, best model: 340, LR: 2.2680e-04, epoch time: 81.95, snr: 3.8851e+00, var(R): 2.7022e-09, var(L*R): 6.1543e-09, WD: 1.6837e-06
[2025-08-03 08:48:41] - Epoch 343/500,it:139944, Train Loss: 6.1432e-02, Val Loss: 1.7557e-02, best model: 340, LR: 2.2418e-04, epoch time: 82.04, snr: 4.2845e+00, var(R): 2.7646e-09, var(L*R): 6.4420e-09, WD: 1.6930e-06
[2025-08-03 08:50:03] - Epoch 344/500,it:140352, Train Loss: 4.6083e-02, Val Loss: 1.9243e-02, best model: 340, LR: 2.2156e-04, epoch time: 82.01, snr: 3.8310e+00, var(R): 2.5310e-09, var(L*R): 5.6394e-09, WD: 1.6903e-06
[2025-08-03 08:51:25] - Epoch 345/500,it:140760, Train Loss: 4.7853e-02, Val Loss: 1.8521e-02, best model: 340, LR: 2.1896e-04, epoch time: 81.84, snr: 2.4191e+00, var(R): 2.5613e-09, var(L*R): 5.3601e-09, WD: 1.6839e-06
[2025-08-03 08:52:47] - Epoch 346/500,it:141168, Train Loss: 4.9470e-02, Val Loss: 1.8915e-02, best model: 340, LR: 2.1637e-04, epoch time: 82.01, snr: 1.6448e+00, var(R): 2.7245e-09, var(L*R): 5.9009e-09, WD: 1.6848e-06
[2025-08-03 08:54:09] - Epoch 347/500,it:141576, Train Loss: 5.3988e-02, Val Loss: 1.7265e-02, best model: 340, LR: 2.1378e-04, epoch time: 81.97, snr: 2.3070e+00, var(R): 2.8032e-09, var(L*R): 5.7327e-09, WD: 1.6903e-06
[2025-08-03 08:55:30] - Epoch 348/500,it:141984, Train Loss: 5.1880e-02, Val Loss: 1.7984e-02, best model: 340, LR: 2.1121e-04, epoch time: 81.92, snr: 1.7577e+00, var(R): 2.6102e-09, var(L*R): 5.4659e-09, WD: 1.6937e-06
[2025-08-03 08:56:52] - Epoch 349/500,it:142392, Train Loss: 5.2141e-02, Val Loss: 2.9975e-02, best model: 340, LR: 2.0865e-04, epoch time: 81.93, snr: 1.7624e+00, var(R): 2.8182e-09, var(L*R): 5.8855e-09, WD: 1.6907e-06
[2025-08-03 08:58:14] - Epoch 350/500,it:142800, Train Loss: 4.5387e-02, Val Loss: 1.5798e-02, best model: 350, LR: 2.0611e-04, epoch time: 82.09, snr: 6.7148e+00, var(R): 2.8857e-09, var(L*R): 6.7285e-09, WD: 1.6969e-06
[2025-08-03 08:59:36] - Epoch 351/500,it:143208, Train Loss: 4.8865e-02, Val Loss: 1.9078e-02, best model: 350, LR: 2.0357e-04, epoch time: 82.00, snr: 2.3218e+00, var(R): 2.8979e-09, var(L*R): 6.7564e-09, WD: 1.6853e-06
[2025-08-03 09:00:58] - Epoch 352/500,it:143616, Train Loss: 4.6518e-02, Val Loss: 2.3029e-02, best model: 350, LR: 2.0105e-04, epoch time: 81.95, snr: 4.0419e+00, var(R): 3.0840e-09, var(L*R): 6.2564e-09, WD: 1.6938e-06
[2025-08-03 09:02:21] - Epoch 353/500,it:144024, Train Loss: 4.9746e-02, Val Loss: 2.4304e-02, best model: 350, LR: 1.9854e-04, epoch time: 82.07, snr: 1.9808e+00, var(R): 3.2469e-09, var(L*R): 7.2484e-09, WD: 1.6927e-06
[2025-08-03 09:03:42] - Epoch 354/500,it:144432, Train Loss: 5.9092e-02, Val Loss: 1.8345e-02, best model: 350, LR: 1.9603e-04, epoch time: 81.94, snr: 6.1723e+00, var(R): 2.8149e-09, var(L*R): 6.0178e-09, WD: 1.6832e-06
[2025-08-03 09:05:04] - Epoch 355/500,it:144840, Train Loss: 4.9298e-02, Val Loss: 1.6574e-02, best model: 350, LR: 1.9355e-04, epoch time: 81.96, snr: 1.7725e+00, var(R): 2.9056e-09, var(L*R): 6.5907e-09, WD: 1.6811e-06
[2025-08-03 09:06:26] - Epoch 356/500,it:145248, Train Loss: 4.6773e-02, Val Loss: 1.7343e-02, best model: 350, LR: 1.9107e-04, epoch time: 81.77, snr: 1.8594e+00, var(R): 3.0494e-09, var(L*R): 6.7205e-09, WD: 1.6908e-06
[2025-08-03 09:07:48] - Epoch 357/500,it:145656, Train Loss: 4.8382e-02, Val Loss: 1.7996e-02, best model: 350, LR: 1.8861e-04, epoch time: 82.09, snr: 1.7345e+00, var(R): 3.0626e-09, var(L*R): 6.0548e-09, WD: 1.6933e-06
[2025-08-03 09:09:10] - Epoch 358/500,it:146064, Train Loss: 5.0872e-02, Val Loss: 2.3255e-02, best model: 350, LR: 1.8615e-04, epoch time: 82.04, snr: 1.7930e+00, var(R): 3.1756e-09, var(L*R): 6.2257e-09, WD: 1.6908e-06
[2025-08-03 09:10:32] - Epoch 359/500,it:146472, Train Loss: 4.8754e-02, Val Loss: 1.8929e-02, best model: 350, LR: 1.8371e-04, epoch time: 82.00, snr: 2.6514e+00, var(R): 3.0905e-09, var(L*R): 7.0815e-09, WD: 1.6895e-06
[2025-08-03 09:11:54] - Epoch 360/500,it:146880, Train Loss: 4.7128e-02, Val Loss: 1.5634e-02, best model: 360, LR: 1.8129e-04, epoch time: 81.96, snr: 5.1890e+00, var(R): 3.2551e-09, var(L*R): 6.9512e-09, WD: 1.6960e-06
[2025-08-03 09:13:16] - Epoch 361/500,it:147288, Train Loss: 4.2007e-02, Val Loss: 1.8668e-02, best model: 360, LR: 1.7887e-04, epoch time: 81.90, snr: 2.1376e+00, var(R): 3.2305e-09, var(L*R): 6.5782e-09, WD: 1.6934e-06
[2025-08-03 09:14:38] - Epoch 362/500,it:147696, Train Loss: 5.0537e-02, Val Loss: 1.5876e-02, best model: 360, LR: 1.7647e-04, epoch time: 81.99, snr: 1.5944e+00, var(R): 3.3022e-09, var(L*R): 7.3313e-09, WD: 1.6914e-06
[2025-08-03 09:16:00] - Epoch 363/500,it:148104, Train Loss: 4.9130e-02, Val Loss: 1.7762e-02, best model: 360, LR: 1.7408e-04, epoch time: 81.96, snr: 3.4433e+00, var(R): 3.2622e-09, var(L*R): 6.9078e-09, WD: 1.6874e-06
[2025-08-03 09:17:22] - Epoch 364/500,it:148512, Train Loss: 5.3119e-02, Val Loss: 2.6166e-02, best model: 360, LR: 1.7171e-04, epoch time: 81.87, snr: 1.9278e+00, var(R): 3.4193e-09, var(L*R): 8.4147e-09, WD: 1.6878e-06
[2025-08-03 09:18:44] - Epoch 365/500,it:148920, Train Loss: 4.3752e-02, Val Loss: 1.7535e-02, best model: 360, LR: 1.6934e-04, epoch time: 81.99, snr: 6.4039e+00, var(R): 3.1861e-09, var(L*R): 6.6176e-09, WD: 1.6913e-06
[2025-08-03 09:20:06] - Epoch 366/500,it:149328, Train Loss: 4.5220e-02, Val Loss: 1.6188e-02, best model: 360, LR: 1.6699e-04, epoch time: 81.98, snr: 4.3437e+00, var(R): 3.3528e-09, var(L*R): 7.4979e-09, WD: 1.6872e-06
[2025-08-03 09:21:28] - Epoch 367/500,it:149736, Train Loss: 4.9373e-02, Val Loss: 1.9574e-02, best model: 360, LR: 1.6466e-04, epoch time: 81.87, snr: 2.5239e+00, var(R): 3.3571e-09, var(L*R): 7.4953e-09, WD: 1.6988e-06
[2025-08-03 09:22:50] - Epoch 368/500,it:150144, Train Loss: 4.8721e-02, Val Loss: 1.7800e-02, best model: 360, LR: 1.6233e-04, epoch time: 81.96, snr: 5.1928e+00, var(R): 3.3115e-09, var(L*R): 6.7454e-09, WD: 1.6950e-06
[2025-08-03 09:24:12] - Epoch 369/500,it:150552, Train Loss: 4.4379e-02, Val Loss: 1.8662e-02, best model: 360, LR: 1.6002e-04, epoch time: 82.00, snr: 4.4986e+00, var(R): 3.5481e-09, var(L*R): 7.4031e-09, WD: 1.6910e-06
[2025-08-03 09:25:34] - Epoch 370/500,it:150960, Train Loss: 4.4641e-02, Val Loss: 2.0087e-02, best model: 360, LR: 1.5773e-04, epoch time: 81.95, snr: 2.0836e+00, var(R): 3.6316e-09, var(L*R): 7.9271e-09, WD: 1.7084e-06
[2025-08-03 09:26:56] - Epoch 371/500,it:151368, Train Loss: 4.6511e-02, Val Loss: 1.5350e-02, best model: 371, LR: 1.5544e-04, epoch time: 81.95, snr: 1.5112e+00, var(R): 3.7554e-09, var(L*R): 8.2797e-09, WD: 1.6862e-06
[2025-08-03 09:28:18] - Epoch 372/500,it:151776, Train Loss: 4.9583e-02, Val Loss: 1.8288e-02, best model: 371, LR: 1.5317e-04, epoch time: 81.95, snr: 2.2507e+00, var(R): 3.4059e-09, var(L*R): 7.4555e-09, WD: 1.6956e-06
[2025-08-03 09:29:40] - Epoch 373/500,it:152184, Train Loss: 4.2148e-02, Val Loss: 1.4451e-02, best model: 373, LR: 1.5092e-04, epoch time: 82.06, snr: 1.9005e+00, var(R): 3.6194e-09, var(L*R): 7.6002e-09, WD: 1.7041e-06
[2025-08-03 09:31:02] - Epoch 374/500,it:152592, Train Loss: 4.1393e-02, Val Loss: 1.4993e-02, best model: 373, LR: 1.4868e-04, epoch time: 81.95, snr: 2.6917e+00, var(R): 3.6716e-09, var(L*R): 7.8563e-09, WD: 1.6899e-06
[2025-08-03 09:32:24] - Epoch 375/500,it:153000, Train Loss: 4.4980e-02, Val Loss: 1.4037e-02, best model: 375, LR: 1.4645e-04, epoch time: 81.92, snr: 3.3394e+00, var(R): 3.6195e-09, var(L*R): 7.9326e-09, WD: 1.6978e-06
[2025-08-03 09:33:46] - Epoch 376/500,it:153408, Train Loss: 4.0685e-02, Val Loss: 1.5751e-02, best model: 375, LR: 1.4423e-04, epoch time: 82.04, snr: 2.3077e+00, var(R): 3.7840e-09, var(L*R): 8.1045e-09, WD: 1.7041e-06
[2025-08-03 09:35:08] - Epoch 377/500,it:153816, Train Loss: 4.6976e-02, Val Loss: 1.5531e-02, best model: 375, LR: 1.4203e-04, epoch time: 81.89, snr: 3.4441e+00, var(R): 3.8525e-09, var(L*R): 8.0296e-09, WD: 1.7009e-06
[2025-08-03 09:36:29] - Epoch 378/500,it:154224, Train Loss: 3.8986e-02, Val Loss: 1.6516e-02, best model: 375, LR: 1.3985e-04, epoch time: 81.79, snr: 1.8878e+00, var(R): 3.7269e-09, var(L*R): 8.3098e-09, WD: 1.6980e-06
[2025-08-03 09:37:51] - Epoch 379/500,it:154632, Train Loss: 4.5149e-02, Val Loss: 2.0380e-02, best model: 375, LR: 1.3767e-04, epoch time: 81.97, snr: 2.3759e+00, var(R): 3.7634e-09, var(L*R): 8.3237e-09, WD: 1.6835e-06
[2025-08-03 09:39:13] - Epoch 380/500,it:155040, Train Loss: 4.5563e-02, Val Loss: 1.6496e-02, best model: 375, LR: 1.3552e-04, epoch time: 81.91, snr: 1.9931e+00, var(R): 4.0734e-09, var(L*R): 8.8369e-09, WD: 1.7018e-06
[2025-08-03 09:40:35] - Epoch 381/500,it:155448, Train Loss: 4.4264e-02, Val Loss: 2.2410e-02, best model: 375, LR: 1.3337e-04, epoch time: 81.81, snr: 2.0085e+00, var(R): 3.9354e-09, var(L*R): 8.6261e-09, WD: 1.7035e-06
[2025-08-03 09:41:57] - Epoch 382/500,it:155856, Train Loss: 4.1525e-02, Val Loss: 1.4700e-02, best model: 375, LR: 1.3124e-04, epoch time: 81.96, snr: 2.3848e+00, var(R): 4.1665e-09, var(L*R): 9.4968e-09, WD: 1.6943e-06
[2025-08-03 09:43:19] - Epoch 383/500,it:156264, Train Loss: 4.0122e-02, Val Loss: 1.4369e-02, best model: 375, LR: 1.2913e-04, epoch time: 81.97, snr: 2.4588e+00, var(R): 3.7999e-09, var(L*R): 7.9808e-09, WD: 1.6849e-06
[2025-08-03 09:44:41] - Epoch 384/500,it:156672, Train Loss: 4.0650e-02, Val Loss: 1.3999e-02, best model: 384, LR: 1.2703e-04, epoch time: 81.92, snr: 2.5007e+00, var(R): 4.1369e-09, var(L*R): 8.6845e-09, WD: 1.6927e-06
[2025-08-03 09:46:03] - Epoch 385/500,it:157080, Train Loss: 3.7527e-02, Val Loss: 1.7064e-02, best model: 384, LR: 1.2494e-04, epoch time: 81.97, snr: 2.5692e+00, var(R): 4.0370e-09, var(L*R): 8.5199e-09, WD: 1.6958e-06
[2025-08-03 09:47:25] - Epoch 386/500,it:157488, Train Loss: 4.1952e-02, Val Loss: 1.6996e-02, best model: 384, LR: 1.2287e-04, epoch time: 81.83, snr: 1.7821e+00, var(R): 4.0864e-09, var(L*R): 8.6346e-09, WD: 1.6957e-06
[2025-08-03 09:48:47] - Epoch 387/500,it:157896, Train Loss: 3.9536e-02, Val Loss: 1.5007e-02, best model: 384, LR: 1.2082e-04, epoch time: 81.91, snr: 2.0402e+00, var(R): 4.2378e-09, var(L*R): 9.0861e-09, WD: 1.6938e-06
[2025-08-03 09:50:09] - Epoch 388/500,it:158304, Train Loss: 4.0808e-02, Val Loss: 1.5054e-02, best model: 384, LR: 1.1878e-04, epoch time: 81.94, snr: 2.7172e+00, var(R): 4.3732e-09, var(L*R): 1.0396e-08, WD: 1.6946e-06
[2025-08-03 09:51:31] - Epoch 389/500,it:158712, Train Loss: 3.9456e-02, Val Loss: 1.3959e-02, best model: 389, LR: 1.1675e-04, epoch time: 81.96, snr: 3.9666e+00, var(R): 4.2535e-09, var(L*R): 8.7445e-09, WD: 1.6954e-06
[2025-08-03 09:52:52] - Epoch 390/500,it:159120, Train Loss: 4.1960e-02, Val Loss: 1.6138e-02, best model: 389, LR: 1.1474e-04, epoch time: 81.92, snr: 3.0199e+00, var(R): 4.1393e-09, var(L*R): 8.7878e-09, WD: 1.6943e-06
[2025-08-03 09:54:14] - Epoch 391/500,it:159528, Train Loss: 3.7470e-02, Val Loss: 1.9963e-02, best model: 389, LR: 1.1275e-04, epoch time: 81.91, snr: 1.9538e+00, var(R): 4.3265e-09, var(L*R): 9.1599e-09, WD: 1.6893e-06
[2025-08-03 09:55:36] - Epoch 392/500,it:159936, Train Loss: 3.8291e-02, Val Loss: 1.3109e-02, best model: 392, LR: 1.1077e-04, epoch time: 81.93, snr: 5.8975e+00, var(R): 4.4457e-09, var(L*R): 9.4128e-09, WD: 1.6940e-06
[2025-08-03 09:56:58] - Epoch 393/500,it:160344, Train Loss: 4.0528e-02, Val Loss: 1.4901e-02, best model: 392, LR: 1.0880e-04, epoch time: 82.07, snr: 3.0946e+00, var(R): 4.4688e-09, var(L*R): 9.3627e-09, WD: 1.6932e-06
[2025-08-03 09:58:20] - Epoch 394/500,it:160752, Train Loss: 3.6248e-02, Val Loss: 1.4080e-02, best model: 392, LR: 1.0686e-04, epoch time: 81.82, snr: 2.6768e+00, var(R): 4.4891e-09, var(L*R): 9.5100e-09, WD: 1.6977e-06
[2025-08-03 09:59:42] - Epoch 395/500,it:161160, Train Loss: 3.6786e-02, Val Loss: 1.3820e-02, best model: 392, LR: 1.0492e-04, epoch time: 81.84, snr: 3.2575e+00, var(R): 4.4986e-09, var(L*R): 9.4513e-09, WD: 1.6977e-06
[2025-08-03 10:01:04] - Epoch 396/500,it:161568, Train Loss: 3.8073e-02, Val Loss: 1.3980e-02, best model: 392, LR: 1.0300e-04, epoch time: 81.94, snr: 2.8178e+00, var(R): 4.4521e-09, var(L*R): 9.5446e-09, WD: 1.6879e-06
[2025-08-03 10:02:26] - Epoch 397/500,it:161976, Train Loss: 3.4615e-02, Val Loss: 1.3853e-02, best model: 392, LR: 1.0110e-04, epoch time: 81.85, snr: 4.1123e+00, var(R): 4.6497e-09, var(L*R): 9.9494e-09, WD: 1.6844e-06
[2025-08-03 10:03:48] - Epoch 398/500,it:162384, Train Loss: 3.5477e-02, Val Loss: 1.4313e-02, best model: 392, LR: 9.9217e-05, epoch time: 81.88, snr: 3.2744e+00, var(R): 4.4748e-09, var(L*R): 9.2259e-09, WD: 1.6892e-06
[2025-08-03 10:05:10] - Epoch 399/500,it:162792, Train Loss: 3.6516e-02, Val Loss: 1.3661e-02, best model: 392, LR: 9.7346e-05, epoch time: 81.97, snr: 2.2912e+00, var(R): 4.7058e-09, var(L*R): 1.0155e-08, WD: 1.6893e-06
[2025-08-03 10:06:32] - Epoch 400/500,it:163200, Train Loss: 3.5385e-02, Val Loss: 1.4352e-02, best model: 392, LR: 9.5492e-05, epoch time: 81.94, snr: 2.4302e+00, var(R): 4.9222e-09, var(L*R): 1.0577e-08, WD: 1.6827e-06
[2025-08-03 10:07:54] - Epoch 401/500,it:163608, Train Loss: 3.4774e-02, Val Loss: 1.2953e-02, best model: 401, LR: 9.3653e-05, epoch time: 81.92, snr: 2.1697e+00, var(R): 4.8821e-09, var(L*R): 1.0667e-08, WD: 1.6872e-06
[2025-08-03 10:09:16] - Epoch 402/500,it:164016, Train Loss: 3.4895e-02, Val Loss: 1.2867e-02, best model: 402, LR: 9.1830e-05, epoch time: 82.01, snr: 2.8937e+00, var(R): 4.8918e-09, var(L*R): 1.0484e-08, WD: 1.6835e-06
[2025-08-03 10:10:38] - Epoch 403/500,it:164424, Train Loss: 3.4958e-02, Val Loss: 1.4535e-02, best model: 402, LR: 9.0024e-05, epoch time: 81.92, snr: 3.1400e+00, var(R): 4.9040e-09, var(L*R): 1.0581e-08, WD: 1.6914e-06
[2025-08-03 10:12:00] - Epoch 404/500,it:164832, Train Loss: 3.6362e-02, Val Loss: 1.3077e-02, best model: 402, LR: 8.8234e-05, epoch time: 82.01, snr: 4.0743e+00, var(R): 4.8774e-09, var(L*R): 1.0158e-08, WD: 1.6978e-06
[2025-08-03 10:13:21] - Epoch 405/500,it:165240, Train Loss: 3.5126e-02, Val Loss: 1.2806e-02, best model: 405, LR: 8.6460e-05, epoch time: 81.92, snr: 2.6137e+00, var(R): 4.9838e-09, var(L*R): 1.0785e-08, WD: 1.6860e-06
[2025-08-03 10:14:43] - Epoch 406/500,it:165648, Train Loss: 3.3710e-02, Val Loss: 1.5474e-02, best model: 405, LR: 8.4702e-05, epoch time: 81.85, snr: 2.6937e+00, var(R): 5.1174e-09, var(L*R): 1.0907e-08, WD: 1.6899e-06
[2025-08-03 10:16:05] - Epoch 407/500,it:166056, Train Loss: 3.6029e-02, Val Loss: 1.2908e-02, best model: 405, LR: 8.2961e-05, epoch time: 82.01, snr: 1.9634e+00, var(R): 5.3224e-09, var(L*R): 1.1677e-08, WD: 1.7017e-06
[2025-08-03 10:17:27] - Epoch 408/500,it:166464, Train Loss: 3.5352e-02, Val Loss: 1.5417e-02, best model: 405, LR: 8.1236e-05, epoch time: 81.92, snr: 3.1921e+00, var(R): 5.1413e-09, var(L*R): 1.1059e-08, WD: 1.6860e-06
[2025-08-03 10:18:49] - Epoch 409/500,it:166872, Train Loss: 3.3601e-02, Val Loss: 1.4252e-02, best model: 405, LR: 7.9528e-05, epoch time: 81.79, snr: 4.4779e+00, var(R): 5.0952e-09, var(L*R): 1.1027e-08, WD: 1.6876e-06
[2025-08-03 10:20:11] - Epoch 410/500,it:167280, Train Loss: 3.5682e-02, Val Loss: 1.2926e-02, best model: 405, LR: 7.7836e-05, epoch time: 81.94, snr: 2.2342e+00, var(R): 5.3051e-09, var(L*R): 1.1274e-08, WD: 1.6840e-06
[2025-08-03 10:21:33] - Epoch 411/500,it:167688, Train Loss: 3.2678e-02, Val Loss: 1.2714e-02, best model: 411, LR: 7.6161e-05, epoch time: 82.03, snr: 3.6722e+00, var(R): 5.1898e-09, var(L*R): 1.1060e-08, WD: 1.6902e-06
[2025-08-03 10:22:55] - Epoch 412/500,it:168096, Train Loss: 3.4507e-02, Val Loss: 1.2514e-02, best model: 412, LR: 7.4503e-05, epoch time: 81.96, snr: 2.9338e+00, var(R): 5.4362e-09, var(L*R): 1.1482e-08, WD: 1.6886e-06
[2025-08-03 10:24:17] - Epoch 413/500,it:168504, Train Loss: 3.3253e-02, Val Loss: 1.3069e-02, best model: 412, LR: 7.2861e-05, epoch time: 81.89, snr: 2.7922e+00, var(R): 5.2802e-09, var(L*R): 1.1473e-08, WD: 1.6811e-06
[2025-08-03 10:25:39] - Epoch 414/500,it:168912, Train Loss: 3.2145e-02, Val Loss: 1.2601e-02, best model: 412, LR: 7.1237e-05, epoch time: 81.91, snr: 3.6775e+00, var(R): 5.5093e-09, var(L*R): 1.1513e-08, WD: 1.6794e-06
[2025-08-03 10:27:01] - Epoch 415/500,it:169320, Train Loss: 3.2707e-02, Val Loss: 1.2655e-02, best model: 412, LR: 6.9629e-05, epoch time: 81.94, snr: 3.6676e+00, var(R): 5.5214e-09, var(L*R): 1.1820e-08, WD: 1.6918e-06
[2025-08-03 10:28:23] - Epoch 416/500,it:169728, Train Loss: 3.2647e-02, Val Loss: 1.2995e-02, best model: 412, LR: 6.8038e-05, epoch time: 81.82, snr: 3.7060e+00, var(R): 5.5991e-09, var(L*R): 1.1891e-08, WD: 1.6729e-06
[2025-08-03 10:29:45] - Epoch 417/500,it:170136, Train Loss: 3.2760e-02, Val Loss: 1.2401e-02, best model: 417, LR: 6.6465e-05, epoch time: 81.96, snr: 2.4711e+00, var(R): 5.7057e-09, var(L*R): 1.2063e-08, WD: 1.6752e-06
[2025-08-03 10:31:06] - Epoch 418/500,it:170544, Train Loss: 3.4270e-02, Val Loss: 1.2690e-02, best model: 417, LR: 6.4908e-05, epoch time: 81.96, snr: 3.2541e+00, var(R): 5.6639e-09, var(L*R): 1.2249e-08, WD: 1.6771e-06
[2025-08-03 10:32:28] - Epoch 419/500,it:170952, Train Loss: 3.2395e-02, Val Loss: 1.2764e-02, best model: 417, LR: 6.3369e-05, epoch time: 81.93, snr: 2.7662e+00, var(R): 5.7348e-09, var(L*R): 1.2333e-08, WD: 1.6753e-06
[2025-08-03 10:33:50] - Epoch 420/500,it:171360, Train Loss: 3.4008e-02, Val Loss: 1.2563e-02, best model: 417, LR: 6.1847e-05, epoch time: 81.76, snr: 2.4767e+00, var(R): 5.8039e-09, var(L*R): 1.2564e-08, WD: 1.6839e-06
[2025-08-03 10:35:12] - Epoch 421/500,it:171768, Train Loss: 3.2069e-02, Val Loss: 1.3328e-02, best model: 417, LR: 6.0342e-05, epoch time: 81.96, snr: 2.7677e+00, var(R): 5.5891e-09, var(L*R): 1.1869e-08, WD: 1.6719e-06
[2025-08-03 10:36:34] - Epoch 422/500,it:172176, Train Loss: 3.2750e-02, Val Loss: 1.1898e-02, best model: 422, LR: 5.8854e-05, epoch time: 82.02, snr: 3.1104e+00, var(R): 5.7398e-09, var(L*R): 1.2019e-08, WD: 1.6691e-06
[2025-08-03 10:37:56] - Epoch 423/500,it:172584, Train Loss: 3.2898e-02, Val Loss: 1.8335e-02, best model: 422, LR: 5.7384e-05, epoch time: 81.90, snr: 2.7572e+00, var(R): 5.9834e-09, var(L*R): 1.2751e-08, WD: 1.6686e-06
[2025-08-03 10:39:18] - Epoch 424/500,it:172992, Train Loss: 3.2970e-02, Val Loss: 1.3403e-02, best model: 422, LR: 5.5932e-05, epoch time: 81.82, snr: 5.0215e+00, var(R): 5.8714e-09, var(L*R): 1.2566e-08, WD: 1.6798e-06
[2025-08-03 10:40:40] - Epoch 425/500,it:173400, Train Loss: 3.0863e-02, Val Loss: 1.2831e-02, best model: 422, LR: 5.4497e-05, epoch time: 81.91, snr: 3.9065e+00, var(R): 5.9384e-09, var(L*R): 1.2553e-08, WD: 1.6780e-06
[2025-08-03 10:42:02] - Epoch 426/500,it:173808, Train Loss: 3.1896e-02, Val Loss: 1.2047e-02, best model: 422, LR: 5.3079e-05, epoch time: 81.90, snr: 2.7373e+00, var(R): 6.2717e-09, var(L*R): 1.3613e-08, WD: 1.6673e-06
[2025-08-03 10:43:24] - Epoch 427/500,it:174216, Train Loss: 3.1627e-02, Val Loss: 1.2021e-02, best model: 422, LR: 5.1679e-05, epoch time: 81.96, snr: 2.9609e+00, var(R): 6.1948e-09, var(L*R): 1.3418e-08, WD: 1.6693e-06
[2025-08-03 10:44:46] - Epoch 428/500,it:174624, Train Loss: 3.2342e-02, Val Loss: 1.2064e-02, best model: 422, LR: 5.0297e-05, epoch time: 81.88, snr: 2.9961e+00, var(R): 6.1455e-09, var(L*R): 1.3295e-08, WD: 1.6702e-06
[2025-08-03 10:46:08] - Epoch 429/500,it:175032, Train Loss: 3.0887e-02, Val Loss: 1.1815e-02, best model: 429, LR: 4.8933e-05, epoch time: 82.01, snr: 3.0875e+00, var(R): 6.2928e-09, var(L*R): 1.3577e-08, WD: 1.6683e-06
[2025-08-03 10:47:29] - Epoch 430/500,it:175440, Train Loss: 3.1880e-02, Val Loss: 1.1954e-02, best model: 429, LR: 4.7586e-05, epoch time: 81.84, snr: 3.2650e+00, var(R): 6.1176e-09, var(L*R): 1.3370e-08, WD: 1.6672e-06
[2025-08-03 10:48:51] - Epoch 431/500,it:175848, Train Loss: 3.1072e-02, Val Loss: 1.1572e-02, best model: 431, LR: 4.6258e-05, epoch time: 81.94, snr: 3.2453e+00, var(R): 6.4395e-09, var(L*R): 1.3650e-08, WD: 1.6704e-06
[2025-08-03 10:50:13] - Epoch 432/500,it:176256, Train Loss: 3.0553e-02, Val Loss: 1.1493e-02, best model: 432, LR: 4.4947e-05, epoch time: 82.03, snr: 3.0800e+00, var(R): 6.2415e-09, var(L*R): 1.3645e-08, WD: 1.6756e-06
[2025-08-03 10:51:35] - Epoch 433/500,it:176664, Train Loss: 3.1048e-02, Val Loss: 1.1626e-02, best model: 432, LR: 4.3654e-05, epoch time: 81.90, snr: 3.1971e+00, var(R): 6.3183e-09, var(L*R): 1.3697e-08, WD: 1.6778e-06
[2025-08-03 10:52:57] - Epoch 434/500,it:177072, Train Loss: 2.9907e-02, Val Loss: 1.1533e-02, best model: 432, LR: 4.2379e-05, epoch time: 81.91, snr: 3.2802e+00, var(R): 6.3738e-09, var(L*R): 1.3990e-08, WD: 1.6626e-06
[2025-08-03 10:54:19] - Epoch 435/500,it:177480, Train Loss: 3.1427e-02, Val Loss: 1.2001e-02, best model: 432, LR: 4.1123e-05, epoch time: 81.88, snr: 3.3680e+00, var(R): 6.5083e-09, var(L*R): 1.4162e-08, WD: 1.6653e-06
[2025-08-03 10:55:41] - Epoch 436/500,it:177888, Train Loss: 3.0353e-02, Val Loss: 1.1635e-02, best model: 432, LR: 3.9884e-05, epoch time: 81.84, snr: 2.9606e+00, var(R): 6.5614e-09, var(L*R): 1.4267e-08, WD: 1.6632e-06
[2025-08-03 10:57:03] - Epoch 437/500,it:178296, Train Loss: 2.9955e-02, Val Loss: 1.1554e-02, best model: 432, LR: 3.8664e-05, epoch time: 81.89, snr: 3.3477e+00, var(R): 6.2400e-09, var(L*R): 1.3565e-08, WD: 1.6654e-06
[2025-08-03 10:58:25] - Epoch 438/500,it:178704, Train Loss: 3.0638e-02, Val Loss: 1.1317e-02, best model: 438, LR: 3.7461e-05, epoch time: 81.94, snr: 3.5757e+00, var(R): 6.7052e-09, var(L*R): 1.4449e-08, WD: 1.6591e-06
[2025-08-03 10:59:47] - Epoch 439/500,it:179112, Train Loss: 2.9608e-02, Val Loss: 1.2390e-02, best model: 438, LR: 3.6277e-05, epoch time: 81.88, snr: 3.4385e+00, var(R): 6.5749e-09, var(L*R): 1.4312e-08, WD: 1.6658e-06
[2025-08-03 11:01:09] - Epoch 440/500,it:179520, Train Loss: 3.0508e-02, Val Loss: 1.1478e-02, best model: 438, LR: 3.5112e-05, epoch time: 81.98, snr: 2.9085e+00, var(R): 6.7973e-09, var(L*R): 1.4951e-08, WD: 1.6664e-06
[2025-08-03 11:02:31] - Epoch 441/500,it:179928, Train Loss: 3.0550e-02, Val Loss: 1.2223e-02, best model: 438, LR: 3.3964e-05, epoch time: 81.94, snr: 3.3243e+00, var(R): 6.7230e-09, var(L*R): 1.4657e-08, WD: 1.6622e-06
[2025-08-03 11:03:52] - Epoch 442/500,it:180336, Train Loss: 3.0010e-02, Val Loss: 1.1387e-02, best model: 438, LR: 3.2836e-05, epoch time: 81.91, snr: 3.5353e+00, var(R): 6.9527e-09, var(L*R): 1.5377e-08, WD: 1.6587e-06
[2025-08-03 11:05:14] - Epoch 443/500,it:180744, Train Loss: 2.9550e-02, Val Loss: 1.1967e-02, best model: 438, LR: 3.1725e-05, epoch time: 81.93, snr: 3.3748e+00, var(R): 6.7762e-09, var(L*R): 1.4791e-08, WD: 1.6633e-06
[2025-08-03 11:06:36] - Epoch 444/500,it:181152, Train Loss: 2.9998e-02, Val Loss: 1.1959e-02, best model: 438, LR: 3.0633e-05, epoch time: 81.98, snr: 2.9820e+00, var(R): 6.7471e-09, var(L*R): 1.4968e-08, WD: 1.6587e-06
[2025-08-03 11:07:58] - Epoch 445/500,it:181560, Train Loss: 3.0094e-02, Val Loss: 1.1989e-02, best model: 438, LR: 2.9560e-05, epoch time: 81.87, snr: 2.9899e+00, var(R): 6.7994e-09, var(L*R): 1.4947e-08, WD: 1.6671e-06
[2025-08-03 11:09:20] - Epoch 446/500,it:181968, Train Loss: 2.9903e-02, Val Loss: 1.2478e-02, best model: 438, LR: 2.8505e-05, epoch time: 81.87, snr: 3.3757e+00, var(R): 6.9411e-09, var(L*R): 1.5453e-08, WD: 1.6566e-06
[2025-08-03 11:10:42] - Epoch 447/500,it:182376, Train Loss: 3.0372e-02, Val Loss: 1.1101e-02, best model: 447, LR: 2.7468e-05, epoch time: 82.00, snr: 3.7945e+00, var(R): 6.9952e-09, var(L*R): 1.5478e-08, WD: 1.6635e-06
[2025-08-03 11:12:04] - Epoch 448/500,it:182784, Train Loss: 2.8976e-02, Val Loss: 1.1224e-02, best model: 447, LR: 2.6451e-05, epoch time: 81.90, snr: 3.6940e+00, var(R): 7.0093e-09, var(L*R): 1.5450e-08, WD: 1.6625e-06
[2025-08-03 11:13:26] - Epoch 449/500,it:183192, Train Loss: 2.9099e-02, Val Loss: 1.3650e-02, best model: 447, LR: 2.5452e-05, epoch time: 81.99, snr: 3.4307e+00, var(R): 7.0912e-09, var(L*R): 1.5884e-08, WD: 1.6665e-06
[2025-08-03 11:14:48] - Epoch 450/500,it:183600, Train Loss: 2.9537e-02, Val Loss: 1.1065e-02, best model: 450, LR: 2.4472e-05, epoch time: 81.81, snr: 4.2540e+00, var(R): 7.2464e-09, var(L*R): 1.5957e-08, WD: 1.6520e-06
[2025-08-03 11:16:10] - Epoch 451/500,it:184008, Train Loss: 2.8626e-02, Val Loss: 1.1130e-02, best model: 450, LR: 2.3510e-05, epoch time: 82.06, snr: 3.7040e+00, var(R): 7.0595e-09, var(L*R): 1.5781e-08, WD: 1.6513e-06
[2025-08-03 11:17:32] - Epoch 452/500,it:184416, Train Loss: 2.8572e-02, Val Loss: 1.1201e-02, best model: 450, LR: 2.2568e-05, epoch time: 81.91, snr: 3.9105e+00, var(R): 7.2284e-09, var(L*R): 1.6044e-08, WD: 1.6536e-06
[2025-08-03 11:18:54] - Epoch 453/500,it:184824, Train Loss: 2.9442e-02, Val Loss: 1.2244e-02, best model: 450, LR: 2.1644e-05, epoch time: 81.85, snr: 3.7504e+00, var(R): 7.1183e-09, var(L*R): 1.5872e-08, WD: 1.6481e-06
[2025-08-03 11:20:16] - Epoch 454/500,it:185232, Train Loss: 2.9147e-02, Val Loss: 1.1058e-02, best model: 454, LR: 2.0739e-05, epoch time: 81.92, snr: 2.9230e+00, var(R): 7.2940e-09, var(L*R): 1.6386e-08, WD: 1.6567e-06
[2025-08-03 11:21:38] - Epoch 455/500,it:185640, Train Loss: 2.9130e-02, Val Loss: 1.0974e-02, best model: 455, LR: 1.9853e-05, epoch time: 81.96, snr: 3.4908e+00, var(R): 7.4051e-09, var(L*R): 1.6712e-08, WD: 1.6475e-06
[2025-08-03 11:23:00] - Epoch 456/500,it:186048, Train Loss: 2.8841e-02, Val Loss: 1.1030e-02, best model: 455, LR: 1.8986e-05, epoch time: 81.95, snr: 3.6517e+00, var(R): 7.2966e-09, var(L*R): 1.6501e-08, WD: 1.6521e-06
[2025-08-03 11:24:21] - Epoch 457/500,it:186456, Train Loss: 2.8770e-02, Val Loss: 1.1076e-02, best model: 455, LR: 1.8138e-05, epoch time: 81.91, snr: 3.6742e+00, var(R): 7.3615e-09, var(L*R): 1.6610e-08, WD: 1.6447e-06
[2025-08-03 11:25:43] - Epoch 458/500,it:186864, Train Loss: 2.8480e-02, Val Loss: 1.1015e-02, best model: 455, LR: 1.7309e-05, epoch time: 81.72, snr: 3.7807e+00, var(R): 7.3385e-09, var(L*R): 1.6479e-08, WD: 1.6481e-06
[2025-08-03 11:27:05] - Epoch 459/500,it:187272, Train Loss: 2.8539e-02, Val Loss: 1.0964e-02, best model: 459, LR: 1.6499e-05, epoch time: 82.01, snr: 3.4490e+00, var(R): 7.4232e-09, var(L*R): 1.6963e-08, WD: 1.6515e-06
[2025-08-03 11:28:27] - Epoch 460/500,it:187680, Train Loss: 2.8442e-02, Val Loss: 1.0911e-02, best model: 460, LR: 1.5708e-05, epoch time: 81.97, snr: 3.6036e+00, var(R): 7.3203e-09, var(L*R): 1.6668e-08, WD: 1.6543e-06
[2025-08-03 11:29:49] - Epoch 461/500,it:188088, Train Loss: 2.8884e-02, Val Loss: 1.1995e-02, best model: 460, LR: 1.4937e-05, epoch time: 81.79, snr: 3.4829e+00, var(R): 7.5534e-09, var(L*R): 1.7199e-08, WD: 1.6427e-06
[2025-08-03 11:31:11] - Epoch 462/500,it:188496, Train Loss: 2.8641e-02, Val Loss: 1.1095e-02, best model: 460, LR: 1.4184e-05, epoch time: 82.01, snr: 4.0277e+00, var(R): 7.6674e-09, var(L*R): 1.7358e-08, WD: 1.6371e-06
[2025-08-03 11:32:33] - Epoch 463/500,it:188904, Train Loss: 2.8490e-02, Val Loss: 1.0950e-02, best model: 460, LR: 1.3451e-05, epoch time: 82.01, snr: 3.3702e+00, var(R): 7.5820e-09, var(L*R): 1.7532e-08, WD: 1.6474e-06
[2025-08-03 11:33:55] - Epoch 464/500,it:189312, Train Loss: 2.8500e-02, Val Loss: 1.0854e-02, best model: 464, LR: 1.2737e-05, epoch time: 81.72, snr: 3.4582e+00, var(R): 7.6620e-09, var(L*R): 1.7551e-08, WD: 1.6375e-06
[2025-08-03 11:35:16] - Epoch 465/500,it:189720, Train Loss: 2.8585e-02, Val Loss: 1.0820e-02, best model: 465, LR: 1.2042e-05, epoch time: 80.92, snr: 3.4435e+00, var(R): 7.6731e-09, var(L*R): 1.7780e-08, WD: 1.6515e-06
[2025-08-03 11:36:37] - Epoch 466/500,it:190128, Train Loss: 2.8596e-02, Val Loss: 1.0819e-02, best model: 466, LR: 1.1366e-05, epoch time: 80.95, snr: 3.5635e+00, var(R): 7.6817e-09, var(L*R): 1.7653e-08, WD: 1.6483e-06
[2025-08-03 11:37:58] - Epoch 467/500,it:190536, Train Loss: 2.8456e-02, Val Loss: 1.0800e-02, best model: 467, LR: 1.0710e-05, epoch time: 81.01, snr: 3.7371e+00, var(R): 7.6719e-09, var(L*R): 1.7808e-08, WD: 1.6407e-06
[2025-08-03 11:39:18] - Epoch 468/500,it:190944, Train Loss: 2.8143e-02, Val Loss: 1.0877e-02, best model: 467, LR: 1.0072e-05, epoch time: 80.89, snr: 3.7524e+00, var(R): 7.7369e-09, var(L*R): 1.7941e-08, WD: 1.6460e-06
[2025-08-03 11:40:39] - Epoch 469/500,it:191352, Train Loss: 2.8453e-02, Val Loss: 1.0956e-02, best model: 467, LR: 9.4547e-06, epoch time: 80.80, snr: 3.7199e+00, var(R): 7.8731e-09, var(L*R): 1.8469e-08, WD: 1.6367e-06
[2025-08-03 11:42:00] - Epoch 470/500,it:191760, Train Loss: 2.8228e-02, Val Loss: 1.0752e-02, best model: 470, LR: 8.8564e-06, epoch time: 80.98, snr: 3.7920e+00, var(R): 7.7297e-09, var(L*R): 1.7900e-08, WD: 1.6369e-06
[2025-08-03 11:43:21] - Epoch 471/500,it:192168, Train Loss: 2.8284e-02, Val Loss: 1.0747e-02, best model: 471, LR: 8.2774e-06, epoch time: 80.95, snr: 3.5817e+00, var(R): 7.8031e-09, var(L*R): 1.8399e-08, WD: 1.6428e-06
[2025-08-03 11:44:42] - Epoch 472/500,it:192576, Train Loss: 2.8331e-02, Val Loss: 1.0841e-02, best model: 471, LR: 7.7178e-06, epoch time: 80.88, snr: 3.5707e+00, var(R): 7.7995e-09, var(L*R): 1.8480e-08, WD: 1.6479e-06
[2025-08-03 11:46:03] - Epoch 473/500,it:192984, Train Loss: 2.8512e-02, Val Loss: 1.0814e-02, best model: 471, LR: 7.1777e-06, epoch time: 80.82, snr: 3.4447e+00, var(R): 7.9187e-09, var(L*R): 1.8778e-08, WD: 1.6441e-06
[2025-08-03 11:47:24] - Epoch 474/500,it:193392, Train Loss: 2.8314e-02, Val Loss: 1.0771e-02, best model: 471, LR: 6.6570e-06, epoch time: 80.89, snr: 3.5223e+00, var(R): 7.8882e-09, var(L*R): 1.8747e-08, WD: 1.6286e-06
[2025-08-03 11:48:45] - Epoch 475/500,it:193800, Train Loss: 2.8482e-02, Val Loss: 1.0708e-02, best model: 475, LR: 6.1558e-06, epoch time: 80.98, snr: 3.4378e+00, var(R): 7.9926e-09, var(L*R): 1.9271e-08, WD: 1.6481e-06
[2025-08-03 11:50:06] - Epoch 476/500,it:194208, Train Loss: 2.8246e-02, Val Loss: 1.0876e-02, best model: 475, LR: 5.6741e-06, epoch time: 80.81, snr: 3.5962e+00, var(R): 7.9667e-09, var(L*R): 1.9071e-08, WD: 1.6472e-06
[2025-08-03 11:51:27] - Epoch 477/500,it:194616, Train Loss: 2.8235e-02, Val Loss: 1.0692e-02, best model: 477, LR: 5.2119e-06, epoch time: 80.98, snr: 3.6414e+00, var(R): 7.9512e-09, var(L*R): 1.9265e-08, WD: 1.6270e-06
[2025-08-03 11:52:48] - Epoch 478/500,it:195024, Train Loss: 2.8410e-02, Val Loss: 1.0653e-02, best model: 478, LR: 4.7693e-06, epoch time: 80.94, snr: 3.5292e+00, var(R): 7.8888e-09, var(L*R): 1.9093e-08, WD: 1.6414e-06
[2025-08-03 11:54:08] - Epoch 479/500,it:195432, Train Loss: 2.8450e-02, Val Loss: 1.0725e-02, best model: 478, LR: 4.3462e-06, epoch time: 80.88, snr: 3.5727e+00, var(R): 7.9087e-09, var(L*R): 1.9294e-08, WD: 1.6332e-06
[2025-08-03 11:55:29] - Epoch 480/500,it:195840, Train Loss: 2.8174e-02, Val Loss: 1.0657e-02, best model: 478, LR: 3.9426e-06, epoch time: 80.82, snr: 3.3836e+00, var(R): 8.0075e-09, var(L*R): 1.9691e-08, WD: 1.6499e-06
[2025-08-03 11:56:50] - Epoch 481/500,it:196248, Train Loss: 2.8323e-02, Val Loss: 1.0630e-02, best model: 481, LR: 3.5587e-06, epoch time: 80.96, snr: 3.5212e+00, var(R): 8.0362e-09, var(L*R): 1.9855e-08, WD: 1.6396e-06
[2025-08-03 11:58:11] - Epoch 482/500,it:196656, Train Loss: 2.8388e-02, Val Loss: 1.0642e-02, best model: 481, LR: 3.1943e-06, epoch time: 80.89, snr: 3.4579e+00, var(R): 8.0841e-09, var(L*R): 1.9970e-08, WD: 1.6225e-06
[2025-08-03 11:59:32] - Epoch 483/500,it:197064, Train Loss: 2.8404e-02, Val Loss: 1.0615e-02, best model: 483, LR: 2.8496e-06, epoch time: 80.97, snr: 3.4568e+00, var(R): 8.0590e-09, var(L*R): 2.0089e-08, WD: 1.6377e-06
[2025-08-03 12:00:53] - Epoch 484/500,it:197472, Train Loss: 2.8433e-02, Val Loss: 1.0658e-02, best model: 483, LR: 2.5245e-06, epoch time: 80.80, snr: 3.5274e+00, var(R): 8.0751e-09, var(L*R): 2.0238e-08, WD: 1.6347e-06
[2025-08-03 12:02:14] - Epoch 485/500,it:197880, Train Loss: 2.8372e-02, Val Loss: 1.0810e-02, best model: 483, LR: 2.2190e-06, epoch time: 80.90, snr: 3.4681e+00, var(R): 8.0596e-09, var(L*R): 2.0296e-08, WD: 1.6344e-06
[2025-08-03 12:03:35] - Epoch 486/500,it:198288, Train Loss: 2.8415e-02, Val Loss: 1.0585e-02, best model: 486, LR: 1.9332e-06, epoch time: 80.94, snr: 3.5950e+00, var(R): 8.0781e-09, var(L*R): 2.0486e-08, WD: 1.6356e-06
[2025-08-03 12:04:56] - Epoch 487/500,it:198696, Train Loss: 2.8449e-02, Val Loss: 1.0589e-02, best model: 486, LR: 1.6670e-06, epoch time: 80.87, snr: 3.5520e+00, var(R): 8.0560e-09, var(L*R): 2.0521e-08, WD: 1.6298e-06
[2025-08-03 12:06:16] - Epoch 488/500,it:199104, Train Loss: 2.8433e-02, Val Loss: 1.0594e-02, best model: 486, LR: 1.4205e-06, epoch time: 80.78, snr: 3.5246e+00, var(R): 8.0760e-09, var(L*R): 2.0658e-08, WD: 1.6188e-06
[2025-08-03 12:07:37] - Epoch 489/500,it:199512, Train Loss: 2.8462e-02, Val Loss: 1.0700e-02, best model: 486, LR: 1.1937e-06, epoch time: 80.90, snr: 3.4669e+00, var(R): 8.0952e-09, var(L*R): 2.0842e-08, WD: 1.6253e-06
[2025-08-03 12:08:58] - Epoch 490/500,it:199920, Train Loss: 2.8419e-02, Val Loss: 1.0643e-02, best model: 486, LR: 9.8664e-07, epoch time: 80.88, snr: 3.5301e+00, var(R): 8.0585e-09, var(L*R): 2.0879e-08, WD: 1.6253e-06
[2025-08-03 12:10:19] - Epoch 491/500,it:200328, Train Loss: 2.8387e-02, Val Loss: 1.0575e-02, best model: 491, LR: 7.9922e-07, epoch time: 80.97, snr: 3.5339e+00, var(R): 8.1196e-09, var(L*R): 2.1111e-08, WD: 1.6219e-06
[2025-08-03 12:11:40] - Epoch 492/500,it:200736, Train Loss: 2.8468e-02, Val Loss: 1.0578e-02, best model: 491, LR: 6.3152e-07, epoch time: 80.84, snr: 3.4866e+00, var(R): 8.1009e-09, var(L*R): 2.1205e-08, WD: 1.6222e-06
[2025-08-03 12:13:01] - Epoch 493/500,it:201144, Train Loss: 2.8631e-02, Val Loss: 1.0553e-02, best model: 493, LR: 4.8353e-07, epoch time: 80.96, snr: 3.4871e+00, var(R): 8.0858e-09, var(L*R): 2.1335e-08, WD: 1.6313e-06
[2025-08-03 12:14:22] - Epoch 494/500,it:201552, Train Loss: 2.8332e-02, Val Loss: 1.0551e-02, best model: 494, LR: 3.5526e-07, epoch time: 80.97, snr: 3.5105e+00, var(R): 8.1163e-09, var(L*R): 2.1522e-08, WD: 1.6206e-06
[2025-08-03 12:15:43] - Epoch 495/500,it:201960, Train Loss: 2.8512e-02, Val Loss: 1.0562e-02, best model: 494, LR: 2.4672e-07, epoch time: 80.79, snr: 3.4793e+00, var(R): 8.1327e-09, var(L*R): 2.1698e-08, WD: 1.6304e-06
[2025-08-03 12:17:04] - Epoch 496/500,it:202368, Train Loss: 2.8638e-02, Val Loss: 1.0578e-02, best model: 494, LR: 1.5791e-07, epoch time: 80.88, snr: 3.4548e+00, var(R): 8.1088e-09, var(L*R): 2.1772e-08, WD: 1.6267e-06
[2025-08-03 12:18:25] - Epoch 497/500,it:202776, Train Loss: 2.8529e-02, Val Loss: 1.0567e-02, best model: 494, LR: 8.8824e-08, epoch time: 80.90, snr: 3.4782e+00, var(R): 8.1229e-09, var(L*R): 2.1953e-08, WD: 1.6203e-06
[2025-08-03 12:19:45] - Epoch 498/500,it:203184, Train Loss: 2.8590e-02, Val Loss: 1.0570e-02, best model: 494, LR: 3.9478e-08, epoch time: 80.87, snr: 3.4717e+00, var(R): 8.1416e-09, var(L*R): 2.2133e-08, WD: 1.6284e-06
[2025-08-03 12:21:06] - Epoch 499/500,it:203592, Train Loss: 2.8685e-02, Val Loss: 1.0545e-02, best model: 499, LR: 9.8696e-09, epoch time: 80.85, snr: 3.4701e+00, var(R): 8.1330e-09, var(L*R): 2.2246e-08, WD: 1.6273e-06
[2025-08-03 12:22:27] - Epoch 500/500,it:204000, Train Loss: 2.8701e-02, Val Loss: 1.0544e-02, best model: 500, LR: 0.0000e+00, epoch time: 81.03, snr: 3.4557e+00, var(R): 8.1272e-09, var(L*R): 2.2390e-08, WD: 1.6155e-06
Training finished.
Test Loss: 1.0622e-02
